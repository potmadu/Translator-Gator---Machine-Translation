getwd()
realtime_dat = read.csv("dataset/Feature-User-Word-Translation-Realtime.csv"); end_dat = read.csv("dataset/Feature-User-Word-Translation-At-the-end-ofproject.csv"); manual_check = read.csv("dataset/Manual quality check TG2.csv");
realtime_dat = read.csv("Dataset/Feature-User-Word-Translation-Realtime.csv"); end_dat = read.csv("Dataset/Feature-User-Word-Translation-At-the-end-ofproject.csv"); manual_check = read.csv("Dataset/Manual quality check TG2.csv");
getwd()
realtime_dat = read.csv("Dataset/Feature-User-Word-Translation-Realtime.csv"); end_dat = read.csv("Dataset/Feature-User-Word-Translation-At-the-end-ofproject.csv"); manual_check = read.csv("Dataset/Manual quality check TG2.csv");
getwd()
realtime_dat = read.csv("Dataset/Feature-User-Word-Translation-Realtime.csv"); end_dat = read.csv("Dataset/Feature-User-Word-Translation-At-the-end-ofproject.csv"); manual_check = read.csv("Dataset/Manual quality check TG2.csv");
realtime_dat = read.csv("Dataset/Feature-User-Word-Translation-Realtime.csv"); end_dat = read.csv("Dataset/Feature-User-Word-Translation-At-the-end-ofproject.csv"); manual_check = read.csv("Dataset/Manual quality check TG2.csv");
head(realtime_dat)
realtime_dat = read.csv("Dataset/Feature-User-Word-Translation-Realtime.csv", stringsAsFactors = FALSE); end_dat = read.csv("Dataset/Feature-User-Word-Translation-At-the-end-ofproject.csv", stringsAsFactors = FALSE); manual_check = read.csv("Dataset/Manual quality check TG2.csv", stringsAsFactors = FALSE);
str(realtime_dat)
str(end_dat)
str(manual_check)
head(manual_check)
str(manual_check)
manual_check2 = manual_check[, 1:19];
str(manual_check)
str(manual_check2)
manual_check = manual_check[, 1:19];
ls()
ls()
install.packages("e1071")
install.packages("e1071")
library(e1071);
data(iris);
df = iris;
df = subset(df, Species == 'setosa');
x = subset(df, select = -Species);
y = df$Species;
model = svm(x, y, type = 'one-classification');
print(model)
summary(model);
pred = predict(model, subset(iris, select = -Species));
pred
df
iris$pred = pred;
head(iris)
head(iris,50)
unique(iris$Species)
iris$flag[iris$pred == 'setosa' && iris$pred == TRUE,] = 1;
iris$flag[iris$Species == 'setosa' && iris$pred == TRUE] = 1;
nrow(subset(iris, flag == 1)) / nrow(iris);
head(iris,50)
iris$flag[iris$Species == 'setosa' & iris$pred == TRUE] = 1;
iris$flag = 0; iris$flag[iris$Species == 'setosa' && iris$pred == TRUE] = 1;
head(iris,50)
iris$flag = 0; iris$flag[iris$Species == 'setosa' & iris$pred == TRUE] = 1;
head(iris,50)
nrow(subset(iris, flag == 1)) / nrow(iris);
nrow(subset(iris, flag == 1)) / nrow(df);
head(x)
head(y)
nrow(y)
length(y)
length(x)
length(x)
length(y)
model = svm(x, y, type = 'one-classification',nu=0.10);
pred = predict(model, subset(iris, select = -Species)); iris$pred = pred; iris$flag = 0; iris$flag[iris$Species == 'setosa' & iris$pred == TRUE] = 1; nrow(subset(iris, flag == 1)) / nrow(df);
head(iris)
nrow(subset(iris, flag == 1)) / nrow(df);
iris$flag[iris$Species == 'setosa' & iris$pred == TRUE] = 1;
pred = predict(model, subset(iris, select = -Species));
library(e1071); data(iris); df = iris; df = subset(df, Species == 'setosa'); x = subset(df, select = -Species); y = df$Species; model = svm(x, y, type = 'one-classification',nu=0.10); print(model); summary(model); pred = predict(model, subset(iris, select = -Species)); iris$pred = pred; iris$flag = 0; iris$flag[iris$Species == 'setosa' & iris$pred == TRUE] = 1; nrow(subset(iris, flag == 1)) / nrow(df);
c(.5,1,2)
c(.5,1,2)
c(.5:2)
c(0.1:1)
seq(.1,1,10)
seq(.1,1,by=0.1)
svm_tune = tune(svm, x, y, type = 'one-classification', ranges = list(gamma = seq(0.05, 1, by = 0.05), nu = seq(0.1, 1, by = 0.1)));
warnings()
library(e1071); data(iris); df = iris; df = subset(df, Species == 'setosa'); x = subset(df, select = -Species); y = df$Species; model = svm(x, y, type = 'one-classification',nu=0.10); print(model); summary(model); pred = predict(model, subset(iris, select = -Species)); iris$pred = pred; iris$flag = 0; iris$flag[iris$Species == 'setosa' & iris$pred == TRUE] = 1; nrow(subset(iris, flag == 1)) / nrow(df); svm_tune = tune(svm, x, y, type = 'one-classification', ranges = list(gamma = seq(0.05, 1, by = 0.05), nu = seq(0.1, 1, by = 0.1)));
print(svm_tune)
svm_tune = tune(svm, x, y, type = 'one-classification', ranges = list(nu = seq(0.1, 1, by = 0.1)));
svm_tune = tune(svm, x, y, type = 'one-classification', nu = seq(0.1, 1, by = 0.1));
print(svm_tune)
svm_tune = tune(svm, x, y, type = 'one-classification', nu = seq(0.1, 1, by = 0.1), gamma = seq(0.05, 1, by = 0.05));
warnings
warnings()
print(svm_tune)
warnings()
head(x)
head(y)
z = as.character(y);
head(y)
head(z)
svm_tune = tune(svm, x, z, type = 'one-classification', nu = seq(0.1, 1, by = 0.1), gamma = seq(0.05, 1, by = 0.05));
unique(z)
z = as.numeric(as.character(y));
z
y
x
y
z
z = 1;
svm_tune = tune(svm, x, z, type = 'one-classification', nu = seq(0.1, 1, by = 0.1), gamma = seq(0.05, 1, by = 0.05));
z
z = 1:50
z
z[1:50] = 1
z
svm_tune = tune(svm, x, z, type = 'one-classification', nu = seq(0.1, 1, by = 0.1), gamma = seq(0.05, 1, by = 0.05));
z
z[1:50] = "setosa";
svm_tune = tune(svm, x, z, type = 'one-classification', nu = seq(0.1, 1, by = 0.1), gamma = seq(0.05, 1, by = 0.05));
z = as.factor(z)
z
svm_tune = tune(svm, x, z, type = 'one-classification', nu = seq(0.1, 1, by = 0.1), gamma = seq(0.05, 1, by = 0.05));
warnings()
print(svm_tune)
svm_tune = tune(svm, x, z, type = 'one-classification', nu = c(0.1,0.2,0.3), gamma = c(0.25,0.5));
svm_tune = tune(svm, x, z, type = 'one-classification', nu = c(0.1,0.2), gamma = c(0.25,0.5));
library(e1071); data(iris); df = iris; df = subset(df, Species == 'setosa'); x = subset(df, select = -Species); y = df$Species; model = svm(x, y, type = 'one-classification',nu=0.10); print(model); summary(model);
print(model); summary(model); pred = predict(model, subset(iris, select = -Species)); iris$pred = pred; iris$flag = 0; iris$flag[iris$Species == 'setosa' & iris$pred == TRUE] = 1; nrow(subset(iris, flag == 1)) / nrow(df);
model = svm(x, y, type = 'one-classification',nu=0.10,gamma=0.5); print(model); summary(model); pred = predict(model, subset(iris, select = -Species));
library(e1071); data(iris); df = iris; df = subset(df, Species == 'setosa'); x = subset(df, select = -Species); y = df$Species; model = svm(x, y, type = 'one-classification',nu=0.10,gamma=0.5); print(model); summary(model); pred = predict(model, subset(iris, select = -Species)); iris$pred = pred; iris$flag = 0; iris$flag[iris$Species == 'setosa' & iris$pred == TRUE] = 1; nrow(subset(iris, flag == 1)) / nrow(df);
svm_tune = tune(svm, x, z, type = 'one-classification', nu = seq(0.1, 1, by = 0.1), gamma = seq(0.05, 1, by = 0.05)); warnings()
z = as.numeric(as.character(z))
z
z = as.character(z)
z
z
z = as.numeric(as.character(y))
z
z = as.character(y)
z
a = as.numeric(z)
a
ls()
svm_tune = tune(svm, x, z, type = 'one-classification', nu = seq(0.1, 1, by = 0.1), gamma = seq(0.05, 1, by = 0.05));
z
svm_tune = tune(svm, Species ~ ., data = iris, type='one-classification', ranges = list(gamma = 2 ^ (-1:1), cost = 2 ^ (2:4)) )
svm_tune
head(iris)
iris$pred =NULL;
iris$flag =NULL;
head(iris)
svm_tune = tune(svm, x, z, type = 'one-classification', nu = seq(0.1, 1, by = 0.1), gamma = seq(0.05, 1, by = 0.05));
svm_tune = tune(svm, x, y, type = 'one-classification', ranges = list(gamma = seq(0.05, 1, by = 0.05), nu = seq(0.1, 1, by = 0.1)));
pred_train = predict(model, x);
pred_test = predict(model, subset(iris, select = -Species));
pred_train
pred_train[pred_train==TRUE]
length(pred_train==TRUE)
length(subset(pred_train,TRUE))
pred_train
filter(pred_train==TRUE)
library(dplyr)
pre_train %>% filter(TRUE) %>% length();
pred_train %>% filter(TRUE) %>% length();
length(pred_train)
pred_train = as.data.frame(pred_train);
str(pred_train)
pred_train = as.data.frame(pred_train);
nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train);
pred_test = iris; iris$pred = pred; iris$flag = 0; iris$flag[iris$Species == 'setosa' & iris$pred == TRUE] = 1; nrow(subset(iris, flag == 1)) / nrow(df);
library(e1071); data(iris); df = iris; df = subset(df, Species == 'setosa'); x = subset(df, select = -Species); y = df$Species; model = svm(x, y, type = 'one-classification',nu=0.10,gamma=0.5); print(model); summary(model); pred_train = predict(model, x);
pred_test = predict(model, subset(iris, select = -Species)); pred_test = iris; iris$pred = pred; iris$flag = 0; iris$flag[iris$Species == 'setosa' & iris$pred == TRUE] = 1; nrow(subset(iris, flag == 1)) / nrow(df); pred_train = as.data.frame(pred_train);
nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train);
library(e1071); data(iris); df = iris; df = subset(df, Species == 'setosa'); x = subset(df, select = -Species); y = df$Species; model = svm(x, y, type = 'one-classification',nu=0.10); print(model); summary(model); pred_train = predict(model, x);
pred_test = predict(model, subset(iris, select = -Species)); pred_test = iris; iris$pred = pred; iris$flag = 0; iris$flag[iris$Species == 'setosa' & iris$pred == TRUE] = 1; nrow(subset(iris, flag == 1)) / nrow(df); pred_train = as.data.frame(pred_train);
nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train);
plot(pred_test,pred_test)
library(shiny) runApp()
plot(pred_test,pred_test)
plot(svm, iris, svSymbol = 1, dataSymbol = 2, symbolPalette = rainbow(4), color.palette = terrain.colors);
plot(pred_test, pred_test, svSymbol = 1, dataSymbol = 2, symbolPalette = rainbow(4), color.palette = terrain.colors);
plot(model, pred_test, svSymbol = 1, dataSymbol = 2, symbolPalette = rainbow(4), color.palette = terrain.colors);
plot(model,iris)
plot(model,pred_test)
model
plot(model,pred_test)
plot(model, pred_test, Sepal.Width = 3, Sepal.Length = 4);
plot(model, pred_test, Petal.Width ~ Petal.Length);
plot(model, iris, Petal.Width ~ Petal.Length);
str(iris)
hist(subset(pred_test,pred==TRUE)$Sepal.Length)
install.packages("caret")
library(caret)
devtools::install_github('topepo/caret/pkg/caret')
install.packages("caret")
library(caret)
install.packages("caret",dependencies = TRUE)
library(caret)
install.packages("DRR")
library(caret)
library(caret); folds = createFolds(subset(iris, select = -Species), k = 10, list = TRUE, returnTrain = FALSE);
str(folds)
folds$Fold1
subset(iris, select = -Species)
iris$pred =NULL;
iris$flag =NULL;
subset(iris, select = -Species)
library(caret); folds = createFolds(subset(iris, select = -Species), k = 10, list = TRUE, returnTrain = FALSE);
folds
iris[folds[[2]],]
iris[folds[[1]],]
ls()
nrow(end_dat)
head(end_dat)
folds = createFolds(end_dat, k = 10, list = TRUE, returnTrain = FALSE);
folds
end_dat[folds[[2]],]
ls()
str(realtime_dat)
str(end_dat)
install.packages("randomForest")
install.packages("MASS")
library(randomForest); library(MASS); attach(Boston); dim(Boston);
set.seed(101); train = sample(1:nrow(Boston), 300);
nrow(Boston)
Boston.rf = randomForest(medv ~ ., data = Boston, subset = train);
Boston.rf;
oob.err = double(13); test.err = double(13); for (mtry in 1:13) {     rf = randomForest(medv ~ ., data = Boston, subset = train, mtry = mtry, ntree = 400);     oob.err[mtry] = rf$mse[400];     pred = predict(rf, Boston[-train,]);     test.err[mtry] = with(Boston.rf[-train,], mean((medv - pred) ^ 2));     cat(mtry," ") }
oob.err = double(13); test.err = double(13); for (mtry in 1:13) {     rf = randomForest(medv ~ ., data = Boston, subset = train, mtry = mtry, ntree = 400);     oob.err[mtry] = rf$mse[400];     pred = predict(rf, Boston[-train,]);     test.err[mtry] = with(Boston[-train,], mean((medv - pred) ^ 2));     cat(mtry," ") }
test.err
oob.err
install.packages("rpart")
library(rpart); data(mcycle); plot(accel ~ times, data = mcycle); mct = rpart(accel ~ times, data = mcycle); plot(mct);
plot(mct);
library(rpart); data(mcycle); plot(accel ~ times, data = mcycle); mct = rpart(accel ~ times, data = mcycle); plot(mct);
mct;
x = cbind(x_train, y_train); fit = rpart(y_train ~ ., data = x, method = "class"); summary(fit); predicted = predict(fit, x_test);
ls()
fit = rpart(times ~ ., data = mcycle, method = "class") summary(fit); predicted = predict(fit, x_test);
fit = rpart(Kyphosis ~ Age + Numer + Start, data = kyphosis);
fit = rpart(Kyphosis ~ Age + Number + Start, data = kyphosis);
fit = rpart(Kyphosis ~ Age + Number + Start, data = kyphosis); fit2 = rpart(Kyphosis ~ Age + Number + Start, data = kyphosis,parms = list(prior=c(.65,.35),split="information")); fit3 = rpart(Kyphosis ~ Age + Number + Start, data = kyphosis, control = rpart.control(cp = 0.05)); par(mfrow = c(1, 2), xpd = NA); plot(fit); test(fit, use.n = TRUE); plot(fit2); test(fit2, use.n = TRUE);
library(rpart); fit = rpart(Kyphosis ~ Age + Number + Start, data = kyphosis); fit2 = rpart(Kyphosis ~ Age + Number + Start, data = kyphosis,parms = list(prior=c(.65,.35),split="information")); fit3 = rpart(Kyphosis ~ Age + Number + Start, data = kyphosis, control = rpart.control(cp = 0.05)); par(mfrow = c(1, 2), xpd = NA); plot(fit); text(fit, use.n = TRUE); plot(fit2); text(fit2, use.n = TRUE);
fit = rpart(Kyphosis ~ Age + Number + Start, data = kyphosis); predict(fit, type = "prob"); predict(fit, type = "vector"); predict(fit, type = "class"); predict(fit, type = "matrix"); sub = c(sample(1:50, 25), sample(51:100, 25), sample(101:150, 25)); fit = rpart(Species ~ ., data = iris, subset = sub); fit; table(predict(fit, iris[-sub,], type = "class"), iris[-sub, "Species"]);
head(iris)
head(iris[-sub,])
nrow(iris[-sub,])
nrow(iris)
nrow(iris[-sub,], iris[-sub, "Species"]);
nrow(iris[-sub, "Species"]);
nrow(iris[-sub]);
nrow(iris[-sub,"Species"]);
iris[-sub,"Species"]
predict(fit, iris[-sub,], type = "class")
head(lipids)
library(caret)
head(lipids)
bacaDanPartisi = function(nama_file) {     #70/30 partition     #column response as y     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     output = createDataPartition(output$response, p = 0.7, list = FALSE, times = 1);     return(output); }
ls()
head(end_dat)
bacaDanPartisi = function(nama_file) {     #70/30 partition     #column response as y     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     output = createDataPartition(output$response, p = 0.7, list = FALSE, times = 1);     return(output); }
nama_file = "Feature-User-Word-Translation-At-the-end-ofproject.csv"; input_data = bacaDanPartisi(nama_file);
bacaDanPartisi = function(nama_file,response_name) {     #70/30 partition     #column response as y     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     colnames(data)[colnames(data) == response_name] = "respon";     output = createDataPartition(output$respon, p = 0.7, list = FALSE, times = 1);     return(output); }
library(dplyr)
bacaDanPartisi = function(nama_file,response_name) {     #70/30 partition     #column response as y     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     colnames(data)[colnames(data) == response_name] = "respon";     output = createDataPartition(output$respon, p = 0.7, list = FALSE, times = 1);     return(output); }
nama_file = "Feature-User-Word-Translation-At-the-end-ofproject.csv"; input_data = bacaDanPartisi(nama_file);
head(iris)
colnames(iris)[colnames(iris) == "Species"] = "respon";
head(iris)
output2 = createDataPartition(output$respon, p = 0.7, list = FALSE, times = 1);
output2 = createDataPartition(iris$respon, p = 0.7, list = FALSE, times = 1);
head(output2)
nama_file = "Feature-User-Word-Translation-At-the-end-ofproject.csv"; input_data = baca(nama_file); #70/30 partition #column response as y colnames(input_data)[colnames(input_data) == response_name] = "respon"; partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1); dataTrain = input_data[partition_data,]; dataTest = input_data[-partition_data,];
baca = function(nama_file) {     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); }
nama_file = "Feature-User-Word-Translation-At-the-end-ofproject.csv"; input_data = baca(nama_file); #70/30 partition #column response as y colnames(input_data)[colnames(input_data) == response_name] = "respon"; partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1); dataTrain = input_data[partition_data,]; dataTest = input_data[-partition_data,];
attach(iris)
iris
head(iris)
nama_file = "Feature-User-Word-Translation-At-the-end-ofproject.csv"; response_name = "respon"; input_data = iris; input_data = baca(nama_file); #70/30 partition #column response as y colnames(input_data)[colnames(input_data) == response_name] = "respon"; partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1); dataTrain = input_data[partition_data,]; dataTest = input_data[-partition_data,];
nama_file = "Feature-User-Word-Translation-At-the-end-ofproject.csv"; response_name = "respon"; input_data = iris; #input_data = baca(nama_file); #70/30 partition #column response as y colnames(input_data)[colnames(input_data) == response_name] = "respon"; partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1); dataTrain = input_data[partition_data,]; dataTest = input_data[-partition_data,];
nrow(dataTrain)
nrow(dataTest)
45/150
head(input_data)
library(e1071); data(iris); df = iris; df = subset(df, Species == 'setosa'); x = subset(df, select = -Species); y = df$Species; model = svm(x, y, type = 'one-classification',nu=0.10); print(model); summary(model); pred_train = predict(model, x); pred_test = predict(model, subset(iris, select = -Species)); pred_test = iris; iris$pred = pred; iris$flag = 0; iris$flag[iris$Species == 'setosa' & iris$pred == TRUE] = 1; nrow(subset(iris, flag == 1)) / nrow(df); pred_train = as.data.frame(pred_train); nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train);
library(e1071); data(iris); df = iris; df = subset(df, Species == 'setosa'); x = subset(df, select = -Species); y = df$Species; model = svm(x, y, type = 'one-classification',nu=0.10);
pred_train = predict(model, x); pred_test = predict(model, subset(iris, select = -Species));
pred_test = iris;
iris$pred = pred;
data(iris)
iris
head(iris)
library(e1071); data(iris); df = iris; df = subset(df, Species == 'setosa'); x = subset(df, select = -Species); y = df$Species; model = svm(x, y, type = 'one-classification',nu=0.10); print(model); summary(model); pred_train = predict(model, x); pred_test = predict(model, subset(iris, select = -Species));
head(pred_train)
head(pred_test)
library(e1071); data(iris); df = iris; df = subset(df, Species == 'setosa'); x = subset(df, select = -Species); y = df$Species; model = svm(x, y, type = 'one-classification',nu=0.10); print(model); summary(model); pred_train = predict(model, x); pred_test = predict(model, subset(iris, select = -Species));
pred = iris; pred$pred = pred_test; pred$flag = 0; pred$flag[pred$Species == 'setosa' & pred$pred == TRUE] = 1; nrow(subset(iris, flag == 1)) / nrow(df);
head(pred)
library(e1071); data(iris); df = iris; df = subset(df, Species == 'setosa'); x = subset(df, select = -Species); y = df$Species; model = svm(x, y, type = 'one-classification',nu=0.10); print(model); summary(model); pred_train = predict(model, x); pred_test = predict(model, subset(iris, select = -Species)); pred_data = iris; pred_data$pred = pred_test; pred_data$flag = 0; pred_data$flag[pred_data$Species == 'setosa' & pred_data$pred == TRUE] = 1; nrow(subset(pred_data, flag == 1)) / nrow(pred_data);
library(e1071); data(iris); df = iris; df = subset(df, Species == 'setosa'); x = subset(df, select = -Species); y = df$Species; model = svm(x, y, type = 'one-classification',nu=0.10); print(model); summary(model); pred_train = predict(model, x); pred_test = predict(model, subset(iris, select = -Species)); pred_data = iris; pred_data$pred = pred_test; pred_data$flag = 0; pred_data$flag[pred_data$Species == 'setosa' & pred_data$pred == TRUE] = 1; nrow(subset(pred_data, flag == 1)) / nrow(pred_data); pred_train = as.data.frame(pred_train); nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train);
head(pred_data)
nrow(pred_data)
length(pred_test)
pred_test
pred_data = iris; pred_data$pred = pred_test; pred_data$flag = 0; pred_data$flag[pred_data$Species == 'setosa' & pred_data$pred == TRUE] = 1; nrow(subset(pred_data, flag == 1)) / nrow(pred_data);
head(pred_test,10)
head(pred_data,10)
head(pred_data,25)
data(iris)
head(iris)
response_name = "respon"; input_data = iris; #input_data = baca(nama_file); #70/30 partition #column response as y colnames(input_data)[colnames(input_data) == response_name] = "respon"; partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1); dataTrain = input_data[partition_data,]; dataTest = input_data[-partition_data,];
head(input_data)
colnames(input_data)[colnames(input_data) == response_name] = "respon";
partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1);
head(input_data)
response_name = "respon"; input_data = iris; #input_data = baca(nama_file); #70/30 partition #column response as y colnames(input_data)[colnames(input_data) == response_name] = "respon"; partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1);
head(input_data)
colnames(input_data)[colnames(input_data) == response_name] = "respon";
head(input_data)
response_name = "Species"; input_data = iris; #input_data = baca(nama_file); #70/30 partition #column response as y colnames(input_data)[colnames(input_data) == response_name] = "respon"; partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1); dataTrain = input_data[partition_data,]; dataTest = input_data[-partition_data,];
train_data = dataTrain
test_data = dataTest
target_respon = 'setosa'
    df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);
    pred_train = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));
    pred_test = test_data;     pred_test$pred = pred;     pred_test$flag = 0;     pred_test$flag[pred_test$respon == 'setosa' & pred_test$pred == TRUE] = 1;     nrow(subset(pred_test, flag == 1)) / nrow(pred_test);     pred_train = as.data.frame(pred_train);     nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train);
head(pred_test)
    df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_train = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     nrow(subset(pred_data, flag == 1)) / nrow(pred_data);     pred_train = as.data.frame(pred_train);     nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train);
nrow(pred_data)
head(pred_data)
tail(pred_data)
    df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_train = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     nrow(subset(pred_data, flag == 1)) / nrow(pred_data);     pred_train = as.data.frame(pred_train);     nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train);
hitungSVM = function(train_data,test_data,target_respon) {     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_train = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(paste("Test Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train = as.data.frame(pred_train);     print(paste("Train Accuracy : ",nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train)));     return(model); }
modelSVM = hitungSVM(dataTrain, dataTest, "setosa");
hitungSVM = function(train_data,test_data,target_respon) {     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_train = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = as.data.frame(pred_train);     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     return(model); }
modelSVM = hitungSVM(dataTrain, dataTest, "setosa");
hitungSVM = function(train_data,test_data,target_respon) {     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_train = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = as.data.frame(pred_train);     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(c(model,train_test_data)); }
modelSVM = hitungSVM(dataTrain, dataTest, "setosa");
train_data = dataTrain;
test_data = dataTest;
target_respon = "setosa";
    df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_train = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = as.data.frame(pred_train);     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);
head(pred_train)
head(pred_data)
    df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = as.data.frame(pred_trains);     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);
head(pred_data)
head(pred_train)
    df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;
head(pred_train)
head(pred_data)
    df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);
    df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);
nrow(train_test_data)
head(train_test_data)
hitungSVM = function(train_data,test_data,target_respon) {     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(c(model,train_test_data)); }
modelSVM = hitungSVM(dataTrain, dataTest, "setosa");
modelSVM
str(modelSVM)
baca = function(nama_file) {     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } hitungSVM = function(train_data,test_data,target_respon) {     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(c(model,train_test_data)); }
baca = function(nama_file) {     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } hitungSVM = function(train_data,test_data,target_respon) {     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); }
nama_file = "Feature TG Whole Duration 10-04-2018.csv";
input_data = baca(nama_file);
head(input_data)
nrow(is.na(input_data))
nrow(input_data)
head(input_data)
input_data[24763:24770,]
nrow(input_data[is.na()],)
nrow(input_data[is.na(input_data)],)
nrow(input_data[is.na(input_data),])
head(input_data[is.na(input_data),])
head(input_data[is.na(input_data)])
head(input_data[is.na(input_data),])
manual = read.csv("C:/manual.csv",stringsAsFactors=FALSE)
head(manual)
str(manual)
nrow(subset(manual,manual$score.for.translation.quality.Yulis==5))
nrow(subset(manual,manual$score.for.translation.quality.Yulis==4))
nrow(subset(manual,manual$score.for.translation.quality.Yulis==3))
nrow(subset(manual,manual$score.for.translation.quality.Yulis==2))
nrow(subset(manual,manual$score.for.translation.quality.Yulis==1))
3714+428+746+312+633
nama_file = "Feature TG Whole Duration 10-04-2018.csv"; response_name = "Species"; input_data = baca(nama_file);
baca = function(nama_file) {     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } hitungSVM = function(train_data,test_data,target_respon) {     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); }
nama_file = "Feature TG Whole Duration 10-04-2018.csv"; response_name = "Species"; input_data = baca(nama_file);
str(input_data)
unique(input_data$user_is_age_25)
unique(input_data$user_is_age_30)
unique(input_data$user_is_age_35)
unique(input_data$user_is_age_40)
unique(input_data$user_is_age_15)
unique(input_data$user_is_age_20)
unique(input_data$user_is_age_0)
nama_file = "Feature TG Whole Duration 10-04-2018.csv"; response_name = "Species"; input_data = baca(nama_file); #Dataset1 = number of vote as target dataset1 = input_data; dataset1$action_vote_down = NULL; dataset1$is_top_translation = NULL;
baca = function(nama_file) {     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } hitungSVM = function(train_data,test_data,target_respon) {     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungDecisionTree = function(input_data) { } hitungRandomForest = function(input_data) { } hitungNaiveBayes = function(input_data) { } ################################# # Main Program ################################# nama_file = "Feature TG Whole Duration 10-04-2018.csv"; response_name = "Species"; input_data = baca(nama_file); #Dataset1 = number of vote as target dataset1 = input_data; dataset1$action_vote_down = NULL; dataset1$is_top_translation = NULL;
baca = function(nama_file) {     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } partisi = function(input_data,response_name) {     #70/30 partition     #column response as y     colnames(input_data)[colnames(input_data) == response_name] = "respon";     partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1);     dataTrain = input_data[partition_data,];     dataTrain$tipe = "training";     dataTest = input_data[-partition_data,];     dataTest$tipe = "testing";     output_data = rbind(dataTrain, dataTest);     return(output_data); } hitungSVM = function(train_data,test_data,target_respon) {     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); }
hist(input_data$action_vote_up)
hist(input_data$action_vote_up)
nrow(subset(input_data,action_vote_up==2))
nrow(subset(input_data,action_vote_up==1))
nrow(subset(input_data,action_vote_up==0))
#Dataset1 = number of vote as target dataset1 = input_data; dataset1$action_vote_down = NULL; dataset1$is_top_translation = NULL; dataset1_part = partisi(dataset1,"action_vote_up"); modelSVM = hitungSVM(dataset1_part, 2);
str(dataset1_par)
str(dataset1_part)
input_data = dataset1_part;
    train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;
    df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;
df = subset(train_data, respon == target_respon);
target_respon = 2;
    df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;
    model = svm(x, y, type = 'one-classification', nu = 0.10);
    library(e1071);
    model = svm(x, y, type = 'one-classification', nu = 0.10);
model
    pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));
    pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));
pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));
    pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;
nrow(test_data)
nrow(train_data)
str(dataset1)
hist(dataset1$user_median_time_to_vote_down)
nrow(subset(dataset1,user_median_time_to_vote_down==0));
nrow(subset(dataset1, user_median_time_to_vote_down < 1));
hist(dataset1$user_median_time_to_vote_down);
str(hist(dataset1$user_median_time_to_vote_down));
dataset1 = input_data; dataset1$action_vote_down = NULL; dataset1$is_top_translation = NULL; #normalization by replace NA with 0 dataset1_norm = dataset1[is.na(dataset1)] = 0; dataset1_part = partisi(dataset1_norm,"action_vote_up");
str(dataset1_norm)
dataset1_norm = dataset1[is.na(dataset1)] = 0;
str(dataset1_norm)
str(dataset1)
library(imputeTS)
install.packages(imputeTS);
install.packages("imputeTS");
library(imputeTS)
#Dataset1 = number of vote as target dataset1 = input_data; dataset1$action_vote_down = NULL; dataset1$is_top_translation = NULL; #normalization by replace NA with 0 dataset1_norm = na.replace(dataset1,0);
nrow(dataset1_norm[is.na(dataset1_norm)])
nrow(is.na(dataset1_norm))
head(dataset1_norm)
nrow(dataset1_norm[is.na(dataset1_norm)])
nrow(subset(dataset1_norm,is.na(dataset1_norm)) ; ; ) ;
nrow(subset(dataset1_norm,is.na(dataset1_norm)))
dataset1_part = partisi(dataset1_norm,"action_vote_up");
input_data = dataset1_part;
target_respon
    library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);
    model = svm(x, y, type = 'one-classification');
model
    pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));
nrow(test_data)
nrow(pred_test)
nrow(pred_train)
nrow(train_data)
str(test_data)
str(subset(test_data, select = -respon))
    pred_test = predict(model, subset(test_data, select = -respon));
str(pred_test)
nrow(pred_test)
length(pred_test)
length(test_data)
nrow(test_data)
    pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));
nrow(pred_train)
nrow(train_data)
print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));
    pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;
length(pred_trains)
nrow(x)
    pred_train = df;     pred_train$pred = pred_trains;     pred_train$flag = 1;
    print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));
head(pred_train)
str(input_data)
hitungSVM = function(input_data,target_respon) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification');     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); }
modelSVM = hitungSVM(dataset1_part, 1);
model
modelSVM = hitungSVM(dataset1_part, 2, 0.1);
modelSVM = hitungSVM(dataset1_part, 2, 0.2); modelSVM = hitungSVM(dataset1_part, 2, 0.3); modelSVM = hitungSVM(dataset1_part, 2, 0.4); modelSVM = hitungSVM(dataset1_part, 2, 0.5); modelSVM = hitungSVM(dataset1_part, 2, 0.6); modelSVM = hitungSVM(dataset1_part, 2, 0.7); modelSVM = hitungSVM(dataset1_part, 2, 0.8); modelSVM = hitungSVM(dataset1_part, 2, 0.9);
hitungSVM = function(input_data,target_respon,nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification',nu=nu_value);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); }
modelSVM = hitungSVM(dataset1_part, 2, 0.1);
modelSVM = hitungSVM(dataset1_part, 2, 0.2); modelSVM = hitungSVM(dataset1_part, 2, 0.3); modelSVM = hitungSVM(dataset1_part, 2, 0.4); modelSVM = hitungSVM(dataset1_part, 2, 0.5); modelSVM = hitungSVM(dataset1_part, 2, 0.6); modelSVM = hitungSVM(dataset1_part, 2, 0.7); modelSVM = hitungSVM(dataset1_part, 2, 0.8); modelSVM = hitungSVM(dataset1_part, 2, 0.9);
modelSVM = hitungSVM(dataset1_part, 1, 0.1); modelSVM = hitungSVM(dataset1_part, 0, 0.1);
modelSVM = hitungSVM(dataset1_part, 2, 0.1); modelSVM = hitungSVM(dataset1_part, 1, 0.1); modelSVM = hitungSVM(dataset1_part, 0, 0.1);
modelSVM = hitungSVM(dataset1_part, 1, 0.1);
modelSVM = hitungSVM(dataset1_part, 1, 0.5); modelSVM = hitungSVM(dataset1_part, 0, 0.1);
modelSVM = hitungSVM(dataset1_part, 0, 0.5);
hist(subset(dataset1_part, tipe == "training")); hist(subset(dataset1_part, tipe == "testing"));
str(dataset1_part)
hist(subset(dataset1_part, tipe == "training")$respon); hist(subset(dataset1_part, tipe == "testing")$respon);
hist(subset(dataset1_part, tipe == "training")$respon);
head(input_data)
    library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;
model = svm(x, y, probability=TRUE);
data(iris) attach(iris) x = subset(iris, select = -Species); y = Species; model = svm(x, y, probability=TRUE);
pred_prob = predict(model, x, decision.values = TRUE, probability = TRUE);
pred_prob
str(iris)
str(input_data)
    library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data);     x = subset(df, select = -respon);     y = as.factor(df$respon);
head(x)
head(y)
nrow(df,respon==1)
nrow(subset(df,respon==1))
nrow(subset(df,respon==0))
nrow(subset(df,respon==2))
nrow(subset(df,respon==3))
nrow(subset(df,respon==4))
    model = svm(x, y, probability = TRUE);     pred_prob = predict(model, x, decision.values = TRUE, probability = TRUE);
nrow(pred_probs)
nrow(pred_prob)
length(pred_prob)
nrow(train)
nrow(train_data)
head(pred_prob)
str(pred_prob)
model
str(pred_prob)
str(input_data)
head(input_data)
head(input_data$respon)
head(attr(pred_prob,"probabilities"))
str(pred_train)
pred_train = predict(model, x, decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon),decision.values = TRUE, probability = TRUE); str(pred_train)
str(pred_train)
str(pred_test)
str(attr(pred_prob,"probabilities"))
str(attr(pred_prob,"probabilities")[1])
str(attr(pred_prob,"probabilities")[,1])
str(attr(pred_prob,"probabilities")[,2])
str(attr(pred_prob,"probabilities")[,0])
str(attr(pred_prob,"probabilities")[,1])
str(attr(pred_prob,"probabilities")[,2])
str(attr(pred_prob,"probabilities")[,1])
head(attr(pred_prob,"probabilities")[,1])
head(attr(pred_prob,"probabilities")[1])
head(attr(pred_prob,"probabilities"))
head(attr(pred_prob,"probabilities")[,1])
    pred_train_value = attr(pred_train, "probabilities");     pred_test_value = attr(pred_test, "probabilities");
head(attr(pred_prob,"decision.values"))
head(pred_train_value)
head(pred_train_value$0)
str(pred_train_value)
head(pred_train_value[,1])
head(pred_train_value[,0])
head(pred_train_value[,0])     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }             pred_train_value$pred[i] = max_pos;         }     }
str(pred_train_value)
str(pred_train_value)    #normalization and find specific prediction value      pred_train_value = attr(pred_train, "probabilities");     pred_test_value = attr(pred_test, "probabilities");
    pred_train_value = attr(pred_train, "probabilities");     pred_test_value = attr(pred_test, "probabilities");
str(pred_train_value)
    pred_train_value[,6] = -1;
    #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));
str(pred_train_value)
    pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }             pred_train_value$pred[i] = max_pos;         }     }
    pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train$0[i];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }             pred_train_value$pred[i] = max_pos;         }     }
    pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value$0[i];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }             pred_train_value$pred[i] = max_pos;         }     }
pred_train = predict(model, x, decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon),decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value$0[i];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }             pred_train_value$pred[i] = max_pos;         }     }
    pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value$0[i];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }             pred_train_value$pred[i] = max_pos;         }     }
    pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;
head(pred_train)
head(pred_train_value)
pred_train_value[1,2]
pred_train_value[0,2]
pred_train_value[1,2]
pred_train_value[1,1]
pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i,1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }
head(pred_train_value)
    pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }
head(pred_test_value)
    pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;
head(pred_data)
    pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;
print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));
pred_train = df;     pred_train$pred = pred_trains_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;
    pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;
print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));
print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));
model
library(imputeTS); nama_file = "Features with Manual Assessment.csv"; input_data = baca(nama_file);
################################# # Fungsi dan Prosedur ################################# baca = function(nama_file) {     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } partisi = function(input_data,response_name) {     #70/30 partition     #column response as y     colnames(input_data)[colnames(input_data) == response_name] = "respon";     partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1);     dataTrain = input_data[partition_data,];     dataTrain$tipe = "training";     dataTest = input_data[-partition_data,];     dataTest$tipe = "testing";     output_data = rbind(dataTrain, dataTest);     return(output_data); } hitungSVM = function(input_data,target_respon,nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification',nu=nu_value);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM-multi = function(input_data, target_respon, nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data);     x = subset(df, select = -respon);     y = as.factor(df$respon);     model = svm(x, y, probability = TRUE);     pred_train = predict(model, x, decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon),decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i,1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); }
hitungSVM-multi = function(input_data, target_respon, nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data);     x = subset(df, select = -respon);     y = as.factor(df$respon);     model = svm(x, y, probability = TRUE);     pred_train = predict(model, x, decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon),decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i,1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); }
hitungSVM_multi = function(input_data, target_respon, nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data);     x = subset(df, select = -respon);     y = as.factor(df$respon);     model = svm(x, y, probability = TRUE);     pred_train = predict(model, x, decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon),decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i,1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); }
baca = function(nama_file) {     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } partisi = function(input_data,response_name) {     #70/30 partition     #column response as y     colnames(input_data)[colnames(input_data) == response_name] = "respon";     partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1);     dataTrain = input_data[partition_data,];     dataTrain$tipe = "training";     dataTest = input_data[-partition_data,];     dataTest$tipe = "testing";     output_data = rbind(dataTrain, dataTest);     return(output_data); } hitungSVM = function(input_data,target_respon,nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification',nu=nu_value);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); }
library(imputeTS); nama_file = "Features with Manual Assessment.csv"; input_data = baca(nama_file);
dataset1 = input_data; dataset1_assessed = dataset1 %>% filter(is.na(manual_assessment)) %>% as.data.frame(); #normalization by replace NA with 0 dataset1_norm = na.replace(dataset1_assessed,0);
library(dplyr);
dataset1 = input_data; dataset1_assessed = dataset1 %>% filter(is.na(manual_assessment)) %>% as.data.frame(); #normalization by replace NA with 0 dataset1_norm = na.replace(dataset1_assessed,0);
nrow(dataset1_norm)
nrow(dataset1)
dataset1_part = partisi(dataset1_norm, "manual_assessment"); hist(subset(dataset1_part, tipe == "training")$respon); hist(subset(dataset1_part, tipe == "testing")$respon);
str(dataset1_assessed)
#Dataset1 = manual_assessment as target dataset1 = input_data; dataset1_assessed = dataset1 %>% filter(!is.na(manual_assessment)) %>% as.data.frame(); #normalization by replace NA with 0 dataset1_norm = na.replace(dataset1_assessed,0); dataset1_part = partisi(dataset1_norm, "manual_assessment"); hist(subset(dataset1_part, tipe == "training")$respon); hist(subset(dataset1_part, tipe == "testing")$respon);
hist(subset(dataset1_part, tipe == "training")$respon); hist(subset(dataset1_part, tipe == "testing")$respon);
hist(subset(dataset1_part, tipe == "training")$respon);
dataset1_part %>% group_by(tipe,manual_assessment) %>% summarise(jumlah_data=n()) %>% as.data.frame();
dataset1_part %>% group_by(tipe,manual_assessment) %>% summarise(jumlah_data=n()) %>% as.data.frame();
str(dataset1_part)
dataset1_part %>% group_by(tipe,respon) %>% summarise(jumlah_data=n()) %>% as.data.frame();
modelSVM = hitungSVM(dataset1_part, 5, 0.1);
input_data = dataset1_part;
target_respon = 5;
nu_value=0.1
    library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification',nu=nu_value);
library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;
head(x)
head(y)
nrow(x)
nrow(y)
length(y)
model = svm(x, y, type = 'one-classification',nu=nu_value);
model
nu_value
model = svm(x, y, type = 'one-classification');
dataset1 = input_data; dataset1$username = NULL; dataset1$source.word = NULL; dataset1$target.word = NULL; dataset1_assessed = dataset1 %>% filter(!is.na(manual_assessment)) %>% as.data.frame(); #normalization by replace NA with 0 dataset1_norm = na.replace(dataset1_assessed,0); dataset1_part = partisi(dataset1_norm, "manual_assessment"); dataset1_part %>% group_by(tipe,respon) %>% summarise(jumlah_data=n()) %>% as.data.frame(); hist(subset(dataset1_part, tipe == "training")$respon); hist(subset(dataset1_part, tipe == "testing")$respon); modelSVM = hitungSVM(dataset1_part, 5, 0.1);
str(dataset1_part)
#Dataset1 = manual_assessment as target dataset1 = input_data; dataset1$username = NULL; dataset1$source.word = NULL; dataset1$target.word = NULL; dataset1_assessed = dataset1 %>% filter(!is.na(manual_assessment)) %>% as.data.frame();
dataset1 = input_data; dataset1$username = NULL; dataset1$source.word = NULL; dataset1$target.word = NULL;
str(input_data)
input_data = baca(nama_file); #Dataset1 = manual_assessment as target dataset1 = input_data; dataset1$username = NULL; dataset1$source.word = NULL; dataset1$target.word = NULL; dataset1_assessed = dataset1 %>% filter(!is.na(manual_assessment)) %>% as.data.frame(); #normalization by replace NA with 0 dataset1_norm = na.replace(dataset1_assessed,0); dataset1_part = partisi(dataset1_norm, "manual_assessment"); dataset1_part %>% group_by(tipe,respon) %>% summarise(jumlah_data=n()) %>% as.data.frame(); hist(subset(dataset1_part, tipe == "training")$respon); hist(subset(dataset1_part, tipe == "testing")$respon); modelSVM = hitungSVM(dataset1_part, 5, 0.1);
modelSVM = hitungSVM(dataset1_part, 5, 0.5);
ls()
str(input_data)
str(dataset1_part)
train_data = subset(input_data, tipe == "training"); train_data$tipe = NULL; test_data = subset(input_data, tipe == "testing"); test_data$tipe = NULL; model = naiveBayes(respon ~ ., data = train_data); class(model); summary(model); print(model);
str(train_data)
input_data = dataset1_part;
train_data = subset(input_data, tipe == "training"); train_data$tipe = NULL; test_data = subset(input_data, tipe == "testing"); test_data$tipe = NULL;
model = naiveBayes(respon ~ ., data = train_data); class(model); summary(model);
preds = predict(model, newdata = test_data);
conf_matrix = table(preds, test_data$respon);
preds = predict(model, newdata = test_data); conf_matrix = table(preds, test_data$respon);
nrow(test_data)
preds(test_data)
preds = predict(model, newdata = test_data); conf_matrix = table(preds, test_data$respon);preds = predict(model, newdata = subset(test_data,select=-respon)); conf_matrix = table(preds, test_data$respon);
preds = predict(model, newdata = subset(test_data,select=-respon));
str(preds)
model <- naiveBayes(class ~ ., data = breast_cancer) class(model) summary(model) print(model) preds = predict(model, newdata = breast_cancer);
attach(breast_cance)
attach(breast_cancer)
install.packages("mlbench")
library(mlbench)
data(HouseVotes84, package = "mlbench") model <- naiveBayes(Class ~ ., data = HouseVotes84)
str(HouseVotes84)
pred <- predict(model, HouseVotes84) table(pred, HouseVotes84$Class)
head(pred)
length(pred)
nrow(HouseVotes84)
preds = predict(model, newdata = subset(test_data,select=-respon)); conf_matrix = table(preds, test_data$respon);
length(preds)
length(test_data$respon)
conf_matrix
str(train_data)
model = naiveBayes(respon ~ ., data = train_data);
preds = predict(model, newdata=test_data); conf_matrix = table(preds, test_data$respon);
preds
model
model = naiveBayes(respon ~ ., data = train_data); preds = predict(model, newdata=test_data); conf_matrix = table(preds, test_data$respon);
str(test_data)
str(train_data)
pred
str(test_data)
train_data$respon = as.factor(train_data$respon); test_data$respon = as.factor(test_data$respon);
model = naiveBayes(respon ~ ., data = train_data); preds = predict(model, newdata=test_data); conf_matrix = table(preds, test_data$respon);
lenth(preds)
length(preds)
conf_matrix
model = naiveBayes(respon ~ ., data = train_data); preds = predict(model, newdata=test_data); conf_matrix = table(preds, test_data$respon); model = naiveBayes(respon ~ ., data = train_data, laplace = 3); preds = predict(model, newdata = test_data); conf_matrix = table(preds, test_data$respon);
model = naiveBayes(respon ~ ., data = train_data); preds = predict(model, newdata=test_data); conf_matrix = table(preds, test_data$respon); conf_matrix; model = naiveBayes(respon ~ ., data = train_data, laplace = 3); preds = predict(model, newdata = test_data); conf_matrix = table(preds, test_data$respon); conf_matrix;
model = naiveBayes(respon ~ ., data = train_data); preds = predict(model, newdata=test_data); conf_matrix = table(preds, test_data$respon); conf_matrix; model = naiveBayes(respon ~ ., data = train_data, laplace = 1); preds = predict(model, newdata = test_data); conf_matrix = table(preds, test_data$respon); conf_matrix; model = naiveBayes(respon ~ ., data = train_data, laplace = 2); preds = predict(model, newdata = test_data); conf_matrix = table(preds, test_data$respon); conf_matrix; model = naiveBayes(respon ~ ., data = train_data, laplace = 3); preds = predict(model, newdata = test_data); conf_matrix = table(preds, test_data$respon); conf_matrix;
modelSVM = hitungSVM(dataset1_part, 5, 0.1); modelSVM = hitungSVM(dataset1_part, 4, 0.1); modelSVM = hitungSVM(dataset1_part, 3, 0.1); modelSVM = hitungSVM(dataset1_part, 2, 0.1); modelSVM = hitungSVM(dataset1_part, 1, 0.1); modelSVM = hitungSVM(dataset1_part, 0, 0.1);
modelSVM = hitungSVM(dataset1_part, 1, 0.5);
modelSVM = hitungSVM(dataset1_part, 1, 0.9);
