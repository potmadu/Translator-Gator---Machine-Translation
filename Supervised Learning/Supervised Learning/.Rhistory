getwd()
realtime_dat = read.csv("dataset/Feature-User-Word-Translation-Realtime.csv"); end_dat = read.csv("dataset/Feature-User-Word-Translation-At-the-end-ofproject.csv"); manual_check = read.csv("dataset/Manual quality check TG2.csv");
realtime_dat = read.csv("Dataset/Feature-User-Word-Translation-Realtime.csv"); end_dat = read.csv("Dataset/Feature-User-Word-Translation-At-the-end-ofproject.csv"); manual_check = read.csv("Dataset/Manual quality check TG2.csv");
getwd()
realtime_dat = read.csv("Dataset/Feature-User-Word-Translation-Realtime.csv"); end_dat = read.csv("Dataset/Feature-User-Word-Translation-At-the-end-ofproject.csv"); manual_check = read.csv("Dataset/Manual quality check TG2.csv");
getwd()
realtime_dat = read.csv("Dataset/Feature-User-Word-Translation-Realtime.csv"); end_dat = read.csv("Dataset/Feature-User-Word-Translation-At-the-end-ofproject.csv"); manual_check = read.csv("Dataset/Manual quality check TG2.csv");
realtime_dat = read.csv("Dataset/Feature-User-Word-Translation-Realtime.csv"); end_dat = read.csv("Dataset/Feature-User-Word-Translation-At-the-end-ofproject.csv"); manual_check = read.csv("Dataset/Manual quality check TG2.csv");
head(realtime_dat)
realtime_dat = read.csv("Dataset/Feature-User-Word-Translation-Realtime.csv", stringsAsFactors = FALSE); end_dat = read.csv("Dataset/Feature-User-Word-Translation-At-the-end-ofproject.csv", stringsAsFactors = FALSE); manual_check = read.csv("Dataset/Manual quality check TG2.csv", stringsAsFactors = FALSE);
str(realtime_dat)
str(end_dat)
str(manual_check)
head(manual_check)
str(manual_check)
manual_check2 = manual_check[, 1:19];
str(manual_check)
str(manual_check2)
manual_check = manual_check[, 1:19];
ls()
ls()
install.packages("e1071")
install.packages("e1071")
library(e1071);
data(iris);
df = iris;
df = subset(df, Species == 'setosa');
x = subset(df, select = -Species);
y = df$Species;
model = svm(x, y, type = 'one-classification');
print(model)
summary(model);
pred = predict(model, subset(iris, select = -Species));
pred
df
iris$pred = pred;
head(iris)
head(iris,50)
unique(iris$Species)
iris$flag[iris$pred == 'setosa' && iris$pred == TRUE,] = 1;
iris$flag[iris$Species == 'setosa' && iris$pred == TRUE] = 1;
nrow(subset(iris, flag == 1)) / nrow(iris);
head(iris,50)
iris$flag[iris$Species == 'setosa' & iris$pred == TRUE] = 1;
iris$flag = 0; iris$flag[iris$Species == 'setosa' && iris$pred == TRUE] = 1;
head(iris,50)
iris$flag = 0; iris$flag[iris$Species == 'setosa' & iris$pred == TRUE] = 1;
head(iris,50)
nrow(subset(iris, flag == 1)) / nrow(iris);
nrow(subset(iris, flag == 1)) / nrow(df);
head(x)
head(y)
nrow(y)
length(y)
length(x)
length(x)
length(y)
model = svm(x, y, type = 'one-classification',nu=0.10);
pred = predict(model, subset(iris, select = -Species)); iris$pred = pred; iris$flag = 0; iris$flag[iris$Species == 'setosa' & iris$pred == TRUE] = 1; nrow(subset(iris, flag == 1)) / nrow(df);
head(iris)
nrow(subset(iris, flag == 1)) / nrow(df);
iris$flag[iris$Species == 'setosa' & iris$pred == TRUE] = 1;
pred = predict(model, subset(iris, select = -Species));
library(e1071); data(iris); df = iris; df = subset(df, Species == 'setosa'); x = subset(df, select = -Species); y = df$Species; model = svm(x, y, type = 'one-classification',nu=0.10); print(model); summary(model); pred = predict(model, subset(iris, select = -Species)); iris$pred = pred; iris$flag = 0; iris$flag[iris$Species == 'setosa' & iris$pred == TRUE] = 1; nrow(subset(iris, flag == 1)) / nrow(df);
c(.5,1,2)
c(.5,1,2)
c(.5:2)
c(0.1:1)
seq(.1,1,10)
seq(.1,1,by=0.1)
svm_tune = tune(svm, x, y, type = 'one-classification', ranges = list(gamma = seq(0.05, 1, by = 0.05), nu = seq(0.1, 1, by = 0.1)));
warnings()
library(e1071); data(iris); df = iris; df = subset(df, Species == 'setosa'); x = subset(df, select = -Species); y = df$Species; model = svm(x, y, type = 'one-classification',nu=0.10); print(model); summary(model); pred = predict(model, subset(iris, select = -Species)); iris$pred = pred; iris$flag = 0; iris$flag[iris$Species == 'setosa' & iris$pred == TRUE] = 1; nrow(subset(iris, flag == 1)) / nrow(df); svm_tune = tune(svm, x, y, type = 'one-classification', ranges = list(gamma = seq(0.05, 1, by = 0.05), nu = seq(0.1, 1, by = 0.1)));
print(svm_tune)
svm_tune = tune(svm, x, y, type = 'one-classification', ranges = list(nu = seq(0.1, 1, by = 0.1)));
svm_tune = tune(svm, x, y, type = 'one-classification', nu = seq(0.1, 1, by = 0.1));
print(svm_tune)
svm_tune = tune(svm, x, y, type = 'one-classification', nu = seq(0.1, 1, by = 0.1), gamma = seq(0.05, 1, by = 0.05));
warnings
warnings()
print(svm_tune)
warnings()
head(x)
head(y)
z = as.character(y);
head(y)
head(z)
svm_tune = tune(svm, x, z, type = 'one-classification', nu = seq(0.1, 1, by = 0.1), gamma = seq(0.05, 1, by = 0.05));
unique(z)
z = as.numeric(as.character(y));
z
y
x
y
z
z = 1;
svm_tune = tune(svm, x, z, type = 'one-classification', nu = seq(0.1, 1, by = 0.1), gamma = seq(0.05, 1, by = 0.05));
z
z = 1:50
z
z[1:50] = 1
z
svm_tune = tune(svm, x, z, type = 'one-classification', nu = seq(0.1, 1, by = 0.1), gamma = seq(0.05, 1, by = 0.05));
z
z[1:50] = "setosa";
svm_tune = tune(svm, x, z, type = 'one-classification', nu = seq(0.1, 1, by = 0.1), gamma = seq(0.05, 1, by = 0.05));
z = as.factor(z)
z
svm_tune = tune(svm, x, z, type = 'one-classification', nu = seq(0.1, 1, by = 0.1), gamma = seq(0.05, 1, by = 0.05));
warnings()
print(svm_tune)
svm_tune = tune(svm, x, z, type = 'one-classification', nu = c(0.1,0.2,0.3), gamma = c(0.25,0.5));
svm_tune = tune(svm, x, z, type = 'one-classification', nu = c(0.1,0.2), gamma = c(0.25,0.5));
library(e1071); data(iris); df = iris; df = subset(df, Species == 'setosa'); x = subset(df, select = -Species); y = df$Species; model = svm(x, y, type = 'one-classification',nu=0.10); print(model); summary(model);
print(model); summary(model); pred = predict(model, subset(iris, select = -Species)); iris$pred = pred; iris$flag = 0; iris$flag[iris$Species == 'setosa' & iris$pred == TRUE] = 1; nrow(subset(iris, flag == 1)) / nrow(df);
model = svm(x, y, type = 'one-classification',nu=0.10,gamma=0.5); print(model); summary(model); pred = predict(model, subset(iris, select = -Species));
library(e1071); data(iris); df = iris; df = subset(df, Species == 'setosa'); x = subset(df, select = -Species); y = df$Species; model = svm(x, y, type = 'one-classification',nu=0.10,gamma=0.5); print(model); summary(model); pred = predict(model, subset(iris, select = -Species)); iris$pred = pred; iris$flag = 0; iris$flag[iris$Species == 'setosa' & iris$pred == TRUE] = 1; nrow(subset(iris, flag == 1)) / nrow(df);
svm_tune = tune(svm, x, z, type = 'one-classification', nu = seq(0.1, 1, by = 0.1), gamma = seq(0.05, 1, by = 0.05)); warnings()
z = as.numeric(as.character(z))
z
z = as.character(z)
z
z
z = as.numeric(as.character(y))
z
z = as.character(y)
z
a = as.numeric(z)
a
ls()
svm_tune = tune(svm, x, z, type = 'one-classification', nu = seq(0.1, 1, by = 0.1), gamma = seq(0.05, 1, by = 0.05));
z
svm_tune = tune(svm, Species ~ ., data = iris, type='one-classification', ranges = list(gamma = 2 ^ (-1:1), cost = 2 ^ (2:4)) )
svm_tune
head(iris)
iris$pred =NULL;
iris$flag =NULL;
head(iris)
svm_tune = tune(svm, x, z, type = 'one-classification', nu = seq(0.1, 1, by = 0.1), gamma = seq(0.05, 1, by = 0.05));
svm_tune = tune(svm, x, y, type = 'one-classification', ranges = list(gamma = seq(0.05, 1, by = 0.05), nu = seq(0.1, 1, by = 0.1)));
pred_train = predict(model, x);
pred_test = predict(model, subset(iris, select = -Species));
pred_train
pred_train[pred_train==TRUE]
length(pred_train==TRUE)
length(subset(pred_train,TRUE))
pred_train
filter(pred_train==TRUE)
library(dplyr)
pre_train %>% filter(TRUE) %>% length();
pred_train %>% filter(TRUE) %>% length();
length(pred_train)
pred_train = as.data.frame(pred_train);
str(pred_train)
pred_train = as.data.frame(pred_train);
nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train);
pred_test = iris; iris$pred = pred; iris$flag = 0; iris$flag[iris$Species == 'setosa' & iris$pred == TRUE] = 1; nrow(subset(iris, flag == 1)) / nrow(df);
library(e1071); data(iris); df = iris; df = subset(df, Species == 'setosa'); x = subset(df, select = -Species); y = df$Species; model = svm(x, y, type = 'one-classification',nu=0.10,gamma=0.5); print(model); summary(model); pred_train = predict(model, x);
pred_test = predict(model, subset(iris, select = -Species)); pred_test = iris; iris$pred = pred; iris$flag = 0; iris$flag[iris$Species == 'setosa' & iris$pred == TRUE] = 1; nrow(subset(iris, flag == 1)) / nrow(df); pred_train = as.data.frame(pred_train);
nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train);
library(e1071); data(iris); df = iris; df = subset(df, Species == 'setosa'); x = subset(df, select = -Species); y = df$Species; model = svm(x, y, type = 'one-classification',nu=0.10); print(model); summary(model); pred_train = predict(model, x);
pred_test = predict(model, subset(iris, select = -Species)); pred_test = iris; iris$pred = pred; iris$flag = 0; iris$flag[iris$Species == 'setosa' & iris$pred == TRUE] = 1; nrow(subset(iris, flag == 1)) / nrow(df); pred_train = as.data.frame(pred_train);
nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train);
plot(pred_test,pred_test)
library(shiny) runApp()
plot(pred_test,pred_test)
plot(svm, iris, svSymbol = 1, dataSymbol = 2, symbolPalette = rainbow(4), color.palette = terrain.colors);
plot(pred_test, pred_test, svSymbol = 1, dataSymbol = 2, symbolPalette = rainbow(4), color.palette = terrain.colors);
plot(model, pred_test, svSymbol = 1, dataSymbol = 2, symbolPalette = rainbow(4), color.palette = terrain.colors);
plot(model,iris)
plot(model,pred_test)
model
plot(model,pred_test)
plot(model, pred_test, Sepal.Width = 3, Sepal.Length = 4);
plot(model, pred_test, Petal.Width ~ Petal.Length);
plot(model, iris, Petal.Width ~ Petal.Length);
str(iris)
hist(subset(pred_test,pred==TRUE)$Sepal.Length)
install.packages("caret")
library(caret)
devtools::install_github('topepo/caret/pkg/caret')
install.packages("caret")
library(caret)
install.packages("caret",dependencies = TRUE)
library(caret)
install.packages("DRR")
library(caret)
library(caret); folds = createFolds(subset(iris, select = -Species), k = 10, list = TRUE, returnTrain = FALSE);
str(folds)
folds$Fold1
subset(iris, select = -Species)
iris$pred =NULL;
iris$flag =NULL;
subset(iris, select = -Species)
library(caret); folds = createFolds(subset(iris, select = -Species), k = 10, list = TRUE, returnTrain = FALSE);
folds
iris[folds[[2]],]
iris[folds[[1]],]
ls()
nrow(end_dat)
head(end_dat)
folds = createFolds(end_dat, k = 10, list = TRUE, returnTrain = FALSE);
folds
end_dat[folds[[2]],]
ls()
str(realtime_dat)
str(end_dat)
install.packages("randomForest")
install.packages("MASS")
library(randomForest); library(MASS); attach(Boston); dim(Boston);
set.seed(101); train = sample(1:nrow(Boston), 300);
nrow(Boston)
Boston.rf = randomForest(medv ~ ., data = Boston, subset = train);
Boston.rf;
oob.err = double(13); test.err = double(13); for (mtry in 1:13) {     rf = randomForest(medv ~ ., data = Boston, subset = train, mtry = mtry, ntree = 400);     oob.err[mtry] = rf$mse[400];     pred = predict(rf, Boston[-train,]);     test.err[mtry] = with(Boston.rf[-train,], mean((medv - pred) ^ 2));     cat(mtry," ") }
oob.err = double(13); test.err = double(13); for (mtry in 1:13) {     rf = randomForest(medv ~ ., data = Boston, subset = train, mtry = mtry, ntree = 400);     oob.err[mtry] = rf$mse[400];     pred = predict(rf, Boston[-train,]);     test.err[mtry] = with(Boston[-train,], mean((medv - pred) ^ 2));     cat(mtry," ") }
test.err
oob.err
install.packages("rpart")
library(rpart); data(mcycle); plot(accel ~ times, data = mcycle); mct = rpart(accel ~ times, data = mcycle); plot(mct);
plot(mct);
library(rpart); data(mcycle); plot(accel ~ times, data = mcycle); mct = rpart(accel ~ times, data = mcycle); plot(mct);
mct;
x = cbind(x_train, y_train); fit = rpart(y_train ~ ., data = x, method = "class"); summary(fit); predicted = predict(fit, x_test);
ls()
fit = rpart(times ~ ., data = mcycle, method = "class") summary(fit); predicted = predict(fit, x_test);
fit = rpart(Kyphosis ~ Age + Numer + Start, data = kyphosis);
fit = rpart(Kyphosis ~ Age + Number + Start, data = kyphosis);
fit = rpart(Kyphosis ~ Age + Number + Start, data = kyphosis); fit2 = rpart(Kyphosis ~ Age + Number + Start, data = kyphosis,parms = list(prior=c(.65,.35),split="information")); fit3 = rpart(Kyphosis ~ Age + Number + Start, data = kyphosis, control = rpart.control(cp = 0.05)); par(mfrow = c(1, 2), xpd = NA); plot(fit); test(fit, use.n = TRUE); plot(fit2); test(fit2, use.n = TRUE);
library(rpart); fit = rpart(Kyphosis ~ Age + Number + Start, data = kyphosis); fit2 = rpart(Kyphosis ~ Age + Number + Start, data = kyphosis,parms = list(prior=c(.65,.35),split="information")); fit3 = rpart(Kyphosis ~ Age + Number + Start, data = kyphosis, control = rpart.control(cp = 0.05)); par(mfrow = c(1, 2), xpd = NA); plot(fit); text(fit, use.n = TRUE); plot(fit2); text(fit2, use.n = TRUE);
fit = rpart(Kyphosis ~ Age + Number + Start, data = kyphosis); predict(fit, type = "prob"); predict(fit, type = "vector"); predict(fit, type = "class"); predict(fit, type = "matrix"); sub = c(sample(1:50, 25), sample(51:100, 25), sample(101:150, 25)); fit = rpart(Species ~ ., data = iris, subset = sub); fit; table(predict(fit, iris[-sub,], type = "class"), iris[-sub, "Species"]);
head(iris)
head(iris[-sub,])
nrow(iris[-sub,])
nrow(iris)
nrow(iris[-sub,], iris[-sub, "Species"]);
nrow(iris[-sub, "Species"]);
nrow(iris[-sub]);
nrow(iris[-sub,"Species"]);
iris[-sub,"Species"]
predict(fit, iris[-sub,], type = "class")
head(lipids)
library(caret)
head(lipids)
bacaDanPartisi = function(nama_file) {     #70/30 partition     #column response as y     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     output = createDataPartition(output$response, p = 0.7, list = FALSE, times = 1);     return(output); }
ls()
head(end_dat)
bacaDanPartisi = function(nama_file) {     #70/30 partition     #column response as y     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     output = createDataPartition(output$response, p = 0.7, list = FALSE, times = 1);     return(output); }
nama_file = "Feature-User-Word-Translation-At-the-end-ofproject.csv"; input_data = bacaDanPartisi(nama_file);
bacaDanPartisi = function(nama_file,response_name) {     #70/30 partition     #column response as y     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     colnames(data)[colnames(data) == response_name] = "respon";     output = createDataPartition(output$respon, p = 0.7, list = FALSE, times = 1);     return(output); }
library(dplyr)
bacaDanPartisi = function(nama_file,response_name) {     #70/30 partition     #column response as y     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     colnames(data)[colnames(data) == response_name] = "respon";     output = createDataPartition(output$respon, p = 0.7, list = FALSE, times = 1);     return(output); }
nama_file = "Feature-User-Word-Translation-At-the-end-ofproject.csv"; input_data = bacaDanPartisi(nama_file);
head(iris)
colnames(iris)[colnames(iris) == "Species"] = "respon";
head(iris)
output2 = createDataPartition(output$respon, p = 0.7, list = FALSE, times = 1);
output2 = createDataPartition(iris$respon, p = 0.7, list = FALSE, times = 1);
head(output2)
nama_file = "Feature-User-Word-Translation-At-the-end-ofproject.csv"; input_data = baca(nama_file); #70/30 partition #column response as y colnames(input_data)[colnames(input_data) == response_name] = "respon"; partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1); dataTrain = input_data[partition_data,]; dataTest = input_data[-partition_data,];
baca = function(nama_file) {     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); }
nama_file = "Feature-User-Word-Translation-At-the-end-ofproject.csv"; input_data = baca(nama_file); #70/30 partition #column response as y colnames(input_data)[colnames(input_data) == response_name] = "respon"; partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1); dataTrain = input_data[partition_data,]; dataTest = input_data[-partition_data,];
attach(iris)
iris
head(iris)
nama_file = "Feature-User-Word-Translation-At-the-end-ofproject.csv"; response_name = "respon"; input_data = iris; input_data = baca(nama_file); #70/30 partition #column response as y colnames(input_data)[colnames(input_data) == response_name] = "respon"; partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1); dataTrain = input_data[partition_data,]; dataTest = input_data[-partition_data,];
nama_file = "Feature-User-Word-Translation-At-the-end-ofproject.csv"; response_name = "respon"; input_data = iris; #input_data = baca(nama_file); #70/30 partition #column response as y colnames(input_data)[colnames(input_data) == response_name] = "respon"; partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1); dataTrain = input_data[partition_data,]; dataTest = input_data[-partition_data,];
nrow(dataTrain)
nrow(dataTest)
45/150
head(input_data)
library(e1071); data(iris); df = iris; df = subset(df, Species == 'setosa'); x = subset(df, select = -Species); y = df$Species; model = svm(x, y, type = 'one-classification',nu=0.10); print(model); summary(model); pred_train = predict(model, x); pred_test = predict(model, subset(iris, select = -Species)); pred_test = iris; iris$pred = pred; iris$flag = 0; iris$flag[iris$Species == 'setosa' & iris$pred == TRUE] = 1; nrow(subset(iris, flag == 1)) / nrow(df); pred_train = as.data.frame(pred_train); nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train);
library(e1071); data(iris); df = iris; df = subset(df, Species == 'setosa'); x = subset(df, select = -Species); y = df$Species; model = svm(x, y, type = 'one-classification',nu=0.10);
pred_train = predict(model, x); pred_test = predict(model, subset(iris, select = -Species));
pred_test = iris;
iris$pred = pred;
data(iris)
iris
head(iris)
library(e1071); data(iris); df = iris; df = subset(df, Species == 'setosa'); x = subset(df, select = -Species); y = df$Species; model = svm(x, y, type = 'one-classification',nu=0.10); print(model); summary(model); pred_train = predict(model, x); pred_test = predict(model, subset(iris, select = -Species));
head(pred_train)
head(pred_test)
library(e1071); data(iris); df = iris; df = subset(df, Species == 'setosa'); x = subset(df, select = -Species); y = df$Species; model = svm(x, y, type = 'one-classification',nu=0.10); print(model); summary(model); pred_train = predict(model, x); pred_test = predict(model, subset(iris, select = -Species));
pred = iris; pred$pred = pred_test; pred$flag = 0; pred$flag[pred$Species == 'setosa' & pred$pred == TRUE] = 1; nrow(subset(iris, flag == 1)) / nrow(df);
head(pred)
library(e1071); data(iris); df = iris; df = subset(df, Species == 'setosa'); x = subset(df, select = -Species); y = df$Species; model = svm(x, y, type = 'one-classification',nu=0.10); print(model); summary(model); pred_train = predict(model, x); pred_test = predict(model, subset(iris, select = -Species)); pred_data = iris; pred_data$pred = pred_test; pred_data$flag = 0; pred_data$flag[pred_data$Species == 'setosa' & pred_data$pred == TRUE] = 1; nrow(subset(pred_data, flag == 1)) / nrow(pred_data);
library(e1071); data(iris); df = iris; df = subset(df, Species == 'setosa'); x = subset(df, select = -Species); y = df$Species; model = svm(x, y, type = 'one-classification',nu=0.10); print(model); summary(model); pred_train = predict(model, x); pred_test = predict(model, subset(iris, select = -Species)); pred_data = iris; pred_data$pred = pred_test; pred_data$flag = 0; pred_data$flag[pred_data$Species == 'setosa' & pred_data$pred == TRUE] = 1; nrow(subset(pred_data, flag == 1)) / nrow(pred_data); pred_train = as.data.frame(pred_train); nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train);
head(pred_data)
nrow(pred_data)
length(pred_test)
pred_test
pred_data = iris; pred_data$pred = pred_test; pred_data$flag = 0; pred_data$flag[pred_data$Species == 'setosa' & pred_data$pred == TRUE] = 1; nrow(subset(pred_data, flag == 1)) / nrow(pred_data);
head(pred_test,10)
head(pred_data,10)
head(pred_data,25)
data(iris)
head(iris)
response_name = "respon"; input_data = iris; #input_data = baca(nama_file); #70/30 partition #column response as y colnames(input_data)[colnames(input_data) == response_name] = "respon"; partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1); dataTrain = input_data[partition_data,]; dataTest = input_data[-partition_data,];
head(input_data)
colnames(input_data)[colnames(input_data) == response_name] = "respon";
partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1);
head(input_data)
response_name = "respon"; input_data = iris; #input_data = baca(nama_file); #70/30 partition #column response as y colnames(input_data)[colnames(input_data) == response_name] = "respon"; partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1);
head(input_data)
colnames(input_data)[colnames(input_data) == response_name] = "respon";
head(input_data)
response_name = "Species"; input_data = iris; #input_data = baca(nama_file); #70/30 partition #column response as y colnames(input_data)[colnames(input_data) == response_name] = "respon"; partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1); dataTrain = input_data[partition_data,]; dataTest = input_data[-partition_data,];
train_data = dataTrain
test_data = dataTest
target_respon = 'setosa'
    df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);
    pred_train = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));
    pred_test = test_data;     pred_test$pred = pred;     pred_test$flag = 0;     pred_test$flag[pred_test$respon == 'setosa' & pred_test$pred == TRUE] = 1;     nrow(subset(pred_test, flag == 1)) / nrow(pred_test);     pred_train = as.data.frame(pred_train);     nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train);
head(pred_test)
    df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_train = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     nrow(subset(pred_data, flag == 1)) / nrow(pred_data);     pred_train = as.data.frame(pred_train);     nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train);
nrow(pred_data)
head(pred_data)
tail(pred_data)
    df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_train = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     nrow(subset(pred_data, flag == 1)) / nrow(pred_data);     pred_train = as.data.frame(pred_train);     nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train);
hitungSVM = function(train_data,test_data,target_respon) {     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_train = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(paste("Test Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train = as.data.frame(pred_train);     print(paste("Train Accuracy : ",nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train)));     return(model); }
modelSVM = hitungSVM(dataTrain, dataTest, "setosa");
hitungSVM = function(train_data,test_data,target_respon) {     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_train = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = as.data.frame(pred_train);     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     return(model); }
modelSVM = hitungSVM(dataTrain, dataTest, "setosa");
hitungSVM = function(train_data,test_data,target_respon) {     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_train = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = as.data.frame(pred_train);     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(c(model,train_test_data)); }
modelSVM = hitungSVM(dataTrain, dataTest, "setosa");
train_data = dataTrain;
test_data = dataTest;
target_respon = "setosa";
    df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_train = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = as.data.frame(pred_train);     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);
head(pred_train)
head(pred_data)
    df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = as.data.frame(pred_trains);     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);
head(pred_data)
head(pred_train)
    df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;
head(pred_train)
head(pred_data)
    df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);
    df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);
nrow(train_test_data)
head(train_test_data)
hitungSVM = function(train_data,test_data,target_respon) {     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(c(model,train_test_data)); }
modelSVM = hitungSVM(dataTrain, dataTest, "setosa");
modelSVM
str(modelSVM)
baca = function(nama_file) {     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } hitungSVM = function(train_data,test_data,target_respon) {     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(c(model,train_test_data)); }
baca = function(nama_file) {     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } hitungSVM = function(train_data,test_data,target_respon) {     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); }
nama_file = "Feature TG Whole Duration 10-04-2018.csv";
input_data = baca(nama_file);
head(input_data)
nrow(is.na(input_data))
nrow(input_data)
head(input_data)
input_data[24763:24770,]
nrow(input_data[is.na()],)
nrow(input_data[is.na(input_data)],)
nrow(input_data[is.na(input_data),])
head(input_data[is.na(input_data),])
head(input_data[is.na(input_data)])
head(input_data[is.na(input_data),])
manual = read.csv("C:/manual.csv",stringsAsFactors=FALSE)
head(manual)
str(manual)
nrow(subset(manual,manual$score.for.translation.quality.Yulis==5))
nrow(subset(manual,manual$score.for.translation.quality.Yulis==4))
nrow(subset(manual,manual$score.for.translation.quality.Yulis==3))
nrow(subset(manual,manual$score.for.translation.quality.Yulis==2))
nrow(subset(manual,manual$score.for.translation.quality.Yulis==1))
3714+428+746+312+633
nama_file = "Feature TG Whole Duration 10-04-2018.csv"; response_name = "Species"; input_data = baca(nama_file);
baca = function(nama_file) {     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } hitungSVM = function(train_data,test_data,target_respon) {     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); }
nama_file = "Feature TG Whole Duration 10-04-2018.csv"; response_name = "Species"; input_data = baca(nama_file);
str(input_data)
unique(input_data$user_is_age_25)
unique(input_data$user_is_age_30)
unique(input_data$user_is_age_35)
unique(input_data$user_is_age_40)
unique(input_data$user_is_age_15)
unique(input_data$user_is_age_20)
unique(input_data$user_is_age_0)
nama_file = "Feature TG Whole Duration 10-04-2018.csv"; response_name = "Species"; input_data = baca(nama_file); #Dataset1 = number of vote as target dataset1 = input_data; dataset1$action_vote_down = NULL; dataset1$is_top_translation = NULL;
baca = function(nama_file) {     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } hitungSVM = function(train_data,test_data,target_respon) {     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungDecisionTree = function(input_data) { } hitungRandomForest = function(input_data) { } hitungNaiveBayes = function(input_data) { } ################################# # Main Program ################################# nama_file = "Feature TG Whole Duration 10-04-2018.csv"; response_name = "Species"; input_data = baca(nama_file); #Dataset1 = number of vote as target dataset1 = input_data; dataset1$action_vote_down = NULL; dataset1$is_top_translation = NULL;
baca = function(nama_file) {     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } partisi = function(input_data,response_name) {     #70/30 partition     #column response as y     colnames(input_data)[colnames(input_data) == response_name] = "respon";     partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1);     dataTrain = input_data[partition_data,];     dataTrain$tipe = "training";     dataTest = input_data[-partition_data,];     dataTest$tipe = "testing";     output_data = rbind(dataTrain, dataTest);     return(output_data); } hitungSVM = function(train_data,test_data,target_respon) {     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); }
hist(input_data$action_vote_up)
hist(input_data$action_vote_up)
nrow(subset(input_data,action_vote_up==2))
nrow(subset(input_data,action_vote_up==1))
nrow(subset(input_data,action_vote_up==0))
#Dataset1 = number of vote as target dataset1 = input_data; dataset1$action_vote_down = NULL; dataset1$is_top_translation = NULL; dataset1_part = partisi(dataset1,"action_vote_up"); modelSVM = hitungSVM(dataset1_part, 2);
str(dataset1_par)
str(dataset1_part)
input_data = dataset1_part;
    train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;
    df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;
df = subset(train_data, respon == target_respon);
target_respon = 2;
    df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;
    model = svm(x, y, type = 'one-classification', nu = 0.10);
    library(e1071);
    model = svm(x, y, type = 'one-classification', nu = 0.10);
model
    pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == 'setosa' & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != 'setosa' & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));
    pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));
pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));
    pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;
nrow(test_data)
nrow(train_data)
str(dataset1)
hist(dataset1$user_median_time_to_vote_down)
nrow(subset(dataset1,user_median_time_to_vote_down==0));
nrow(subset(dataset1, user_median_time_to_vote_down < 1));
hist(dataset1$user_median_time_to_vote_down);
str(hist(dataset1$user_median_time_to_vote_down));
dataset1 = input_data; dataset1$action_vote_down = NULL; dataset1$is_top_translation = NULL; #normalization by replace NA with 0 dataset1_norm = dataset1[is.na(dataset1)] = 0; dataset1_part = partisi(dataset1_norm,"action_vote_up");
str(dataset1_norm)
dataset1_norm = dataset1[is.na(dataset1)] = 0;
str(dataset1_norm)
str(dataset1)
library(imputeTS)
install.packages(imputeTS);
install.packages("imputeTS");
library(imputeTS)
#Dataset1 = number of vote as target dataset1 = input_data; dataset1$action_vote_down = NULL; dataset1$is_top_translation = NULL; #normalization by replace NA with 0 dataset1_norm = na.replace(dataset1,0);
nrow(dataset1_norm[is.na(dataset1_norm)])
nrow(is.na(dataset1_norm))
head(dataset1_norm)
nrow(dataset1_norm[is.na(dataset1_norm)])
nrow(subset(dataset1_norm,is.na(dataset1_norm)) ; ; ) ;
nrow(subset(dataset1_norm,is.na(dataset1_norm)))
dataset1_part = partisi(dataset1_norm,"action_vote_up");
input_data = dataset1_part;
target_respon
    library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification', nu = 0.10);
    model = svm(x, y, type = 'one-classification');
model
    pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));
nrow(test_data)
nrow(pred_test)
nrow(pred_train)
nrow(train_data)
str(test_data)
str(subset(test_data, select = -respon))
    pred_test = predict(model, subset(test_data, select = -respon));
str(pred_test)
nrow(pred_test)
length(pred_test)
length(test_data)
nrow(test_data)
    pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));
nrow(pred_train)
nrow(train_data)
print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));
    pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;
length(pred_trains)
nrow(x)
    pred_train = df;     pred_train$pred = pred_trains;     pred_train$flag = 1;
    print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));
head(pred_train)
str(input_data)
hitungSVM = function(input_data,target_respon) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification');     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); }
modelSVM = hitungSVM(dataset1_part, 1);
model
modelSVM = hitungSVM(dataset1_part, 2, 0.1);
modelSVM = hitungSVM(dataset1_part, 2, 0.2); modelSVM = hitungSVM(dataset1_part, 2, 0.3); modelSVM = hitungSVM(dataset1_part, 2, 0.4); modelSVM = hitungSVM(dataset1_part, 2, 0.5); modelSVM = hitungSVM(dataset1_part, 2, 0.6); modelSVM = hitungSVM(dataset1_part, 2, 0.7); modelSVM = hitungSVM(dataset1_part, 2, 0.8); modelSVM = hitungSVM(dataset1_part, 2, 0.9);
hitungSVM = function(input_data,target_respon,nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification',nu=nu_value);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); }
modelSVM = hitungSVM(dataset1_part, 2, 0.1);
modelSVM = hitungSVM(dataset1_part, 2, 0.2); modelSVM = hitungSVM(dataset1_part, 2, 0.3); modelSVM = hitungSVM(dataset1_part, 2, 0.4); modelSVM = hitungSVM(dataset1_part, 2, 0.5); modelSVM = hitungSVM(dataset1_part, 2, 0.6); modelSVM = hitungSVM(dataset1_part, 2, 0.7); modelSVM = hitungSVM(dataset1_part, 2, 0.8); modelSVM = hitungSVM(dataset1_part, 2, 0.9);
modelSVM = hitungSVM(dataset1_part, 1, 0.1); modelSVM = hitungSVM(dataset1_part, 0, 0.1);
modelSVM = hitungSVM(dataset1_part, 2, 0.1); modelSVM = hitungSVM(dataset1_part, 1, 0.1); modelSVM = hitungSVM(dataset1_part, 0, 0.1);
modelSVM = hitungSVM(dataset1_part, 1, 0.1);
modelSVM = hitungSVM(dataset1_part, 1, 0.5); modelSVM = hitungSVM(dataset1_part, 0, 0.1);
modelSVM = hitungSVM(dataset1_part, 0, 0.5);
hist(subset(dataset1_part, tipe == "training")); hist(subset(dataset1_part, tipe == "testing"));
str(dataset1_part)
hist(subset(dataset1_part, tipe == "training")$respon); hist(subset(dataset1_part, tipe == "testing")$respon);
hist(subset(dataset1_part, tipe == "training")$respon);
head(input_data)
    library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;
model = svm(x, y, probability=TRUE);
data(iris) attach(iris) x = subset(iris, select = -Species); y = Species; model = svm(x, y, probability=TRUE);
pred_prob = predict(model, x, decision.values = TRUE, probability = TRUE);
pred_prob
str(iris)
str(input_data)
    library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data);     x = subset(df, select = -respon);     y = as.factor(df$respon);
head(x)
head(y)
nrow(df,respon==1)
nrow(subset(df,respon==1))
nrow(subset(df,respon==0))
nrow(subset(df,respon==2))
nrow(subset(df,respon==3))
nrow(subset(df,respon==4))
    model = svm(x, y, probability = TRUE);     pred_prob = predict(model, x, decision.values = TRUE, probability = TRUE);
nrow(pred_probs)
nrow(pred_prob)
length(pred_prob)
nrow(train)
nrow(train_data)
head(pred_prob)
str(pred_prob)
model
str(pred_prob)
str(input_data)
head(input_data)
head(input_data$respon)
head(attr(pred_prob,"probabilities"))
str(pred_train)
pred_train = predict(model, x, decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon),decision.values = TRUE, probability = TRUE); str(pred_train)
str(pred_train)
str(pred_test)
str(attr(pred_prob,"probabilities"))
str(attr(pred_prob,"probabilities")[1])
str(attr(pred_prob,"probabilities")[,1])
str(attr(pred_prob,"probabilities")[,2])
str(attr(pred_prob,"probabilities")[,0])
str(attr(pred_prob,"probabilities")[,1])
str(attr(pred_prob,"probabilities")[,2])
str(attr(pred_prob,"probabilities")[,1])
head(attr(pred_prob,"probabilities")[,1])
head(attr(pred_prob,"probabilities")[1])
head(attr(pred_prob,"probabilities"))
head(attr(pred_prob,"probabilities")[,1])
    pred_train_value = attr(pred_train, "probabilities");     pred_test_value = attr(pred_test, "probabilities");
head(attr(pred_prob,"decision.values"))
head(pred_train_value)
head(pred_train_value$0)
str(pred_train_value)
head(pred_train_value[,1])
head(pred_train_value[,0])
head(pred_train_value[,0])     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }             pred_train_value$pred[i] = max_pos;         }     }
str(pred_train_value)
str(pred_train_value)    #normalization and find specific prediction value      pred_train_value = attr(pred_train, "probabilities");     pred_test_value = attr(pred_test, "probabilities");
    pred_train_value = attr(pred_train, "probabilities");     pred_test_value = attr(pred_test, "probabilities");
str(pred_train_value)
    pred_train_value[,6] = -1;
    #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));
str(pred_train_value)
    pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }             pred_train_value$pred[i] = max_pos;         }     }
    pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train$0[i];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }             pred_train_value$pred[i] = max_pos;         }     }
    pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value$0[i];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }             pred_train_value$pred[i] = max_pos;         }     }
pred_train = predict(model, x, decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon),decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value$0[i];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }             pred_train_value$pred[i] = max_pos;         }     }
    pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value$0[i];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }             pred_train_value$pred[i] = max_pos;         }     }
    pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;
head(pred_train)
head(pred_train_value)
pred_train_value[1,2]
pred_train_value[0,2]
pred_train_value[1,2]
pred_train_value[1,1]
pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i,1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }
head(pred_train_value)
    pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }
head(pred_test_value)
    pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;
head(pred_data)
    pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;
print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));
pred_train = df;     pred_train$pred = pred_trains_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;
    pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;
print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));
print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));
model
library(imputeTS); nama_file = "Features with Manual Assessment.csv"; input_data = baca(nama_file);
################################# # Fungsi dan Prosedur ################################# baca = function(nama_file) {     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } partisi = function(input_data,response_name) {     #70/30 partition     #column response as y     colnames(input_data)[colnames(input_data) == response_name] = "respon";     partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1);     dataTrain = input_data[partition_data,];     dataTrain$tipe = "training";     dataTest = input_data[-partition_data,];     dataTest$tipe = "testing";     output_data = rbind(dataTrain, dataTest);     return(output_data); } hitungSVM = function(input_data,target_respon,nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification',nu=nu_value);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM-multi = function(input_data, target_respon, nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data);     x = subset(df, select = -respon);     y = as.factor(df$respon);     model = svm(x, y, probability = TRUE);     pred_train = predict(model, x, decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon),decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i,1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); }
hitungSVM-multi = function(input_data, target_respon, nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data);     x = subset(df, select = -respon);     y = as.factor(df$respon);     model = svm(x, y, probability = TRUE);     pred_train = predict(model, x, decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon),decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i,1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); }
hitungSVM_multi = function(input_data, target_respon, nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data);     x = subset(df, select = -respon);     y = as.factor(df$respon);     model = svm(x, y, probability = TRUE);     pred_train = predict(model, x, decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon),decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i,1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); }
baca = function(nama_file) {     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } partisi = function(input_data,response_name) {     #70/30 partition     #column response as y     colnames(input_data)[colnames(input_data) == response_name] = "respon";     partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1);     dataTrain = input_data[partition_data,];     dataTrain$tipe = "training";     dataTest = input_data[-partition_data,];     dataTest$tipe = "testing";     output_data = rbind(dataTrain, dataTest);     return(output_data); } hitungSVM = function(input_data,target_respon,nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification',nu=nu_value);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); }
library(imputeTS); nama_file = "Features with Manual Assessment.csv"; input_data = baca(nama_file);
dataset1 = input_data; dataset1_assessed = dataset1 %>% filter(is.na(manual_assessment)) %>% as.data.frame(); #normalization by replace NA with 0 dataset1_norm = na.replace(dataset1_assessed,0);
library(dplyr);
dataset1 = input_data; dataset1_assessed = dataset1 %>% filter(is.na(manual_assessment)) %>% as.data.frame(); #normalization by replace NA with 0 dataset1_norm = na.replace(dataset1_assessed,0);
nrow(dataset1_norm)
nrow(dataset1)
dataset1_part = partisi(dataset1_norm, "manual_assessment"); hist(subset(dataset1_part, tipe == "training")$respon); hist(subset(dataset1_part, tipe == "testing")$respon);
str(dataset1_assessed)
#Dataset1 = manual_assessment as target dataset1 = input_data; dataset1_assessed = dataset1 %>% filter(!is.na(manual_assessment)) %>% as.data.frame(); #normalization by replace NA with 0 dataset1_norm = na.replace(dataset1_assessed,0); dataset1_part = partisi(dataset1_norm, "manual_assessment"); hist(subset(dataset1_part, tipe == "training")$respon); hist(subset(dataset1_part, tipe == "testing")$respon);
hist(subset(dataset1_part, tipe == "training")$respon); hist(subset(dataset1_part, tipe == "testing")$respon);
hist(subset(dataset1_part, tipe == "training")$respon);
dataset1_part %>% group_by(tipe,manual_assessment) %>% summarise(jumlah_data=n()) %>% as.data.frame();
dataset1_part %>% group_by(tipe,manual_assessment) %>% summarise(jumlah_data=n()) %>% as.data.frame();
str(dataset1_part)
dataset1_part %>% group_by(tipe,respon) %>% summarise(jumlah_data=n()) %>% as.data.frame();
modelSVM = hitungSVM(dataset1_part, 5, 0.1);
input_data = dataset1_part;
target_respon = 5;
nu_value=0.1
    library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification',nu=nu_value);
library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;
head(x)
head(y)
nrow(x)
nrow(y)
length(y)
model = svm(x, y, type = 'one-classification',nu=nu_value);
model
nu_value
model = svm(x, y, type = 'one-classification');
dataset1 = input_data; dataset1$username = NULL; dataset1$source.word = NULL; dataset1$target.word = NULL; dataset1_assessed = dataset1 %>% filter(!is.na(manual_assessment)) %>% as.data.frame(); #normalization by replace NA with 0 dataset1_norm = na.replace(dataset1_assessed,0); dataset1_part = partisi(dataset1_norm, "manual_assessment"); dataset1_part %>% group_by(tipe,respon) %>% summarise(jumlah_data=n()) %>% as.data.frame(); hist(subset(dataset1_part, tipe == "training")$respon); hist(subset(dataset1_part, tipe == "testing")$respon); modelSVM = hitungSVM(dataset1_part, 5, 0.1);
str(dataset1_part)
#Dataset1 = manual_assessment as target dataset1 = input_data; dataset1$username = NULL; dataset1$source.word = NULL; dataset1$target.word = NULL; dataset1_assessed = dataset1 %>% filter(!is.na(manual_assessment)) %>% as.data.frame();
dataset1 = input_data; dataset1$username = NULL; dataset1$source.word = NULL; dataset1$target.word = NULL;
str(input_data)
input_data = baca(nama_file); #Dataset1 = manual_assessment as target dataset1 = input_data; dataset1$username = NULL; dataset1$source.word = NULL; dataset1$target.word = NULL; dataset1_assessed = dataset1 %>% filter(!is.na(manual_assessment)) %>% as.data.frame(); #normalization by replace NA with 0 dataset1_norm = na.replace(dataset1_assessed,0); dataset1_part = partisi(dataset1_norm, "manual_assessment"); dataset1_part %>% group_by(tipe,respon) %>% summarise(jumlah_data=n()) %>% as.data.frame(); hist(subset(dataset1_part, tipe == "training")$respon); hist(subset(dataset1_part, tipe == "testing")$respon); modelSVM = hitungSVM(dataset1_part, 5, 0.1);
modelSVM = hitungSVM(dataset1_part, 5, 0.5);
ls()
str(input_data)
str(dataset1_part)
train_data = subset(input_data, tipe == "training"); train_data$tipe = NULL; test_data = subset(input_data, tipe == "testing"); test_data$tipe = NULL; model = naiveBayes(respon ~ ., data = train_data); class(model); summary(model); print(model);
str(train_data)
input_data = dataset1_part;
train_data = subset(input_data, tipe == "training"); train_data$tipe = NULL; test_data = subset(input_data, tipe == "testing"); test_data$tipe = NULL;
model = naiveBayes(respon ~ ., data = train_data); class(model); summary(model);
preds = predict(model, newdata = test_data);
conf_matrix = table(preds, test_data$respon);
preds = predict(model, newdata = test_data); conf_matrix = table(preds, test_data$respon);
nrow(test_data)
preds(test_data)
preds = predict(model, newdata = test_data); conf_matrix = table(preds, test_data$respon);preds = predict(model, newdata = subset(test_data,select=-respon)); conf_matrix = table(preds, test_data$respon);
preds = predict(model, newdata = subset(test_data,select=-respon));
str(preds)
model <- naiveBayes(class ~ ., data = breast_cancer) class(model) summary(model) print(model) preds = predict(model, newdata = breast_cancer);
attach(breast_cance)
attach(breast_cancer)
install.packages("mlbench")
library(mlbench)
data(HouseVotes84, package = "mlbench") model <- naiveBayes(Class ~ ., data = HouseVotes84)
str(HouseVotes84)
pred <- predict(model, HouseVotes84) table(pred, HouseVotes84$Class)
head(pred)
length(pred)
nrow(HouseVotes84)
preds = predict(model, newdata = subset(test_data,select=-respon)); conf_matrix = table(preds, test_data$respon);
length(preds)
length(test_data$respon)
conf_matrix
str(train_data)
model = naiveBayes(respon ~ ., data = train_data);
preds = predict(model, newdata=test_data); conf_matrix = table(preds, test_data$respon);
preds
model
model = naiveBayes(respon ~ ., data = train_data); preds = predict(model, newdata=test_data); conf_matrix = table(preds, test_data$respon);
str(test_data)
str(train_data)
pred
str(test_data)
train_data$respon = as.factor(train_data$respon); test_data$respon = as.factor(test_data$respon);
model = naiveBayes(respon ~ ., data = train_data); preds = predict(model, newdata=test_data); conf_matrix = table(preds, test_data$respon);
lenth(preds)
length(preds)
conf_matrix
model = naiveBayes(respon ~ ., data = train_data); preds = predict(model, newdata=test_data); conf_matrix = table(preds, test_data$respon); model = naiveBayes(respon ~ ., data = train_data, laplace = 3); preds = predict(model, newdata = test_data); conf_matrix = table(preds, test_data$respon);
model = naiveBayes(respon ~ ., data = train_data); preds = predict(model, newdata=test_data); conf_matrix = table(preds, test_data$respon); conf_matrix; model = naiveBayes(respon ~ ., data = train_data, laplace = 3); preds = predict(model, newdata = test_data); conf_matrix = table(preds, test_data$respon); conf_matrix;
model = naiveBayes(respon ~ ., data = train_data); preds = predict(model, newdata=test_data); conf_matrix = table(preds, test_data$respon); conf_matrix; model = naiveBayes(respon ~ ., data = train_data, laplace = 1); preds = predict(model, newdata = test_data); conf_matrix = table(preds, test_data$respon); conf_matrix; model = naiveBayes(respon ~ ., data = train_data, laplace = 2); preds = predict(model, newdata = test_data); conf_matrix = table(preds, test_data$respon); conf_matrix; model = naiveBayes(respon ~ ., data = train_data, laplace = 3); preds = predict(model, newdata = test_data); conf_matrix = table(preds, test_data$respon); conf_matrix;
modelSVM = hitungSVM(dataset1_part, 5, 0.1); modelSVM = hitungSVM(dataset1_part, 4, 0.1); modelSVM = hitungSVM(dataset1_part, 3, 0.1); modelSVM = hitungSVM(dataset1_part, 2, 0.1); modelSVM = hitungSVM(dataset1_part, 1, 0.1); modelSVM = hitungSVM(dataset1_part, 0, 0.1);
modelSVM = hitungSVM(dataset1_part, 1, 0.5);
modelSVM = hitungSVM(dataset1_part, 1, 0.9);
################################# # Fungsi dan Prosedur ################################# baca = function(nama_file) {     library(caret);     set.seed(3456);     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } partisi = function(input_data,response_name) {     #70/30 partition     #column response as y     colnames(input_data)[colnames(input_data) == response_name] = "respon";     partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1);     dataTrain = input_data[partition_data,];     dataTrain$tipe = "training";     dataTest = input_data[-partition_data,];     dataTest$tipe = "testing";     output_data = rbind(dataTrain, dataTest);     return(output_data); } hitungSVM = function(input_data,target_respon,nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification',nu=nu_value);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi = function(input_data, target_respon, nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data);     x = subset(df, select = -respon);     y = as.factor(df$respon);     model = svm(x, y, probability = TRUE);     pred_train = predict(model, x, decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon),decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i,1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungDecisionTree = function(input_data) { } hitungRandomForest = function(input_data) { } hitungNaiveBayes = function(input_data) { }
library(imputeTS); library(dplyr); nama_file = "Features with Manual Assessment.csv"; input_data = baca(nama_file); #Dataset1 = manual_assessment as target dataset1 = input_data; dataset1$username = NULL; dataset1$source.word = NULL; dataset1$target.word = NULL; dataset1_assessed = dataset1 %>% filter(!is.na(manual_assessment)) %>% as.data.frame(); #normalization by replace NA with 0 dataset1_norm = na.replace(dataset1_assessed,0); dataset1_part = partisi(dataset1_norm, "manual_assessment"); dataset1_part %>% group_by(tipe,respon) %>% summarise(jumlah_data=n()) %>% as.data.frame(); hist(subset(dataset1_part, tipe == "training")$respon); hist(subset(dataset1_part, tipe == "testing")$respon);
modelSVM = hitungSVM(dataset1_part, 1, 0.9);
modelSVM = hitungSVM(dataset1_part, 1, 0.5);
modelSVM = hitungSVM(dataset1_part, 1, 0.1);
modelSVM = hitungSVM(dataset1_part, 1, 0.3);
modelSVM = hitungSVM(dataset1_part, 1, 0.7);
modelSVM = hitungSVM(dataset1_part, 2, 0.5);
modelSVM = hitungSVM(dataset1_part, 3, 0.3);
modelSVM = hitungSVM(dataset1_part, 3, 0.5);
modelSVM = hitungSVM(dataset1_part, 5, 0.5);
control <- trainControl(method = "repeatedcv", number = 10, repeats = 3) seed <- 7 metric <- "Accuracy" set.seed(seed) mtry <- sqrt(ncol(x)) tunegrid <- expand.grid(.mtry = mtry) rf_default <- train(Class ~ ., data = dataset, method = "rf", metric = metric, tuneGrid = tunegrid, trControl = control) print(rf_default)
library(randomForest) library(mlbench) library(caret) # Load Dataset data(Sonar) dataset <- Sonar x <- dataset[, 1:60] y <- dataset[, 61] control <- trainControl(method = "repeatedcv", number = 10, repeats = 3) seed <- 7 metric <- "Accuracy" set.seed(seed) mtry <- sqrt(ncol(x)) tunegrid <- expand.grid(.mtry = mtry) rf_default <- train(Class ~ ., data = dataset, method = "rf", metric = metric, tuneGrid = tunegrid, trControl = control) print(rf_default)
length(x)
length(y)
url <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv' wine <- read.table(url) library(randomForest) model <- randomForest(taste ~ . - quality, data = train) pred <- predict(model, newdata = test) table(pred, test$taste)
url <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv' wine <- read.table(url)
input_data = library(imputeTS); library(dplyr); nama_file = "Features with Manual Assessment.csv"; input_data = baca(nama_file);
library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;
library(imputeTS); library(dplyr); nama_file = "Features with Manual Assessment.csv"; input_data = baca(nama_file); #Dataset1 = manual_assessment as target dataset1 = input_data; dataset1$username = NULL; dataset1$source.word = NULL; dataset1$target.word = NULL; dataset1_assessed = dataset1 %>% filter(!is.na(manual_assessment)) %>% as.data.frame(); #normalization by replace NA with 0 dataset1_norm = na.replace(dataset1_assessed,0); dataset1_part = partisi(dataset1_norm, "manual_assessment");
input_data = dataset1_part
    library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;
library(randomForest) model <- randomForest(respon ~ ., data = train_data)
pred <- predict(model, newdata = test_data) table(pred, test$taste)
pred <- predict(model, newdata = test_data) table(pred, test_data$respon)
str(test_data)
train_data$respon = as.factor(train_data$respon); test_data$respon = as.factor(test_data$respon);
model <- randomForest(respon ~ ., data = train_data)
pred <- predict(model, newdata = test_data) table(pred, test_data$respon)
library(caret)
confusionMatrix(pred, test_data$respon)
model = naiveBayes(respon ~ ., data = train_data); preds = predict(model, newdata=test_data); confusionMatrix(preds, test_data$respon);
library(rpart);
model = rpart(respon ~ ., data = train_data, method = "class");
pred = predict(model, test, type = "class"); confusionMatrix(pred, test_data$respon)
pred = predict(model, test_data, type = "class"); confusionMatrix(pred, test_data$respon)
model = rpart(respon ~ ., data = train_data); pred = predict(model, test_data); confusionMatrix(pred, test_data$respon)
model = rpart(respon ~ ., data = train_data, method = "class"); pred = predict(model, test_data, type = "class"); confusionMatrix(pred, test_data$respon)
model = rpart(respon ~ ., data = train_data, method = "class");
pred = predict(model, test_data, type = "class");
confusionMatrix(pred, test_data$respon)
hitungSVM_multi = function(input_data, target_respon) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data);     x = subset(df, select = -respon);     y = as.factor(df$respon);     model = svm(x, y, probability = TRUE);     pred_train = predict(model, x, decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon),decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i,1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); }
install.packages("RWeka")
model = rpart(respon ~ ., data = train_data, method = "class"); pred = predict(model, test_data, type = "class"); confusionMatrix(pred, test_data$respon)
str(pred)
head(pred)
str(train_Data)
str(train_data)
head(train_data)
head(train_data %>% filter(respon!=5))
head(pred)
head(pred %>% filter(pred!=5))
pred[pred!=5]
model = rpart(respon ~ ., data = train_data); pred = predict(model, test_data); confusionMatrix(pred, test_data$respon)
model
pred
model = rpart(respon ~ ., data = train_data,method = "class"); pred = predict(model, test_data,method="class"); confusionMatrix(pred, test_data$respon)
model = rpart(respon ~ ., data = train_data,method = "class"); pred = predict(model, test_data,method="class"); confusionMatrix(pred, test_data$respon)
pred
modelSVM = hitungSVM(dataset1_part, 5, 0.5);
modelSVM = hitungSVM(dataset1_part, 5, 0.1);
library(RWeka); library(caret); set.seed(1958); model = train(Species~.,data=train_data,method="J48");
data(iris)
library(RWeka); library(caret); set.seed(1958); model = train(respon~.,data=train_data,method="J48");
str(train_data)
str(input_data)
input_data = baca(nama_file);
install.packages("classify")
install.packages("classify")
library(classify)
install.packages("classify",dependencies = TRUE)
library(classify)
install.packages("nnet");
library(nnet)
baca = function(nama_file) {     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); }
library(imputeTS); library(dplyr); train_file = "Training Data.csv"; test_file = "Test Data.csv"; train_data = baca(nama_file); test_data = baca(nama_file);
nrow(test_data)
nrow(train_data)
train_data = baca(train_file); test_data = baca(test_file);
nrow(train_data)
nrow(test_data)
str(train_data)
train_data %>% group_by(origin_word_entropy) %>% summarise(jumlah_data = n()) %>% as.data.frame();
train_data %>% group_by(manual_assessment) %>% summarise(jumlah_data = n()) %>% as.data.frame();
test_data %>% group_by(manual_assessment) %>% summarise(jumlah_data = n()) %>% as.data.frame();
hist(train_data$manual_assessment);
hist(train_data$manual_assessment);
hist(test_data$manual_assessment);
str(train_data)
train_data %>% group_by(manual_origin_source) %>% summarise(jumlah_data = n());
train_data %>% group_by(origin_word_entropy) %>% summarise(jumlah_data = n());
train_data %>% filter(is.na(origin_word_entropy)) %>%  group_by(origin_word_entropy) %>% summarise(jumlah_data = n());
train_data = baca(train_file); colnames(train_data)[colnames(train_data) == target_column] = "respon"; test_data = baca(test_file); colnames(test_data)[colnames(test_data) == target_column] = "respon";
str(target_column = "manual_assessment"; train_data = baca(train_file); colnames(train_data)[colnames(train_data) == target_column] = "respon"; test_data = baca(test_file); colnames(test_data)[colnames(test_data) == target_column] = "respon"; ) ; ;
target_column = "manual_assessment"; train_data = baca(train_file); colnames(train_data)[colnames(train_data) == target_column] = "respon"; test_data = baca(test_file); colnames(test_data)[colnames(test_data) == target_column] = "respon";
str(train_data)
train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(manual_origin_source) & !is.na(origin_word_entropy)) %>% as.data.frame();
train_dataset1 = train_data; test_dataset1 = test_data; train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(manual_origin_source) & !is.na(origin_word_entropy)) %>% as.data.frame();
nrow(train_dataset1)
nrow(dataset1_assessed)
dataset1_assessed %>% filter(is.na(origin_word_entropy)) %>%  group_by(origin_word_entropy) %>% summarise(jumlah_data = n());
train_dataset1 %>% filter(is.na(origin_word_entropy)) %>%  group_by(origin_word_entropy) %>% summarise(jumlah_data = n());
train_data %>% group_by(manual_origin_source,origin_word_entropy,respon) %>% summarise(jumlah_data = n());
train_data %>% filter(!is.na(respon) & !is.na(manual_origin_source) & !is.na(origin_word_entropy)) %>% group_by(manual_origin_source,origin_word_entropy,respon) %>% summarise(jumlah_data = n());
train_data %>% filter(is.na(respon) | !is.na(manual_origin_source) | !is.na(origin_word_entropy)) %>% group_by(manual_origin_source,origin_word_entropy,respon) %>% summarise(jumlah_data = n());
train_data %>% filter(is.na(respon) | is.na(manual_origin_source) | is.na(origin_word_entropy)) %>% group_by(manual_origin_source,origin_word_entropy,respon) %>% summarise(jumlah_data = n());
dataset1_assessed %>% filter(is.na(respon) | is.na(manual_origin_source) | is.na(origin_word_entropy)) %>% group_by(manual_origin_source,origin_word_entropy,respon) %>% summarise(jumlah_data = n());
str(dataset1_assessed)
nrow(dataset1_assessed[is.na(dataset1_assessed)]);
nrow(dataset1_assessed[is.na(dataset1_assessed),]);
colnames(dataset1_assessed)[colSums(is.na(dataset1_assessed)) > 0]
#normalization by replace NA with 0 dataset1_norm = na.replace(dataset1_assessed,0);
colnames(dataset1_assessed)[colSums(is.na(dataset1_assessed)) > 0]
colnames(dataset1_norm)[colSums(is.na(dataset1_norm)) > 0]
hitungRandomForest = function(train_data, test_data) {     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = randomForest(respon ~ ., data = train_data);     pred = predict(model, newdata = test_data);     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); }
train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(manual_origin_source) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(manual_origin_source) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0);
train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(manual_origin_source) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(manual_origin_source) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0]
colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0]
train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(manual_origin_source) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(manual_origin_source) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm);
library(caret)
# ensure the results are repeatable set.seed(7) # load the library library(mlbench) library(caret) # load the data data(PimaIndiansDiabetes) # calculate correlation matrix correlationMatrix <- cor(PimaIndiansDiabetes[, 1:8]) # summarize the correlation matrix print(correlationMatrix) # find attributes that are highly corrected (ideally >0.75) highlyCorrelated <- findCorrelation(correlationMatrix, cutoff = 0.5) # print indexes of highly correlated attributes print(highlyCorrelated)
print(highlyCorrelated)
highlyCorrelated
# ensure results are repeatable set.seed(7) # load the library library(mlbench) library(caret) # load the dataset data(PimaIndiansDiabetes) # prepare training scheme control <- trainControl(method = "repeatedcv", number = 10, repeats = 3) # train the model model <- train(diabetes ~ ., data = PimaIndiansDiabetes, method = "lvq", preProcess = "scale", trControl = control) # estimate variable importance importance <- varImp(model, scale = FALSE) # summarize importance print(importance) # plot importance plot(importance)
# ensure the results are repeatable set.seed(7) # load the library library(mlbench) library(caret) # load the data data(PimaIndiansDiabetes) # define the control using a random forest selection function control <- rfeControl(functions = rfFuncs, method = "cv", number = 10) # run the RFE algorithm results <- rfe(PimaIndiansDiabetes[, 1:8], PimaIndiansDiabetes[, 9], sizes = c(1:8), rfeControl = control) # summarize the results print(results) # list the chosen features predictors(results) # plot the results plot(results, type = c("g", "o"))
# ensure results are repeatable     set.seed(7)     # load the library     library(mlbench)     library(caret)     # load the dataset     input_data = rbind(train_data,test_data)     # prepare training scheme     control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)     # train the model     model <- train(respon ~ ., data = input_data, method = "lvq", preProcess = "scale", trControl = control)     # estimate variable importance     importance <- varImp(model, scale = FALSE)     # summarize importance     print(importance)     # plot importance     plot(importance)
hitungFeaturesImportance = function(train_data,test_data) {     # ensure results are repeatable     set.seed(7)     # load the library     library(mlbench)     library(caret)     # load the dataset     input_data = rbind(train_data,test_data)     # prepare training scheme     control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)     # train the model     model <- train(respon ~ ., data = input_data, method = "lvq", preProcess = "scale", trControl = control)     # estimate variable importance     importance <- varImp(model, scale = FALSE)     # summarize importance     print(importance)     # plot importance     plot(importance) }
hitungFeaturesImportance(train_dataset1_norm,test_dataset1_norm);
str(train_dataset1_norm)
str(PimaIndiansDiabetes)
hitungFeaturesImportance = function(train_data,test_data) {     # ensure results are repeatable     set.seed(7)     # load the library     library(mlbench)     library(caret)     # load the dataset     input_data = rbind(train_data, test_data)     input_data$respon = as.factor(input_data$respon);     # prepare training scheme     control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)     # train the model     model <- train(respon ~ ., data = input_data, method = "lvq", preProcess = "scale", trControl = control)     # estimate variable importance     importance <- varImp(model, scale = FALSE)     # summarize importance     print(importance)     # plot importance     plot(importance) }
hitungFeaturesImportance(train_dataset1_norm,test_dataset1_norm);
library(imputeTS); library(dplyr); train_file = "Training Data.csv"; test_file = "Test Data.csv"; target_column = "manual_assessment"; train_data = baca(train_file); colnames(train_data)[colnames(train_data) == target_column] = "respon"; test_data = baca(test_file); colnames(test_data)[colnames(test_data) == target_column] = "respon";
baca = function(nama_file) {     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); }
library(imputeTS); library(dplyr); train_file = "Training Data.csv"; test_file = "Test Data.csv"; target_column = "manual_assessment"; train_data = baca(train_file); colnames(train_data)[colnames(train_data) == target_column] = "respon"; test_data = baca(test_file); colnames(test_data)[colnames(test_data) == target_column] = "respon";
train_data %>% filter(is.na(respon) | is.na(manual_origin_source) | is.na(origin_word_entropy)) %>% group_by(manual_origin_source,origin_word_entropy,respon) %>% summarise(jumlah_data = n()); #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(manual_origin_source) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(manual_origin_source) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm); hitungNaiveBayes(train_dataset1_norm, test_dataset1_norm); hitungDecisionTree(train_dataset1_norm, test_dataset1_norm);
partisi = function(input_data,response_name) {     #70/30 partition     #column response as y     colnames(input_data)[colnames(input_data) == response_name] = "respon";     partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1);     dataTrain = input_data[partition_data,];     dataTrain$tipe = "training";     dataTest = input_data[-partition_data,];     dataTest$tipe = "testing";     output_data = rbind(dataTrain, dataTest);     return(output_data); } hitungSVM2 = function(train_data,test_data, target_respon, nu_value, gamma_value) {     library(e1071);     model = svm(subset(train_data,select = -respon), train_data$respon, type = 'one-classification', nu = nu_value, gamma=gamma_value);     pred_trains = predict(model, subset(train_data,select= -respon));     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM = function(input_data,target_respon,nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification',nu=nu_value);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi = function(input_data, target_respon) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data);     x = subset(df, select = -respon);     y = as.factor(df$respon);     model = svm(x, y, probability = TRUE);     pred_train = predict(model, x, decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon),decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i,1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi2 = function(train_data,test_data, c_value, gamma_value) {     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = svm(subset(train_data,select=-respon), train_data$respon, probability = TRUE,C=c_value,gamma=gamma_value);     pred_train = predict(model, subset(train_data, select = -respon), decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon), decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungDecisionTree = function(train_data,test_data) {     library(C50);     library(printr);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     print("CHAID");     library(party);     model = ctree(respon ~ ., data = train_data);     pred = predict(model, test_data);     print(confusionMatrix(pred, test_data$respon));     print("CART");     model = rpart(respon ~ ., data = train_data, method = "class");     pred = predict(model, test_data, type = "class");     print(confusionMatrix(pred, test_data$respon));     print("C50");     model = C5.0(respon ~ ., data = train_data);     results = predict(object = model, newdata = test_data, type = "class");     pred = predict(model, test_data);     print(confusionMatrix(pred, test_data$respon)); } hitungRandomForest = function(train_data, test_data) {     library(caret);     library(randomForest);     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = randomForest(respon ~ ., data = train_data,importance=TRUE);     pred = predict(model, newdata = test_data);     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon));     return(model); } hitungNaiveBayes = function(train_data,test_data) {     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = naiveBayes(respon ~ ., data = train_data)     pred = predict(model, newdata = subset(test_data, select = -respon));     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); } hitungNaiveBayes_normalization = function(train_data, test_data) {     library(e1071)     library(forecast)     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     for (i in 1:(ncol(train_data)-1)) {             train_data[, i] = BoxCox(train_data[, i], BoxCox.lambda(train_data[, i]));     }     for (i in 1:(ncol(test_data)-1)) {             test_data[, i] = BoxCox(test_data[, i], BoxCox.lambda(test_data[, i]));     }     model = naiveBayes(respon ~ ., data = train_data)     pred = predict(model, newdata = subset(test_data, select = -respon));     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); } hitungFeaturesImportance = function(train_data,test_data) {     # ensure results are repeatable     set.seed(7)     # load the library     library(mlbench)     library(caret)     # load the dataset     input_data = rbind(train_data, test_data)     input_data$respon = as.factor(input_data$respon);     # prepare training scheme     control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)     # train the model     model <- train(respon ~ ., data = input_data, method = "lvq", preProcess = "scale", trControl = control)     # estimate variable importance     importance <- varImp(model, scale = FALSE)     # summarize importance     print(importance)     # plot importance     plot(importance) }
modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm); hitungNaiveBayes(train_dataset1_norm, test_dataset1_norm); hitungDecisionTree(train_dataset1_norm, test_dataset1_norm);
install.packages("C50",dependencies = TRUE);
library(C50)
install.packages("C50");
library(C50)
install.packages("libcoin");
library(C50)
install.packages("partykit",dependencies = TRUE);
library(party)
library(printr)
install.packages("printr");
library(printr)
library(caret)
library(randomForest)
library(e1071)
library(imputeTS)
library(dplyr)
modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm); hitungNaiveBayes(train_dataset1_norm, test_dataset1_norm); hitungDecisionTree(train_dataset1_norm, test_dataset1_norm);
install.packages("rpart",dependencies = TRUE)
library(rpart)
set.seed(12345);
modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm); hitungNaiveBayes(train_dataset1_norm, test_dataset1_norm); hitungDecisionTree(train_dataset1_norm, test_dataset1_norm);
library(e1071); train_data_back = train_data; test_data_back = test_data; train_data = train_dataset1_norm; test_data = test_dataset1_norm; train_data5 = subset(train_data, respon == 5, select = -respon); train_data4 = subset(train_data, respon == 4, select = -respon); train_data3 = subset(train_data, respon == 3, select = -respon); train_data2 = subset(train_data, respon == 2, select = -respon); train_data1 = subset(train_data, respon == 1, select = -respon); train_data5$user_is_age_0 = NULL; train_data4$user_is_age_0 = NULL; train_data3$user_is_age_0 = NULL; train_data2$user_is_age_0 = NULL; train_data1$user_is_age_0 = NULL; test_data$user_is_age_0 = NULL;
library(e1071); train_data_back = train_data; test_data_back = test_data; train_data = train_dataset1_norm; test_data = test_dataset1_norm; train_data5 = subset(train_data, respon == 5, select = -respon); train_data54 = subset(train_data, respon >= 4, select = -respon); train_data543 = subset(train_data, respon >= 3, select = -respon); train_data5432 = subset(train_data, respon >= 2, select = -respon); #Best nu=0.001, gamma=0.01 accuracy=78.03 #model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); #model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.001,gamma=0.01); model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); pred5 = predict(model5, subset(test_data,select=-respon)); pred4 = predict(model54, subset(test_data, select = -respon)); pred3 = predict(model543, subset(test_data, select = -respon)); pred2 = predict(model5432, subset(test_data, select = -respon)); head(pred5); head(pred4); head(pred3); head(pred2); head(test_data$respon); preds = data.frame(pred5, pred4, pred3, pred2); preds$pred = -1; for (i in 1:nrow(preds)) {     if (preds$pred5[i]) {         preds$pred[i] = 5;     } else {         if (preds$pred4[i]) {             preds$pred[i] = 4;         } else {             if (preds$pred3[i]) {                 preds$pred[i] = 3;             } else {                 if (preds$pred2[i]) {                     preds$pred[i] = 2;                 } else {                     preds$pred[i] = 1;                 }             }         }     } } preds$target = test_data$respon; confusionMatrix(preds$pred, test_data$respon); test_data %>% group_by(respon) %>% summarise(jumlah_data = n(), persentase = n() / 4679) %>% as.data.frame();
importance(modelRandomForest);
importance(modelRandomForest)$MeanDecreaseAccuracy;
importance(modelRandomForest)$MeanDecreaseAccuracy;
data.frame(importance(modelRandomForest))$MeanDecreaseAccuracy;
str(importance(modelRandomForest))
head(importance(modelRandomForest))
str(data.frame(importance(modelRandomForest)))
colnames(train_dataset1_norm)
colnames(train_dataset1_norm)importances = data.frame(importance(modelRandomForest)); importances$kolom = colnames(train_dataset1_norm);
importances = data.frame(importance(modelRandomForest));
importances$kolom = colnames(train_dataset1_norm);
importances$kolom = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm)-1];
head(importances)
mean(importances$MeanDecreaseAccuracy);
rataMDA = mean(importances$MeanDecreaseAccuracy);
rataMDA
train_dataset1_norm_withMD = train_dataset1_norm; train_dataset1_norm_withMD$MDA = importances$MeanDecreaseAccuracy; train_dataset1_norm_withMD$MDG = importances$MeanDecreaseGini;
train_dataset1_norm_withMD = rbind(train_dataset1_norm_withMD,transpose(importances$MeanDecreaseAccuracy));
train_dataset1_norm_withMD = rbind(train_dataset1_norm_withMD,t(importances$MeanDecreaseAccuracy));
t(importances$MeanDecreaseAccuracy)
ncol(train_dataset1_norm_withMD)
importances = rbind(importances,importances[1,]);
train_dataset1_norm_withMD = train_dataset1_norm; train_dataset1_norm_withMD = rbind(train_dataset1_norm_withMD,t(importances$MeanDecreaseAccuracy));
train_dataset1_norm_withMD = train_dataset1_norm; colnames(t(importances$MeanDecreaseAccuracy)) = colnames(train_dataset1_norm); train_dataset1_norm_withMD = rbind(train_dataset1_norm_withMD,t(importances$MeanDecreaseAccuracy));
colnames(t(importances$MeanDecreaseAccuracy))
t(importances$MeanDecreaseAccuracy)
colnames(data.frame(t(importances$MeanDecreaseAccuracy)))
train_dataset1_norm_withMD = train_dataset1_norm; colnames(data.frame(t(importances$MeanDecreaseAccuracy))) = colnames(train_dataset1_norm); train_dataset1_norm_withMD = rbind(train_dataset1_norm_withMD,t(importances$MeanDecreaseAccuracy));
colnames(data.frame(t(importances$MeanDecreaseAccuracy)))
colnames(train_dataset1_norm)
colnames(data.frame(t(importances$MeanDecreaseAccuracy))) = colnames(train_dataset1_norm);
train_dataset1_norm_withMD = train_dataset1_norm; colnames(data.frame(t(importances$MeanDecreaseAccuracy))) = colnames(train_dataset1_norm); train_dataset1_norm_withMD = rbind(train_dataset1_norm_withMD,t(importances$MeanDecreaseAccuracy));
str(colnames(data.frame(t(importances$MeanDecreaseAccuracy))))
str(colnames(train_dataset1_norm))
datanya = data.frame(t(importances$MeanDecreaseAccuracy));
colnames(datanya) = colnames(train_dataset1_norm);
train_dataset1_norm_withMD = rbind(datanya,t(importances$MeanDecreaseAccuracy));
importances = data.frame(importance(modelRandomForest)); importances = rbind(importances,importances[1,]); importances$kolom = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm)-1];
importances = data.frame(importance(modelRandomForest));
importances$kolom = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm)-1];
head(importances)
meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini);
importances$threshMDA[importances$MeanDecreaseAccuracy >= meanMDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= meanMDG] = 1;
head(importances)
importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= meanMDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= meanMDG] = 1;
head(importances)
meanMDA
featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1);
nrow(featuresMDA)
nrow(featuresMDG)
namaMDA = colnames(featuresMDA); namaMDG = colnames(featuresMDG);
namaMDA
featuresMDA
namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom;
namaMDA
namaMDG
train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame();
nrow(train_dataset1_normMDA)
ncol(train_dataset1_normMDA)
train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; ncol(train_dataset1_normMDA)
head(train_dataset1_normMDA)
test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon;
set.seed(12345); modelRandomForest = hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA); hitungNaiveBayes(train_dataset1_normMDA, test_dataset1_normMDA); hitungDecisionTree(train_dataset1_normMDA, test_dataset1_normMDA); modelRandomForest = hitungRandomForest(train_dataset1_normMDG, test_dataset1_normMDG); hitungNaiveBayes(train_dataset1_normMDG, test_dataset1_normMDG); hitungDecisionTree(train_dataset1_normMDG, test_dataset1_normMDG);
library(e1071); train_data_back = train_data; test_data_back = test_data; train_data = train_dataset1_normMDA; test_data = test_dataset1_normMDA; train_data5 = subset(train_data, respon == 5, select = -respon); train_data54 = subset(train_data, respon >= 4, select = -respon); train_data543 = subset(train_data, respon >= 3, select = -respon); train_data5432 = subset(train_data, respon >= 2, select = -respon); #Best nu=0.001, gamma=0.01 accuracy=78.03 #model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); #model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.001,gamma=0.01); model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); pred5 = predict(model5, subset(test_data,select=-respon)); pred4 = predict(model54, subset(test_data, select = -respon)); pred3 = predict(model543, subset(test_data, select = -respon)); pred2 = predict(model5432, subset(test_data, select = -respon)); head(pred5); head(pred4); head(pred3); head(pred2); head(test_data$respon); preds = data.frame(pred5, pred4, pred3, pred2); preds$pred = -1; for (i in 1:nrow(preds)) {     if (preds$pred5[i]) {         preds$pred[i] = 5;     } else {         if (preds$pred4[i]) {             preds$pred[i] = 4;         } else {             if (preds$pred3[i]) {                 preds$pred[i] = 3;             } else {                 if (preds$pred2[i]) {                     preds$pred[i] = 2;                 } else {                     preds$pred[i] = 1;                 }             }         }     } } preds$target = test_data$respon; confusionMatrix(preds$pred, test_data$respon); test_data %>% group_by(respon) %>% summarise(jumlah_data = n(), persentase = n() / 4679) %>% as.data.frame();
library(e1071); train_data_back = train_data; test_data_back = test_data; train_data = train_dataset1_normMDG; test_data = test_dataset1_normMDG; train_data5 = subset(train_data, respon == 5, select = -respon); train_data54 = subset(train_data, respon >= 4, select = -respon); train_data543 = subset(train_data, respon >= 3, select = -respon); train_data5432 = subset(train_data, respon >= 2, select = -respon); #Best nu=0.001, gamma=0.01 accuracy=78.03 #model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); #model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.001,gamma=0.01); model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); pred5 = predict(model5, subset(test_data,select=-respon)); pred4 = predict(model54, subset(test_data, select = -respon)); pred3 = predict(model543, subset(test_data, select = -respon)); pred2 = predict(model5432, subset(test_data, select = -respon)); head(pred5); head(pred4); head(pred3); head(pred2); head(test_data$respon); preds = data.frame(pred5, pred4, pred3, pred2); preds$pred = -1; for (i in 1:nrow(preds)) {     if (preds$pred5[i]) {         preds$pred[i] = 5;     } else {         if (preds$pred4[i]) {             preds$pred[i] = 4;         } else {             if (preds$pred3[i]) {                 preds$pred[i] = 3;             } else {                 if (preds$pred2[i]) {                     preds$pred[i] = 2;                 } else {                     preds$pred[i] = 1;                 }             }         }     } } preds$target = test_data$respon; confusionMatrix(preds$pred, test_data$respon); test_data %>% group_by(respon) %>% summarise(jumlah_data = n(), persentase = n() / 4679) %>% as.data.frame();
quantile(importances$MeanDecreaseAccuracy,1);
quantile(importances$MeanDecreaseAccuracy,2);
quantile(importances$MeanDecreaseAccuracy);
meanMDA
quantile(importances$MeanDecreaseAccuracy)[3];
quantile(importances$MeanDecreaseAccuracy)[4];
q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4];
importances = data.frame(importance(modelRandomForest)); importances = rbind(importances,importances[1,]); importances$kolom = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm)-1]; meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= q3MDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= q3MDG] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon;
importances = data.frame(importance(modelRandomForest)); importances = rbind(importances,importances[1,]); importances$kolom = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm)-1];
str(train_dataset1_norm)
importances = data.frame(importance(modelRandomForest));
importances = rbind(importances,importances[1,]);
importances$kolom = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm)-1];
baca = function(nama_file) {     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } partisi = function(input_data,response_name) {     #70/30 partition     #column response as y     colnames(input_data)[colnames(input_data) == response_name] = "respon";     partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1);     dataTrain = input_data[partition_data,];     dataTrain$tipe = "training";     dataTest = input_data[-partition_data,];     dataTest$tipe = "testing";     output_data = rbind(dataTrain, dataTest);     return(output_data); } hitungSVM2 = function(train_data,test_data, target_respon, nu_value, gamma_value) {     library(e1071);     model = svm(subset(train_data,select = -respon), train_data$respon, type = 'one-classification', nu = nu_value, gamma=gamma_value);     pred_trains = predict(model, subset(train_data,select= -respon));     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM = function(input_data,target_respon,nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification',nu=nu_value);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi = function(input_data, target_respon) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data);     x = subset(df, select = -respon);     y = as.factor(df$respon);     model = svm(x, y, probability = TRUE);     pred_train = predict(model, x, decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon),decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i,1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi2 = function(train_data,test_data, c_value, gamma_value) {     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = svm(subset(train_data,select=-respon), train_data$respon, probability = TRUE,C=c_value,gamma=gamma_value);     pred_train = predict(model, subset(train_data, select = -respon), decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon), decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungDecisionTree = function(train_data,test_data) {     library(C50);     library(printr);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     print("CHAID");     library(party);     model = ctree(respon ~ ., data = train_data);     pred = predict(model, test_data);     print(confusionMatrix(pred, test_data$respon));     print("CART");     library(rpart);     model = rpart(respon ~ ., data = train_data, method = "class");     pred = predict(model, test_data, type = "class");     print(confusionMatrix(pred, test_data$respon));     print("C50");     model = C5.0(respon ~ ., data = train_data);     results = predict(object = model, newdata = test_data, type = "class");     pred = predict(model, test_data);     print(confusionMatrix(pred, test_data$respon)); } hitungRandomForest = function(train_data, test_data) {     library(caret);     library(randomForest);     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = randomForest(respon ~ ., data = train_data,importance=TRUE);     pred = predict(model, newdata = test_data);     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon));     return(model); } hitungNaiveBayes = function(train_data,test_data) {     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = naiveBayes(respon ~ ., data = train_data)     pred = predict(model, newdata = subset(test_data, select = -respon));     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); } hitungNaiveBayes_normalization = function(train_data, test_data) {     library(e1071)     library(forecast)     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     for (i in 1:(ncol(train_data)-1)) {             train_data[, i] = BoxCox(train_data[, i], BoxCox.lambda(train_data[, i]));     }     for (i in 1:(ncol(test_data)-1)) {             test_data[, i] = BoxCox(test_data[, i], BoxCox.lambda(test_data[, i]));     }     model = naiveBayes(respon ~ ., data = train_data)     pred = predict(model, newdata = subset(test_data, select = -respon));     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); } hitungFeaturesImportance = function(train_data,test_data,modelRandomForest) {     library(dplyr);     set.seed(12345);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     importances = data.frame(importance(modelRandomForest));     kolom_train_data = colnames(train_data)[1:ncol(train_data) - 1];     importances$kolom = kolom_train_data;     importances = rbind(importances, importances[1,]);     importancesMDA = importances %>%     select(kolom, MeanDecreaseAccuracy) %>%     arrange(-MeanDecreaseAccuracy) %>%     as.data.frame();     importancesMDG = importances %>%     select(kolom, MeanDecreaseGini) %>%     arrange(-MeanDecreaseGini) %>%     as.data.frame();     importancesMDA$results = -1;     for (i in 1:nrow(importancesMDA)) {         kolom = importancesMDA$kolom[1:(nrow(importancesMDA) - i)];         train_dataset1_normMDA = train_data %>%         select(kolom) %>%         as.data.frame();         train_dataset1_normMDA$respon = as.factor(train_data$respon);         test_dataset1_normMDA = test_data %>%         select(kolom) %>%         as.data.frame();         test_dataset1_normMDA$respon = as.factor(test_data$respon);         model = randomForest(respon ~ ., data = train_data, importance = TRUE);         pred = predict(model, newdata = test_data);         hasil = confusionMatrix(pred, test_data$respon);         akurasi = as.numeric(hasil$overall[1]);         importancesMDA$results[i] = akurasi;     }     return(importancesMDA); }
library(imputeTS); library(dplyr); train_file = "Training Data.csv"; test_file = "Test Data.csv"; target_column = "manual_assessment"; train_data = baca(train_file); colnames(train_data)[colnames(train_data) == target_column] = "respon"; test_data = baca(test_file); colnames(test_data)[colnames(test_data) == target_column] = "respon"; train_data %>% filter(is.na(respon) | is.na(manual_origin_source) | is.na(origin_word_entropy)) %>% group_by(manual_origin_source,origin_word_entropy,respon) %>% summarise(jumlah_data = n()); #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(manual_origin_source) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(manual_origin_source) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= q3MDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= q3MDG] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon;
train_data = train_dataset1_normMDA; test_data = test_dataset1_normMDA; train_data5 = subset(train_data, respon == 5, select = -respon); train_data54 = subset(train_data, respon >= 4, select = -respon); train_data543 = subset(train_data, respon >= 3, select = -respon); train_data5432 = subset(train_data, respon >= 2, select = -respon); #Best nu=0.001, gamma=0.01 accuracy=78.03 #model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); #model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.001,gamma=0.01); model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); pred5 = predict(model5, subset(test_data,select=-respon)); pred4 = predict(model54, subset(test_data, select = -respon)); pred3 = predict(model543, subset(test_data, select = -respon)); pred2 = predict(model5432, subset(test_data, select = -respon)); head(pred5); head(pred4); head(pred3); head(pred2); head(test_data$respon); preds = data.frame(pred5, pred4, pred3, pred2); preds$pred = -1; for (i in 1:nrow(preds)) {     if (preds$pred5[i]) {         preds$pred[i] = 5;     } else {         if (preds$pred4[i]) {             preds$pred[i] = 4;         } else {             if (preds$pred3[i]) {                 preds$pred[i] = 3;             } else {                 if (preds$pred2[i]) {                     preds$pred[i] = 2;                 } else {                     preds$pred[i] = 1;                 }             }         }     } } preds$target = test_data$respon; confusionMatrix(preds$pred, test_data$respon); test_data %>% group_by(respon) %>% summarise(jumlah_data = n(), persentase = n() / 4679) %>% as.data.frame();
train_data = train_dataset1_normMDA; test_data = test_dataset1_normMDA; train_data5 = subset(train_data, respon == 5, select = -respon); train_data54 = subset(train_data, respon >= 4, select = -respon); train_data543 = subset(train_data, respon >= 3, select = -respon); train_data5432 = subset(train_data, respon >= 2, select = -respon); #Best nu=0.001, gamma=0.01 accuracy=78.03 #model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); #model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.001,gamma=0.01); model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.01, gamma = 0.1); model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.01, gamma = 0.1); pred5 = predict(model5, subset(test_data,select=-respon)); pred4 = predict(model54, subset(test_data, select = -respon)); pred3 = predict(model543, subset(test_data, select = -respon)); pred2 = predict(model5432, subset(test_data, select = -respon)); head(pred5); head(pred4); head(pred3); head(pred2); head(test_data$respon); preds = data.frame(pred5, pred4, pred3, pred2); preds$pred = -1; for (i in 1:nrow(preds)) {     if (preds$pred5[i]) {         preds$pred[i] = 5;     } else {         if (preds$pred4[i]) {             preds$pred[i] = 4;         } else {             if (preds$pred3[i]) {                 preds$pred[i] = 3;             } else {                 if (preds$pred2[i]) {                     preds$pred[i] = 2;                 } else {                     preds$pred[i] = 1;                 }             }         }     } } preds$target = test_data$respon; confusionMatrix(preds$pred, test_data$respon); test_data %>% group_by(respon) %>% summarise(jumlah_data = n(), persentase = n() / 4679) %>% as.data.frame();
train_data5 = subset(train_data, respon == 5, select = -respon); train_data54 = subset(train_data, respon >= 4, select = -respon); train_data543 = subset(train_data, respon >= 3, select = -respon); train_data5432 = subset(train_data, respon >= 2, select = -respon); #Best nu=0.001, gamma=0.01 accuracy=78.03 #model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); #model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.001,gamma=0.01); model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.1, gamma = 0.1); model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.1, gamma = 0.1); pred5 = predict(model5, subset(test_data,select=-respon)); pred4 = predict(model54, subset(test_data, select = -respon)); pred3 = predict(model543, subset(test_data, select = -respon)); pred2 = predict(model5432, subset(test_data, select = -respon)); head(pred5); head(pred4); head(pred3); head(pred2); head(test_data$respon); preds = data.frame(pred5, pred4, pred3, pred2); preds$pred = -1; for (i in 1:nrow(preds)) {     if (preds$pred5[i]) {         preds$pred[i] = 5;     } else {         if (preds$pred4[i]) {             preds$pred[i] = 4;         } else {             if (preds$pred3[i]) {                 preds$pred[i] = 3;             } else {                 if (preds$pred2[i]) {                     preds$pred[i] = 2;                 } else {                     preds$pred[i] = 1;                 }             }         }     } } preds$target = test_data$respon; confusionMatrix(preds$pred, test_data$respon); test_data %>% group_by(respon) %>% summarise(jumlah_data = n(), persentase = n() / 4679) %>% as.data.frame();
train_data5 = subset(train_data, respon == 5, select = -respon); train_data54 = subset(train_data, respon >= 4, select = -respon); train_data543 = subset(train_data, respon >= 3, select = -respon); train_data5432 = subset(train_data, respon >= 2, select = -respon); #Best nu=0.001, gamma=0.01 accuracy=78.03 #model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); #model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.001,gamma=0.01); model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.1, gamma = 0.01); model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.1, gamma = 0.01); pred5 = predict(model5, subset(test_data,select=-respon)); pred4 = predict(model54, subset(test_data, select = -respon)); pred3 = predict(model543, subset(test_data, select = -respon)); pred2 = predict(model5432, subset(test_data, select = -respon)); head(pred5); head(pred4); head(pred3); head(pred2); head(test_data$respon); preds = data.frame(pred5, pred4, pred3, pred2); preds$pred = -1; for (i in 1:nrow(preds)) {     if (preds$pred5[i]) {         preds$pred[i] = 5;     } else {         if (preds$pred4[i]) {             preds$pred[i] = 4;         } else {             if (preds$pred3[i]) {                 preds$pred[i] = 3;             } else {                 if (preds$pred2[i]) {                     preds$pred[i] = 2;                 } else {                     preds$pred[i] = 1;                 }             }         }     } } preds$target = test_data$respon; confusionMatrix(preds$pred, test_data$respon); test_data %>% group_by(respon) %>% summarise(jumlah_data = n(), persentase = n() / 4679) %>% as.data.frame();
train_data5 = subset(train_data, respon == 5, select = -respon); train_data54 = subset(train_data, respon >= 4, select = -respon); train_data543 = subset(train_data, respon >= 3, select = -respon); train_data5432 = subset(train_data, respon >= 2, select = -respon); #Best nu=0.001, gamma=0.01 accuracy=78.03 #model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); #model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.1,gamma=0.01); model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.1, gamma = 0.01); model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.1, gamma = 0.01); model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.1, gamma = 0.01); pred5 = predict(model5, subset(test_data,select=-respon)); pred4 = predict(model54, subset(test_data, select = -respon)); pred3 = predict(model543, subset(test_data, select = -respon)); pred2 = predict(model5432, subset(test_data, select = -respon)); head(pred5); head(pred4); head(pred3); head(pred2); head(test_data$respon); preds = data.frame(pred5, pred4, pred3, pred2); preds$pred = -1; for (i in 1:nrow(preds)) {     if (preds$pred5[i]) {         preds$pred[i] = 5;     } else {         if (preds$pred4[i]) {             preds$pred[i] = 4;         } else {             if (preds$pred3[i]) {                 preds$pred[i] = 3;             } else {                 if (preds$pred2[i]) {                     preds$pred[i] = 2;                 } else {                     preds$pred[i] = 1;                 }             }         }     } } preds$target = test_data$respon; confusionMatrix(preds$pred, test_data$respon); test_data %>% group_by(respon) %>% summarise(jumlah_data = n(), persentase = n() / 4679) %>% as.data.frame();
train_data5 = subset(train_data, respon == 5, select = -respon); train_data54 = subset(train_data, respon >= 4, select = -respon); train_data543 = subset(train_data, respon >= 3, select = -respon); train_data5432 = subset(train_data, respon >= 2, select = -respon); #Best nu=0.001, gamma=0.01 accuracy=78.03 #model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); #model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.1,gamma=0.01); model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.1, gamma = 1); model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.1, gamma = 0.01); model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.1, gamma = 1); pred5 = predict(model5, subset(test_data,select=-respon)); pred4 = predict(model54, subset(test_data, select = -respon)); pred3 = predict(model543, subset(test_data, select = -respon)); pred2 = predict(model5432, subset(test_data, select = -respon)); head(pred5); head(pred4); head(pred3); head(pred2); head(test_data$respon); preds = data.frame(pred5, pred4, pred3, pred2); preds$pred = -1; for (i in 1:nrow(preds)) {     if (preds$pred5[i]) {         preds$pred[i] = 5;     } else {         if (preds$pred4[i]) {             preds$pred[i] = 4;         } else {             if (preds$pred3[i]) {                 preds$pred[i] = 3;             } else {                 if (preds$pred2[i]) {                     preds$pred[i] = 2;                 } else {                     preds$pred[i] = 1;                 }             }         }     } } preds$target = test_data$respon; confusionMatrix(preds$pred, test_data$respon); test_data %>% group_by(respon) %>% summarise(jumlah_data = n(), persentase = n() / 4679) %>% as.data.frame();
ncol(train_dataset1_normMDG)
ncol(train_dataset1_normMDA)
q3MDA
meanMDA
ncol(train_dataset1_norm)
quantile(importances$MeanDecreaseAccuracy,10)
quantile(importances$MeanDecreaseAccuracy)
quantile(importances$MeanDecreaseAccuracy,.80)
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = as.numeric(quantile(importances$MeanDecreaseAccuracy,0.8)); q80MDG = as.numeric(quantile(importances$MeanDecreaseGini),0.8); q85MDA = as.numeric(quantile(importances$MeanDecreaseAccuracy, 0.85)); q85MDG = as.numeric(quantile(importances$MeanDecreaseGini), 0.85); q90MDA = as.numeric(quantile(importances$MeanDecreaseAccuracy, 0.9)); q90MDG = as.numeric(quantile(importances$MeanDecreaseGini), 0.9); q95MDA = as.numeric(quantile(importances$MeanDecreaseAccuracy, 0.95)); q95MDG = as.numeric(quantile(importances$MeanDecreaseGini), 0.95); importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= q95MDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= q95MDG] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = as.numeric(quantile(importances$MeanDecreaseAccuracy,0.8)); q80MDG = as.numeric(quantile(importances$MeanDecreaseGini),0.8); q85MDA = as.numeric(quantile(importances$MeanDecreaseAccuracy, 0.85)); q85MDG = as.numeric(quantile(importances$MeanDecreaseGini), 0.85); q90MDA = as.numeric(quantile(importances$MeanDecreaseAccuracy, 0.9)); q90MDG = as.numeric(quantile(importances$MeanDecreaseGini), 0.9); q95MDA = as.numeric(quantile(importances$MeanDecreaseAccuracy, 0.95)); q95MDG = as.numeric(quantile(importances$MeanDecreaseGini), 0.95); importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= q90MDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= q90MDG] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = as.numeric(quantile(importances$MeanDecreaseAccuracy,0.8)); q80MDG = as.numeric(quantile(importances$MeanDecreaseGini),0.8); q85MDA = as.numeric(quantile(importances$MeanDecreaseAccuracy, 0.85)); q85MDG = as.numeric(quantile(importances$MeanDecreaseGini), 0.85); q90MDA = as.numeric(quantile(importances$MeanDecreaseAccuracy, 0.9)); q90MDG = as.numeric(quantile(importances$MeanDecreaseGini), 0.9); q95MDA = as.numeric(quantile(importances$MeanDecreaseAccuracy, 0.95)); q95MDG = as.numeric(quantile(importances$MeanDecreaseGini), 0.95); importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= q90MDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= q90MDG] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = as.numeric(quantile(importances$MeanDecreaseAccuracy,0.8)); q80MDG = as.numeric(quantile(importances$MeanDecreaseGini),0.8); q85MDA = as.numeric(quantile(importances$MeanDecreaseAccuracy, 0.85)); q85MDG = as.numeric(quantile(importances$MeanDecreaseGini), 0.85); q90MDA = as.numeric(quantile(importances$MeanDecreaseAccuracy, 0.9)); q90MDG = as.numeric(quantile(importances$MeanDecreaseGini), 0.9); q95MDA = as.numeric(quantile(importances$MeanDecreaseAccuracy, 0.95)); q95MDG = as.numeric(quantile(importances$MeanDecreaseGini), 0.95); importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= meanMDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= meanMDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85)); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9)); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95)); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= q90MDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= q90MDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= q90MDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= q90MDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= q95MDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= q95MDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
ncol(train_dataset1_normMDA)
q95MDA
ncol(importance)
ncol(importances)
head(importances)
str(train_dataset1_normMDA)
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q98MDA = quantile(importances$MeanDecreaseAccuracy, 0.98); q98MDG = quantile(importances$MeanDecreaseGini, 0.98); importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= q98MDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= q98MDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
ncol(train_dataset1_normMDA)
str(train_dataset1_normMDA)
q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q96MDA = quantile(importances$MeanDecreaseAccuracy, 0.96); q96MDG = quantile(importances$MeanDecreaseGini, 0.96); q97MDA = quantile(importances$MeanDecreaseAccuracy, 0.97); q97MDG = quantile(importances$MeanDecreaseGini, 0.97);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q96MDA = quantile(importances$MeanDecreaseAccuracy, 0.96); q96MDG = quantile(importances$MeanDecreaseGini, 0.96); q97MDA = quantile(importances$MeanDecreaseAccuracy, 0.97); q97MDG = quantile(importances$MeanDecreaseGini, 0.97); q98MDA = quantile(importances$MeanDecreaseAccuracy, 0.98); q98MDG = quantile(importances$MeanDecreaseGini, 0.98); importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= q96MDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= q96MDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
str(train_dataset1_normMDA)
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q96MDA = quantile(importances$MeanDecreaseAccuracy, 0.96); q96MDG = quantile(importances$MeanDecreaseGini, 0.96); q97MDA = quantile(importances$MeanDecreaseAccuracy, 0.97); q97MDG = quantile(importances$MeanDecreaseGini, 0.97); q98MDA = quantile(importances$MeanDecreaseAccuracy, 0.98); q98MDG = quantile(importances$MeanDecreaseGini, 0.98); importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= q97MDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= q97MDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q 95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q96MDA = quantile(importances$MeanDecreaseAccuracy, 0.96); q96MDG = quantile(importances$MeanDecreaseGini, 0.96); q97MDA = quantile(importances$MeanDecreaseAccuracy, 0.97); q97MDG = quantile(importances$MeanDecreaseGini, 0.97); q98MDA = quantile(importances$MeanDecreaseAccuracy, 0.98); q98MDG = quantile(importances$MeanDecreaseGini, 0.98); importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= q97MDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= q97MDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q96MDA = quantile(importances$MeanDecreaseAccuracy, 0.96); q96MDG = quantile(importances$MeanDecreaseGini, 0.96); q97MDA = quantile(importances$MeanDecreaseAccuracy, 0.97); q97MDG = quantile(importances$MeanDecreaseGini, 0.97); q98MDA = quantile(importances$MeanDecreaseAccuracy, 0.98); q98MDG = quantile(importances$MeanDecreaseGini, 0.98); importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= q97MDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= q97MDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
str(train_dataset1_normMDA)
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q96MDA = quantile(importances$MeanDecreaseAccuracy, 0.96); q96MDG = quantile(importances$MeanDecreaseGini, 0.96); q97MDA = quantile(importances$MeanDecreaseAccuracy, 0.97); q97MDG = quantile(importances$MeanDecreaseGini, 0.97); q98MDA = quantile(importances$MeanDecreaseAccuracy, 0.98); q98MDG = quantile(importances$MeanDecreaseGini, 0.98); importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= q95MDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= q95MDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q96MDA = quantile(importances$MeanDecreaseAccuracy, 0.96); q96MDG = quantile(importances$MeanDecreaseGini, 0.96); q97MDA = quantile(importances$MeanDecreaseAccuracy, 0.97); q97MDG = quantile(importances$MeanDecreaseGini, 0.97); q98MDA = quantile(importances$MeanDecreaseAccuracy, 0.98); q98MDG = quantile(importances$MeanDecreaseGini, 0.98); importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= q96MDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= q96MDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
set.seed(12345); modelRandomForest = hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA); hitungNaiveBayes(train_dataset1_normMDA, test_dataset1_normMDA); hitungDecisionTree(train_dataset1_normMDA, test_dataset1_normMDA);
install.packages("partykit");
library(party)
baca = function(nama_file) {     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } partisi = function(input_data,response_name) {     #70/30 partition     #column response as y     colnames(input_data)[colnames(input_data) == response_name] = "respon";     partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1);     dataTrain = input_data[partition_data,];     dataTrain$tipe = "training";     dataTest = input_data[-partition_data,];     dataTest$tipe = "testing";     output_data = rbind(dataTrain, dataTest);     return(output_data); } hitungSVM2 = function(train_data,test_data, target_respon, nu_value, gamma_value) {     library(e1071);     model = svm(subset(train_data,select = -respon), train_data$respon, type = 'one-classification', nu = nu_value, gamma=gamma_value);     pred_trains = predict(model, subset(train_data,select= -respon));     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM = function(input_data,target_respon,nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification',nu=nu_value);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi = function(input_data, target_respon) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data);     x = subset(df, select = -respon);     y = as.factor(df$respon);     model = svm(x, y, probability = TRUE);     pred_train = predict(model, x, decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon),decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i,1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi2 = function(train_data,test_data, c_value, gamma_value) {     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = svm(subset(train_data,select=-respon), train_data$respon, probability = TRUE,C=c_value,gamma=gamma_value);     pred_train = predict(model, subset(train_data, select = -respon), decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon), decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungDecisionTree = function(train_data,test_data) {     library(C50);     library(printr);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     print("CHAID");     library(party);     model = ctree(respon ~ ., data = train_data);     pred = predict(model, test_data);     print(confusionMatrix(pred, test_data$respon));     print("CART");     library(rpart);     model = rpart(respon ~ ., data = train_data, method = "class");     pred = predict(model, test_data, type = "class");     print(confusionMatrix(pred, test_data$respon));     print("C50");     model = C5.0(respon ~ ., data = train_data);     results = predict(object = model, newdata = test_data, type = "class");     pred = predict(model, test_data);     print(confusionMatrix(pred, test_data$respon)); } hitungRandomForest = function(train_data, test_data) {     library(caret);     library(randomForest);     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = randomForest(respon ~ ., data = train_data,importance=TRUE);     pred = predict(model, newdata = test_data);     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon));     return(model); } hitungNaiveBayes = function(train_data,test_data) {     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = naiveBayes(respon ~ ., data = train_data)     pred = predict(model, newdata = subset(test_data, select = -respon));     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); } hitungNaiveBayes_normalization = function(train_data, test_data) {     library(e1071)     library(forecast)     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     for (i in 1:(ncol(train_data)-1)) {             train_data[, i] = BoxCox(train_data[, i], BoxCox.lambda(train_data[, i]));     }     for (i in 1:(ncol(test_data)-1)) {             test_data[, i] = BoxCox(test_data[, i], BoxCox.lambda(test_data[, i]));     }     model = naiveBayes(respon ~ ., data = train_data)     pred = predict(model, newdata = subset(test_data, select = -respon));     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); } hitungFeaturesImportance = function(train_data,test_data,modelRandomForest) {     library(dplyr);     set.seed(12345);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     importances = data.frame(importance(modelRandomForest));     kolom_train_data = colnames(train_data)[1:ncol(train_data) - 1];     importances$kolom = kolom_train_data;     importances = rbind(importances, importances[1,]);     importancesMDA = importances %>%     select(kolom, MeanDecreaseAccuracy) %>%     arrange(-MeanDecreaseAccuracy) %>%     as.data.frame();     importancesMDG = importances %>%     select(kolom, MeanDecreaseGini) %>%     arrange(-MeanDecreaseGini) %>%     as.data.frame();     importancesMDA$results = -1;     for (i in 1:nrow(importancesMDA)) {         kolom = importancesMDA$kolom[1:(nrow(importancesMDA) - i)];         train_dataset1_normMDA = train_data %>%         select(kolom) %>%         as.data.frame();         train_dataset1_normMDA$respon = as.factor(train_data$respon);         test_dataset1_normMDA = test_data %>%         select(kolom) %>%         as.data.frame();         test_dataset1_normMDA$respon = as.factor(test_data$respon);         model = randomForest(respon ~ ., data = train_data, importance = TRUE);         pred = predict(model, newdata = test_data);         hasil = confusionMatrix(pred, test_data$respon);         akurasi = as.numeric(hasil$overall[1]);         importancesMDA$results[i] = akurasi;     }     return(importancesMDA); }
set.seed(12345); modelRandomForest = hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA); hitungNaiveBayes(train_dataset1_normMDA, test_dataset1_normMDA); hitungDecisionTree(train_dataset1_normMDA, test_dataset1_normMDA);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q96MDA = quantile(importances$MeanDecreaseAccuracy, 0.96); q96MDG = quantile(importances$MeanDecreaseGini, 0.96); q97MDA = quantile(importances$MeanDecreaseAccuracy, 0.97); q97MDG = quantile(importances$MeanDecreaseGini, 0.97); q98MDA = quantile(importances$MeanDecreaseAccuracy, 0.98); q98MDG = quantile(importances$MeanDecreaseGini, 0.98); importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= q98MDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= q98MDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q96MDA = quantile(importances$MeanDecreaseAccuracy, 0.96); q96MDG = quantile(importances$MeanDecreaseGini, 0.96); q97MDA = quantile(importances$MeanDecreaseAccuracy, 0.97); q97MDG = quantile(importances$MeanDecreaseGini, 0.97); q98MDA = quantile(importances$MeanDecreaseAccuracy, 0.98); q98MDG = quantile(importances$MeanDecreaseGini, 0.98); importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= q98MDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= q98MDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
nrow(train_data)
nrow(train_dataset1_norm)
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q96MDA = quantile(importances$MeanDecreaseAccuracy, 0.96); q96MDG = quantile(importances$MeanDecreaseGini, 0.96); q97MDA = quantile(importances$MeanDecreaseAccuracy, 0.97); q97MDG = quantile(importances$MeanDecreaseGini, 0.97); q98MDA = quantile(importances$MeanDecreaseAccuracy, 0.98); q98MDG = quantile(importances$MeanDecreaseGini, 0.98); importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= meanMDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= meanMDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
nrow(train_dataset1_norm)
library(imputeTS); library(dplyr); train_file = "Training Data.csv"; test_file = "Test Data.csv"; target_column = "manual_assessment"; train_data = baca(train_file); colnames(train_data)[colnames(train_data) == target_column] = "respon"; test_data = baca(test_file); colnames(test_data)[colnames(test_data) == target_column] = "respon"; train_data %>% filter(is.na(respon) | is.na(manual_origin_source) | is.na(origin_word_entropy)) %>% group_by(manual_origin_source,origin_word_entropy,respon) %>% summarise(jumlah_data = n()); #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(manual_origin_source) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(manual_origin_source) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
str(train_data)
library(imputeTS); library(dplyr); train_file = "Training Data.csv"; test_file = "Test Data.csv"; target_column = "manual_assessment"; train_data = baca(train_file); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; test_data = baca(test_file); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; train_data %>% filter(is.na(respon) | is.na(manual_origin_source) | is.na(origin_word_entropy)) %>% group_by(manual_origin_source,origin_word_entropy,respon) %>% summarise(jumlah_data = n()); #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(manual_origin_source) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(manual_origin_source) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
library(imputeTS); library(dplyr); train_file = "Training Data.csv"; test_file = "Test Data.csv"; target_column = "manual_assessment"; train_data = baca(train_file); colnames(train_data)[colnames(train_data) == target_column] = "respon";
str(train_data)
library(imputeTS); library(dplyr); train_file = "Training Data.csv"; test_file = "Test Data.csv"; target_column = "manual_assessment"; train_data = baca(train_file); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; test_data = baca(test_file); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL;
str(train_data)
library(imputeTS); library(dplyr); train_file = "Training Data.csv"; test_file = "Test Data.csv"; target_column = "manual_assessment"; train_data = baca(train_file); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; test_data = baca(test_file); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; train_data %>% filter(is.na(respon) | is.na(manual_origin_source) | is.na(origin_word_entropy)) %>% group_by(manual_origin_source,origin_word_entropy,respon) %>% summarise(jumlah_data = n()); #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(manual_origin_source) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(manual_origin_source) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
library(imputeTS); library(dplyr); train_file = "Training Data.csv"; test_file = "Test Data.csv"; target_column = "manual_assessment"; train_data = baca(train_file); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; test_data = baca(test_file); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(manual_origin_source, origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(manual_origin_source) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
library(imputeTS); library(dplyr); train_file = "Training Data.csv"; test_file = "Test Data.csv"; target_column = "manual_assessment"; train_data = baca(train_file); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; test_data = baca(test_file); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(manual_origin_source, origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
library(imputeTS); library(dplyr); train_file = "Training Data.csv"; test_file = "Test Data.csv"; target_column = "manual_assessment"; train_data = baca(train_file); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; test_data = baca(test_file); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
set.seed(12345); modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm); hitungNaiveBayes(train_dataset1_norm, test_dataset1_norm); hitungDecisionTree(train_dataset1_norm, test_dataset1_norm);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q96MDA = quantile(importances$MeanDecreaseAccuracy, 0.96); q96MDG = quantile(importances$MeanDecreaseGini, 0.96); q97MDA = quantile(importances$MeanDecreaseAccuracy, 0.97); q97MDG = quantile(importances$MeanDecreaseGini, 0.97); q98MDA = quantile(importances$MeanDecreaseAccuracy, 0.98); q98MDG = quantile(importances$MeanDecreaseGini, 0.98); importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= meanMDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= meanMDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
str(train_dataset1_norm)
library(imputeTS); library(dplyr); train_file = "Training Data.csv"; test_file = "Test Data.csv"; target_column = "manual_assessment"; train_data = baca(train_file); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; test_data = baca(test_file); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
set.seed(12345); modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm); hitungNaiveBayes(train_dataset1_norm, test_dataset1_norm); hitungDecisionTree(train_dataset1_norm, test_dataset1_norm);
library(keras)
cifar = dataset_cifar10()
train_x <- cifar$train$x / 255 #convert a vector class to binary class matrix #converting the target variable to once hot encoded vectors using #keras inbuilt function 'to_categorical() train_y <- to_categorical(cifar$train$y, num_classes = 10) #TEST DATA test_x <- cifar$test$x / 255 test_y <- to_categorical(cifar$test$y, num_classes = 10)
model <- keras_model_sequential() #configuring the Model model %>% #defining a 2-D convolution layer layer_conv_2d(filter = 32, kernel_size = c(3, 3), padding = "same", input_shape = c(32, 32, 3)) %>% layer_activation("relu") %>% #another 2-D convolution layer layer_conv_2d(filter = 32, kernel_size = c(3, 3)) %>% layer_activation("relu") %>% #Defining a Pooling layer which reduces the dimentions of the #features map and reduces the computational complexity of the model layer_max_pooling_2d(pool_size = c(2, 2)) %>% #dropout layer to avoid overfitting layer_dropout(0.25) %>% layer_conv_2d(filter = 32, kernel_size = c(3, 3), padding = "same") %>% layer_activation("relu") %>% layer_conv_2d(filter = 32, kernel_size = c(3, 3)) %>% layer_activation("relu") %>% layer_max_pooling_2d(pool_size = c(2, 2)) %>% layer_dropout(0.25) %>% #flatten the input   layer_flatten() %>% layer_dense(512) %>% layer_activation("relu") %>% layer_dropout(0.5) %>% #output layer-10 classes-10 units   layer_dense(10) %>% #applying softmax nonlinear activation function to the output layer #to calculate cross-entropy   layer_activation("softmax")
opt <- optimizer_adam(lr = 0.0001, decay = 1e-6) #lr-learning rate , decay - learning rate decay over each update model %>%  compile(loss = "categorical_crossentropy",  optimizer = opt, metrics = "accuracy") #Summary of the Model and its Architecture summary(model)
data_augmentation <- TRUE if (!data_augmentation) {     model %>% fit(train_x, train_y, batch_size = 32,                epochs = 80, validation_data = list(test_x, test_y),                shuffle = TRUE) } else {     #Generating images     gen_images <- image_data_generator(featurewise_center = TRUE,       featurewise_std_normalization = TRUE,       rotation_range = 20,       width_shift_range = 0.30,       height_shift_range = 0.30,       horizontal_flip = TRUE)     #Fit image data generator internal statistics to some sample data     gen_images %>% fit_image_data_generator(train_x)     #Generates batches of augmented/normalized data from image data and #labels to visually see the generated images by the Model     model %>% fit_generator(      flow_images_from_data(train_x, train_y, gen_images,      batch_size = 32, save_to_dir = "F:/PROJECTS/CNNcifarimages/"),      steps_per_epoch = as.integer(50000 / 32), epochs = 80,      validation_data = list(test_x, test_y)) }
cifar <- dataset_cifar10() #TRAINING DATA train_x <- cifar$train$x / 255 #convert a vector class to binary class matrix #converting the target variable to once hot encoded vectors using #keras inbuilt function 'to_categorical() train_y <- to_categorical(cifar$train$y, num_classes = 10) #TEST DATA test_x <- cifar$test$x / 255 test_y <- to_categorical(cifar$test$y, num_classes = 10) #checking the dimentions dim(train_x) cat("No of training samples\t", dim(train_x)[[1]], "\tNo of test samples\t", dim(test_x)[[1]]) #a linear stack of layers model <- keras_model_sequential() #configuring the Model model %>% #defining a 2-D convolution layer layer_conv_2d(filter = 32, kernel_size = c(3, 3), padding = "same", input_shape = c(32, 32, 3)) %>% layer_activation("relu") %>% #another 2-D convolution layer layer_conv_2d(filter = 32, kernel_size = c(3, 3)) %>% layer_activation("relu") %>% #Defining a Pooling layer which reduces the dimentions of the #features map and reduces the computational complexity of the model layer_max_pooling_2d(pool_size = c(2, 2)) %>% #dropout layer to avoid overfitting layer_dropout(0.25) %>% layer_conv_2d(filter = 32, kernel_size = c(3, 3), padding = "same") %>% layer_activation("relu") %>% layer_conv_2d(filter = 32, kernel_size = c(3, 3)) %>% layer_activation("relu") %>% layer_max_pooling_2d(pool_size = c(2, 2)) %>% layer_dropout(0.25) %>% #flatten the input   layer_flatten() %>% layer_dense(512) %>% layer_activation("relu") %>% layer_dropout(0.5) %>% #output layer-10 classes-10 units   layer_dense(10) %>% #applying softmax nonlinear activation function to the output layer #to calculate cross-entropy   layer_activation("softmax") #for computing Probabilities of classes-"logit(log probabilities) #Model's Optimizer #defining the type of optimizer-ADAM-Adaptive Momentum Estimation opt <- optimizer_adam(lr = 0.0001, decay = 1e-6) #lr-learning rate , decay - learning rate decay over each update model %>%  compile(loss = "categorical_crossentropy",  optimizer = opt, metrics = "accuracy") #Summary of the Model and its Architecture summary(model) #TRAINING PROCESS OF THE MODEL data_augmentation <- TRUE if (!data_augmentation) {     model %>% fit(train_x, train_y, batch_size = 32,                epochs = 80, validation_data = list(test_x, test_y),                shuffle = TRUE) } else {     #Generating images     gen_images <- image_data_generator(featurewise_center = TRUE,       featurewise_std_normalization = TRUE,       rotation_range = 20,       width_shift_range = 0.30,       height_shift_range = 0.30,       horizontal_flip = TRUE)     #Fit image data generator internal statistics to some sample data     gen_images %>% fit_image_data_generator(train_x)     #Generates batches of augmented/normalized data from image data and #labels to visually see the generated images by the Model     model %>% fit_generator(      flow_images_from_data(train_x, train_y, gen_images,      batch_size = 32, save_to_dir = "F:/PROJECTS/CNNcifarimages/"),      steps_per_epoch = as.integer(50000 / 32), epochs = 80,      validation_data = list(test_x, test_y)) }
head(cifar)
?dataset_cifar10
library(keras)
boston <- load_boston_housing()
attach(Boston)
attach(boston)
data(iris)
head(iris)
str(iris)
# Build your own `normalize()` function
normalize <- function(x) {
    num <- x - min(x)
    denom <- max(x) - min(x)
    return(num / denom)
};
# Normalize the `iris` data
iris_norm <- as.data.frame(lapply(iris[1:4], normalize));
iris[, 5] <- as.numeric(iris[, 5]) - 1;
# Turn `iris` into a matrix
iris <- as.matrix(iris);
# Set iris `dimnames` to `NULL`
dimnames(iris) <- NULL;
normalize <- function(x) {
    num <- x - min(x)
    denom <- max(x) - min(x)
    return(num / denom)
};
# Normalize the `iris` data
iris_norm <- as.data.frame(lapply(iris[1:4], normalize));
iris[, 5] <- as.numeric(iris[, 5]) - 1;
# Turn `iris` into a matrix
iris <- as.matrix(iris);
# Set iris `dimnames` to `NULL`
dimnames(iris) <- NULL; # Normalize the `iris` data
iris <- normalize(iris[, 1:4])
# Return the summary of `iris`
summary(iris); # Determine sample size
ind <- sample(2, nrow(iris), replace = TRUE, prob = c(0.67, 0.33))
# Split the `iris` data
iris.training <- iris[ind == 1, 1:4]
iris.test <- iris[ind == 2, 1:4]
# Split the class attribute
iris.trainingtarget <- iris[ind == 1, 5]
iris.testtarget <- iris[ind == 2, 5] # One hot encode training target values
iris.trainLabels <- to_categorical(iris.trainingtarget)
# One hot encode test target values
iris.testLabels <- to_categorical(iris.testtarget)
# Print out the iris.testLabels to double check the result
print(iris.testLabels)
# Build your own `normalize()` function
normalize <- function(x) {
    num <- x - min(x)
    denom <- max(x) - min(x)
    return(num / denom)
};
# Normalize the `iris` data
iris_norm <- as.data.frame(lapply(iris[1:4], normalize));
iris[, 5] <- as.numeric(iris[, 5]) - 1;
# Turn `iris` into a matrix
iris <- as.matrix(iris);
# Set iris `dimnames` to `NULL`
dimnames(iris) <- NULL; # Normalize the `iris` data
iris <- normalize(iris[, 1:4])
# Return the summary of `iris`
summary(iris); # Determine sample size
ind <- sample(2, nrow(iris), replace = TRUE, prob = c(0.67, 0.33))
# Split the `iris` data
iris.training <- iris[ind == 1, 1:4]
iris.test <- iris[ind == 2, 1:4]
# Build your own `normalize()` function
normalize <- function(x) {
    num <- x - min(x)
    denom <- max(x) - min(x)
    return(num / denom)
};
# Normalize the `iris` data
iris_norm <- as.data.frame(lapply(iris[1:4], normalize));
iris[, 5] <- as.numeric(iris[, 5]) - 1;
# Turn `iris` into a matrix
iris <- as.matrix(iris);
# Set iris `dimnames` to `NULL`
dimnames(iris) <- NULL; # Normalize the `iris` data
iris <- normalize(iris[, 1:4])
# Return the summary of `iris`
summary(iris); # Determine sample size
ind <- sample(2, nrow(iris), replace = TRUE, prob = c(0.67, 0.33))
# Split the `iris` data
iris.training <- iris[ind == 1, 1:4]
iris.test <- iris[ind == 2, 1:4]
data(iris); # Build your own `normalize()` function
normalize <- function(x) {
    num <- x - min(x)
    denom <- max(x) - min(x)
    return(num / denom)
};
# Normalize the `iris` data
iris_norm <- as.data.frame(lapply(iris[1:4], normalize));
iris[, 5] <- as.numeric(iris[, 5]) - 1;
# Turn `iris` into a matrix
iris <- as.matrix(iris);
# Set iris `dimnames` to `NULL`
dimnames(iris) <- NULL; # Normalize the `iris` data
iris <- normalize(iris[, 1:4])
# Return the summary of `iris`
summary(iris); # Determine sample size
ind <- sample(2, nrow(iris), replace = TRUE, prob = c(0.67, 0.33))
# Split the `iris` data
iris.training <- iris[ind == 1, 1:4]
iris.test <- iris[ind == 2, 1:4]
# Split the class attribute
iris.trainingtarget <- iris[ind == 1, 5]
iris.testtarget <- iris[ind == 2, 5] # One hot encode training target values
iris.trainLabels <- to_categorical(iris.trainingtarget)
# One hot encode test target values
iris.testLabels <- to_categorical(iris.testtarget)
# Print out the iris.testLabels to double check the result
print(iris.testLabels)
head(iris)
data(iris); # Build your own `normalize()` function
normalize <- function(x) {
    num <- x - min(x)
    denom <- max(x) - min(x)
    return(num / denom)
};
# Normalize the `iris` data
iris_norm <- as.data.frame(lapply(iris[1:4], normalize));
iris[, 5] <- as.numeric(iris[, 5]) - 1;
# Turn `iris` into a matrix
iris <- as.matrix(iris);
# Set iris `dimnames` to `NULL`
dimnames(iris) <- NULL; # Normalize the `iris` data
iris <- normalize(iris[, 1:4])
# Return the summary of `iris`
summary(iris); # Determine sample size
ind <- sample(2, nrow(iris), replace = TRUE, prob = c(0.67, 0.33))
# Split the `iris` data
iris.training <- iris[ind == 1, 1:4]
iris.test <- iris[ind == 2, 1:4]
head(iris)
# Split the class attribute
iris.trainingtarget <- iris[ind == 1, 5]
iris.testtarget <- iris[ind == 2, 5]
data(iris); # Build your own `normalize()` function
normalize <- function(x) {
    num <- x - min(x)
    denom <- max(x) - min(x)
    return(num / denom)
};
# Normalize the `iris` data
iris_norm <- as.data.frame(lapply(iris[1:4], normalize));
iris[, 5] <- as.numeric(iris[, 5]) - 1;
# Turn `iris` into a matrix
iris <- as.matrix(iris);
# Set iris `dimnames` to `NULL`
dimnames(iris) <- NULL; # Normalize the `iris` data
iris <- normalize(iris[, 1:4])
# Return the summary of `iris`
summary(iris);
head(iris)
data(iris); # Build your own `normalize()` function
normalize <- function(x) {
    num <- x - min(x)
    denom <- max(x) - min(x)
    return(num / denom)
};
# Normalize the `iris` data
iris_norm <- as.data.frame(lapply(iris[1:4], normalize));
iris[, 5] <- as.numeric(iris[, 5]) - 1;
# Turn `iris` into a matrix
iris <- as.matrix(iris);
# Set iris `dimnames` to `NULL`
dimnames(iris) <- NULL;
head(iris)
data(iris); # Build your own `normalize()` function
normalize <- function(x) {
    num <- x - min(x)
    denom <- max(x) - min(x)
    return(num / denom)
};
# Normalize the `iris` data
iris_norm <- as.data.frame(lapply(iris[1:4], normalize));
iris[, 5] <- as.numeric(iris[, 5]) - 1;
# Turn `iris` into a matrix
iris <- as.matrix(iris);
# Set iris `dimnames` to `NULL`
dimnames(iris) <- NULL; # Normalize the `iris` data
iris2 <- normalize(iris[, 1:4])
head(iris2)
# Determine sample size
ind <- sample(2, nrow(iris2), replace = TRUE, prob = c(0.67, 0.33))
head(ind)
# Split the class attribute
iris.trainingtarget <- iris2[ind == 1, 5]
iris.testtarget <- iris2[ind == 2, 5]
# Split the `iris` data
iris.training <- iris2[ind == 1, 1:4]
iris.test <- iris2[ind == 2, 1:4]
# Split the class attribute
iris.trainingtarget <- iris[ind == 1, 5]
iris.testtarget <- iris[ind == 2, 5]
head(iris)
head(iris.trainingtarget)
# One hot encode training target values
iris.trainLabels <- to_categorical(iris.trainingtarget)
# One hot encode test target values
iris.testLabels <- to_categorical(iris.testtarget)
head(iris.trainLabels)
print(iris.testLabels)
data(iris); # Build your own `normalize()` function
normalize <- function(x) {
    num <- x - min(x)
    denom <- max(x) - min(x)
    return(num / denom)
};
# Normalize the `iris` data
iris_norm <- as.data.frame(lapply(iris[1:4], normalize));
iris[, 5] <- as.numeric(iris[, 5]) - 1;
# Turn `iris` into a matrix
iris <- as.matrix(iris);
# Set iris `dimnames` to `NULL`
dimnames(iris) <- NULL; # Normalize the `iris` data
iris2 <- normalize(iris[, 1:4])
# Return the summary of `iris`
summary(iris2); # Determine sample size
ind <- sample(2, nrow(iris2), replace = TRUE, prob = c(0.67, 0.33))
# Split the `iris` data
iris.training <- iris2[ind == 1, 1:4]
iris.test <- iris2[ind == 2, 1:4]
# Split the class attribute
iris.trainingtarget <- iris[ind == 1, 5]
iris.testtarget <- iris[ind == 2, 5] # One hot encode training target values
iris.trainLabels <- to_categorical(iris.trainingtarget)
# One hot encode test target values
iris.testLabels <- to_categorical(iris.testtarget)
# Print out the iris.testLabels to double check the result
print(iris.testLabels) # Initialize a sequential model
model <- keras_model_sequential()
# Add layers to the model
model %>%
    layer_dense(units = 8, activation = 'relu', input_shape = c(4)) %>%
    layer_dense(units = 3, activation = 'softmax') # Print a summary of a model
summary(model)
# Get model configuration
get_config(model)
# Get layer configuration
get_layer(model, index = 1)
# List the model's layers
model$layers
# List the input tensors
model$inputs
# List the output tensors
model$outputs # Compile the model
model %>% compile(
     loss = 'categorical_crossentropy',
     optimizer = 'adam',
     metrics = 'accuracy'
 ) # Fit the model 
model %>% fit(
     iris.training,
     iris.trainLabels,
     epochs = 200,
     batch_size = 5,
     validation_split = 0.2
 ) # Store the fitting history in `history` 
history <- model %>% fit(
     iris.training,
     iris.trainLabels,
     epochs = 200,
     batch_size = 5,
     validation_split = 0.2
 )
# Plot the history
plot(history)
# Plot the model loss of the training data
plot(history$metrics$loss, main = "Model Loss", xlab = "epoch", ylab = "loss", col = "blue", type = "l")
# Plot the model loss of the test data
lines(history$metrics$val_loss, col = "green")
# Add legend
legend("topright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))
# Plot the accuracy of the training data 
plot(history$metrics$acc, main = "Model Accuracy", xlab = "epoch", ylab = "accuracy", col = "blue", type = "l")
# Plot the accuracy of the validation data
lines(history$metrics$val_acc, col = "green")
# Add Legend
legend("bottomright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))
# Initialize a sequential model
model <- keras_model_sequential()
# Add layers to the model
model %>%
    layer_dense(units = 8, activation = 'relu', input_shape = c(4)) %>%
    layer_dense(units = 5, activation = 'relu') %>%
    layer_dense(units = 3, activation = 'softmax')
# Compile the model
model %>% compile(
     loss = 'categorical_crossentropy',
     optimizer = 'adam',
     metrics = 'accuracy'
 )
# Save the training history in history
history <- model %>% fit(
  iris.training, iris.trainLabels,
  epochs = 200, batch_size = 5,
  validation_split = 0.2
 )
# Plot the model loss
plot(history$metrics$loss, main = "Model Loss", xlab = "epoch", ylab = "loss", col = "blue", type = "l")
lines(history$metrics$val_loss, col = "green")
legend("topright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))
# Plot the model accuracy
plot(history$metrics$acc, main = "Model Accuracy", xlab = "epoch", ylab = "accuracy", col = "blue", type = "l")
lines(history$metrics$val_acc, col = "green")
legend("bottomright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))
# Initialize the sequential model
model <- keras_model_sequential()
# Add layers to the model
model %>%
    layer_dense(units = 28, activation = 'relu', input_shape = c(4)) %>%
    layer_dense(units = 3, activation = 'softmax')
# Compile the model
model %>% compile(
     loss = 'categorical_crossentropy',
     optimizer = 'adam',
     metrics = 'accuracy'
 )
# Save the training history in the history variable
history <- model %>% fit(
  iris.training, iris.trainLabels,
  epochs = 200, batch_size = 5,
  validation_split = 0.2
 )
# Plot the model loss
plot(history$metrics$loss, main = "Model Loss", xlab = "epoch", ylab = "loss", col = "blue", type = "l")
lines(history$metrics$val_loss, col = "green")
legend("topright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))
# Plot the model accuracy
plot(history$metrics$acc, main = "Model Accuracy", xlab = "epoch", ylab = "accuracy", col = "blue", type = "l")
lines(history$metrics$val_acc, col = "green")
legend("bottomright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))
# Initialize the sequential model
model <- keras_model_sequential()
# Add layers to the model
model %>%
    layer_dense(units = 28, activation = 'relu', input_shape = c(4)) %>%
    layer_dense(units = 3, activation = 'softmax')
# Compile the model
model %>% compile(
     loss = 'categorical_crossentropy',
     optimizer = 'adam',
     metrics = 'accuracy'
 )
# Save the training history in the history variable
history <- model %>% fit(
  iris.training, iris.trainLabels,
  epochs = 200, batch_size = 5,
  validation_split = 0.2
 )
# Plot the model loss
plot(history$metrics$loss, main = "Model Loss", xlab = "epoch", ylab = "loss", col = "blue", type = "l")
lines(history$metrics$val_loss, col = "green")
legend("topright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))
# Plot the model accuracy
plot(history$metrics$acc, main = "Model Accuracy", xlab = "epoch", ylab = "accuracy", col = "blue", type = "l")
lines(history$metrics$val_acc, col = "green")
legend("bottomright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))
# Initialize a sequential model
model <- keras_model_sequential()
# Add layers to the model
model %>%
    layer_dense(units = 8, activation = 'relu', input_shape = c(4)) %>%
    layer_dense(units = 5, activation = 'relu') %>%
    layer_dense(units = 3, activation = 'softmax')
# Compile the model
model %>% compile(
     loss = 'categorical_crossentropy',
     optimizer = 'adam',
     metrics = 'accuracy'
 )
# Save the training history in history
history <- model %>% fit(
  iris.training, iris.trainLabels,
  epochs = 200, batch_size = 5,
  validation_split = 0.2
 )
# Plot the model loss
plot(history$metrics$loss, main = "Model Loss", xlab = "epoch", ylab = "loss", col = "blue", type = "l")
lines(history$metrics$val_loss, col = "green")
legend("topright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))
# Plot the model accuracy
plot(history$metrics$acc, main = "Model Accuracy", xlab = "epoch", ylab = "accuracy", col = "blue", type = "l")
lines(history$metrics$val_acc, col = "green")
legend("bottomright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))
data(iris); # Build your own `normalize()` function
normalize <- function(x) {
    num <- x - min(x)
    denom <- max(x) - min(x)
    return(num / denom)
};
# Normalize the `iris` data
iris_norm <- as.data.frame(lapply(iris[1:4], normalize));
iris[, 5] <- as.numeric(iris[, 5]) - 1;
# Turn `iris` into a matrix
iris <- as.matrix(iris);
# Set iris `dimnames` to `NULL`
dimnames(iris) <- NULL; # Normalize the `iris` data
iris2 <- normalize(iris[, 1:4])
# Return the summary of `iris`
summary(iris2); # Determine sample size
ind <- sample(2, nrow(iris2), replace = TRUE, prob = c(0.67, 0.33))
# Split the `iris` data
iris.training <- iris2[ind == 1, 1:4]
iris.test <- iris2[ind == 2, 1:4]
# Split the class attribute
iris.trainingtarget <- iris[ind == 1, 5]
iris.testtarget <- iris[ind == 2, 5] # One hot encode training target values
iris.trainLabels <- to_categorical(iris.trainingtarget)
# One hot encode test target values
iris.testLabels <- to_categorical(iris.testtarget)
# Initialize a sequential model
model <- keras_model_sequential()
# Add layers to the model
model %>%
    layer_dense(units = 8, activation = 'relu', input_shape = c(4)) %>%
    layer_dense(units = 5, activation = 'relu') %>%
    layer_dense(units = 3, activation = 'softmax')
# Compile the model
model %>% compile(
     loss = 'categorical_crossentropy',
     optimizer = 'adam',
     metrics = 'accuracy'
 )
# Save the training history in history
history <- model %>% fit(
  iris.training, iris.trainLabels,
  epochs = 200, batch_size = 5,
  validation_split = 0.2
 )
# Plot the model loss
plot(history$metrics$loss, main = "Model Loss", xlab = "epoch", ylab = "loss", col = "blue", type = "l")
lines(history$metrics$val_loss, col = "green")
legend("topright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))
# Plot the model accuracy
plot(history$metrics$acc, main = "Model Accuracy", xlab = "epoch", ylab = "accuracy", col = "blue", type = "l")
lines(history$metrics$val_acc, col = "green")
legend("bottomright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))
head(iris.trainLabels)
head(iris.testLabels)
head(iris.training)
head(iris.test)
nrow(iris.training)
nrow(iris.trainLabels)
nrow(iris)
nrow(iris.test)
data(iris); # Build your own `normalize()` function
normalize <- function(x) {
    num <- x - min(x)
    denom <- max(x) - min(x)
    return(num / denom)
};
# Normalize the `iris` data
iris_norm <- as.data.frame(lapply(iris[1:4], normalize));
iris[, 5] <- as.numeric(iris[, 5]) - 1;
# Turn `iris` into a matrix
iris <- as.matrix(iris);
# Set iris `dimnames` to `NULL`
dimnames(iris) <- NULL; # Normalize the `iris` data
iris2 <- normalize(iris[, 1:4])
# Return the summary of `iris`
summary(iris2); # Determine sample size
ind <- sample(2, nrow(iris2), replace = TRUE, prob = c(0.80, 0.20))
# Split the `iris` data
iris.training <- iris2[ind == 1, 1:4]
iris.test <- iris2[ind == 2, 1:4]
# Split the class attribute
iris.trainingtarget <- iris[ind == 1, 5]
iris.testtarget <- iris[ind == 2, 5] # One hot encode training target values
iris.trainLabels <- to_categorical(iris.trainingtarget)
# One hot encode test target values
iris.testLabels <- to_categorical(iris.testtarget)
# Initialize a sequential model
model <- keras_model_sequential()
# Add layers to the model
model %>%
    layer_dense(units = 8, activation = 'relu', input_shape = c(4)) %>%
    layer_dense(units = 5, activation = 'relu') %>%
    layer_dense(units = 3, activation = 'softmax')
# Compile the model
model %>% compile(
     loss = 'categorical_crossentropy',
     optimizer = 'adam',
     metrics = 'accuracy'
 )
# Save the training history in history
history <- model %>% fit(
  iris.training, iris.trainLabels,
  epochs = 200, batch_size = 5,
  validation_split = 0.2
 )
# Plot the model loss
plot(history$metrics$loss, main = "Model Loss", xlab = "epoch", ylab = "loss", col = "blue", type = "l")
lines(history$metrics$val_loss, col = "green")
legend("topright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))
# Plot the model accuracy
plot(history$metrics$acc, main = "Model Accuracy", xlab = "epoch", ylab = "accuracy", col = "blue", type = "l")
lines(history$metrics$val_acc, col = "green")
legend("bottomright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))
library(keras); data(iris); # Build your own `normalize()` function normalize <- function(x) {     num <- x - min(x)     denom <- max(x) - min(x)     return(num / denom) }; # Normalize the `iris` data iris_norm <- as.data.frame(lapply(iris[1:4], normalize)); iris[, 5] <- as.numeric(iris[, 5]) - 1; # Turn `iris` into a matrix iris <- as.matrix(iris); # Set iris `dimnames` to `NULL` dimnames(iris) <- NULL; # Normalize the `iris` data iris2 <- normalize(iris[, 1:4]) # Return the summary of `iris` summary(iris2); # Determine sample size ind <- sample(2, nrow(iris2), replace = TRUE, prob = c(0.80, 0.20)) # Split the `iris` data iris.training <- iris2[ind == 1, 1:4] iris.test <- iris2[ind == 2, 1:4] # Split the class attribute iris.trainingtarget <- iris[ind == 1, 5] iris.testtarget <- iris[ind == 2, 5] # One hot encode training target values iris.trainLabels <- to_categorical(iris.trainingtarget) # One hot encode test target values iris.testLabels <- to_categorical(iris.testtarget) # Print out the iris.testLabels to double check the result print(iris.testLabels) # Initialize a sequential model model <- keras_model_sequential() # Add layers to the model model %>%     layer_dense(units = 8, activation = 'relu', input_shape = c(4)) %>%     layer_dense(units = 3, activation = 'softmax') # Print a summary of a model summary(model) # Get model configuration get_config(model) # Get layer configuration get_layer(model, index = 1) # List the model's layers model$layers # List the input tensors model$inputs # List the output tensors model$outputs # Compile the model model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'  ) # Fit the model  model %>% fit(      iris.training,      iris.trainLabels,      epochs = 200,      batch_size = 5,      validation_split = 0.2  ) # Store the fitting history in `history`  history <- model %>% fit(      iris.training,      iris.trainLabels,      epochs = 200,      batch_size = 5,      validation_split = 0.2  ) # Plot the history plot(history) # Plot the model loss of the training data plot(history$metrics$loss, main = "Model Loss", xlab = "epoch", ylab = "loss", col = "blue", type = "l") # Plot the model loss of the test data lines(history$metrics$val_loss, col = "green") # Add legend legend("topright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1)) # Plot the accuracy of the training data  plot(history$metrics$acc, main = "Model Accuracy", xlab = "epoch", ylab = "accuracy", col = "blue", type = "l") # Plot the accuracy of the validation data lines(history$metrics$val_acc, col = "green") # Add Legend legend("bottomright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1)) # Predict the classes for the test data classes <- model %>% predict_classes(iris.test, batch_size = 128) # Confusion matrix table(iris.testtarget, classes) # Evaluate on test data and labels score <- model %>% evaluate(iris.test, iris.testLabels, batch_size = 128) # Print the score print(score)
library(keras); data(iris); # Build your own `normalize()` function normalize <- function(x) {     num <- x - min(x)     denom <- max(x) - min(x)     return(num / denom) }; # Normalize the `iris` data iris_norm <- as.data.frame(lapply(iris[1:4], normalize)); iris[, 5] <- as.numeric(iris[, 5]) - 1; # Turn `iris` into a matrix iris <- as.matrix(iris); # Set iris `dimnames` to `NULL` dimnames(iris) <- NULL; # Normalize the `iris` data iris2 <- normalize(iris[, 1:4]) # Return the summary of `iris` summary(iris2); # Determine sample size ind <- sample(2, nrow(iris2), replace = TRUE, prob = c(0.80, 0.20)) # Split the `iris` data iris.training <- iris2[ind == 1, 1:4] iris.test <- iris2[ind == 2, 1:4] # Split the class attribute iris.trainingtarget <- iris[ind == 1, 5] iris.testtarget <- iris[ind == 2, 5] # One hot encode training target values iris.trainLabels <- to_categorical(iris.trainingtarget) # One hot encode test target values iris.testLabels <- to_categorical(iris.testtarget) # Print out the iris.testLabels to double check the result print(iris.testLabels) # Initialize a sequential model model <- keras_model_sequential() # Add layers to the model model %>%     layer_dense(units = 8, activation = 'relu', input_shape = c(4)) %>%     layer_dense(units = 3, activation = 'softmax') # Print a summary of a model summary(model) # Get model configuration get_config(model) # Get layer configuration get_layer(model, index = 1) # List the model's layers model$layers # List the input tensors model$inputs # List the output tensors model$outputs # Compile the model model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'  ) # Fit the model  model %>% fit(      iris.training,      iris.trainLabels,      epochs = 200,      batch_size = 5,      validation_split = 0.2  ) # Store the fitting history in `history`  history <- model %>% fit(      iris.training,      iris.trainLabels,      epochs = 200,      batch_size = 5,      validation_split = 0.2  ) # Plot the history plot(history) # Plot the model loss of the training data plot(history$metrics$loss, main = "Model Loss", xlab = "epoch", ylab = "loss", col = "blue", type = "l") # Plot the model loss of the test data lines(history$metrics$val_loss, col = "green") # Add legend legend("topright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1)) # Plot the accuracy of the training data  plot(history$metrics$acc, main = "Model Accuracy", xlab = "epoch", ylab = "accuracy", col = "blue", type = "l") # Plot the accuracy of the validation data lines(history$metrics$val_acc, col = "green") # Add Legend legend("bottomright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1)) # Predict the classes for the test data classes <- model %>% predict_classes(iris.test, batch_size = 128) # Confusion matrix table(iris.testtarget, classes) # Evaluate on test data and labels score <- model %>% evaluate(iris.test, iris.testLabels, batch_size = 128) # Print the score print(score)
data(iris)
str(iris)
iris[, 5] <- as.numeric(iris[, 5]) - 1;
str(iris)
# Turn `iris` into a matrix iris <- as.matrix(iris);
str(iris)
hitungSoftmax = function(train_data,test_data) {     library(keras);     train_data$respon = as.numeric(train_data$respon);     test_data$respon = as.numeric(test_data$respon);     train_data_matrix = as.matrix(train_data);     test_data_matrix = as.matrix(test_data);     dimnames(train_data_matrix) = NULL;     dimnames(test_data_matrix) = NULL;     train_data_matrix_wTarget = train_data_matrix[, 1:(ncol(train_data_matrix) - 1)];     train_data_matrix_target = train_data_matrix[, ncol(train_data_matrix)];     test_data_matrix_wTarget = test_data_matrix[, 1:(ncol(test_data_matrix) - 1)];     test_data_matrix_target = test_data_matrix[, ncol(test_data_matrix)];     train_data_matrix_labels = to_categorical(train_data_matrix_target);     test_data_matrix_labels = to_categorical(test_data_matrix_target);     # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     model %>%     layer_dense(units = 8, activation = 'relu', input_shape = c(4)) %>%     layer_dense(units = 3, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )     # Plot the history     plot(history)     # Plot the model loss of the training data     plot(history$metrics$loss, main = "Model Loss", xlab = "epoch", ylab = "loss", col = "blue", type = "l")     # Plot the model loss of the test data     lines(history$metrics$val_loss, col = "green")     # Add legend     legend("topright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Plot the accuracy of the training data      plot(history$metrics$acc, main = "Model Accuracy", xlab = "epoch", ylab = "accuracy", col = "blue", type = "l")     # Plot the accuracy of the validation data     lines(history$metrics$val_acc, col = "green")     # Add Legend     legend("bottomright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)     return(output); }
library(imputeTS); library(dplyr); train_file = "Training Data.csv"; test_file = "Test Data.csv"; target_column = "manual_assessment"; train_data = baca(train_file); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; test_data = baca(test_file); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
baca = function(nama_file) {     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } partisi = function(input_data,response_name) {     #70/30 partition     #column response as y     colnames(input_data)[colnames(input_data) == response_name] = "respon";     partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1);     dataTrain = input_data[partition_data,];     dataTrain$tipe = "training";     dataTest = input_data[-partition_data,];     dataTest$tipe = "testing";     output_data = rbind(dataTrain, dataTest);     return(output_data); } hitungSVM2 = function(train_data,test_data, target_respon, nu_value, gamma_value) {     library(e1071);     model = svm(subset(train_data,select = -respon), train_data$respon, type = 'one-classification', nu = nu_value, gamma=gamma_value);     pred_trains = predict(model, subset(train_data,select= -respon));     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM = function(input_data,target_respon,nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification',nu=nu_value);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi = function(input_data, target_respon) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data);     x = subset(df, select = -respon);     y = as.factor(df$respon);     model = svm(x, y, probability = TRUE);     pred_train = predict(model, x, decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon),decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i,1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi2 = function(train_data,test_data, c_value, gamma_value) {     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = svm(subset(train_data,select=-respon), train_data$respon, probability = TRUE,C=c_value,gamma=gamma_value);     pred_train = predict(model, subset(train_data, select = -respon), decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon), decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungDecisionTree = function(train_data,test_data) {     library(C50);     library(printr);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     print("CHAID");     library(party);     model = ctree(respon ~ ., data = train_data);     pred = predict(model, test_data);     print(confusionMatrix(pred, test_data$respon));     print("CART");     library(rpart);     model = rpart(respon ~ ., data = train_data, method = "class");     pred = predict(model, test_data, type = "class");     print(confusionMatrix(pred, test_data$respon));     print("C50");     model = C5.0(respon ~ ., data = train_data);     results = predict(object = model, newdata = test_data, type = "class");     pred = predict(model, test_data);     print(confusionMatrix(pred, test_data$respon)); } hitungRandomForest = function(train_data, test_data) {     library(caret);     library(randomForest);     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = randomForest(respon ~ ., data = train_data,importance=TRUE);     pred = predict(model, newdata = test_data);     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon));     return(model); } hitungNaiveBayes = function(train_data,test_data) {     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = naiveBayes(respon ~ ., data = train_data)     pred = predict(model, newdata = subset(test_data, select = -respon));     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); } hitungNaiveBayes_normalization = function(train_data, test_data) {     library(e1071)     library(forecast)     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     for (i in 1:(ncol(train_data)-1)) {             train_data[, i] = BoxCox(train_data[, i], BoxCox.lambda(train_data[, i]));     }     for (i in 1:(ncol(test_data)-1)) {             test_data[, i] = BoxCox(test_data[, i], BoxCox.lambda(test_data[, i]));     }     model = naiveBayes(respon ~ ., data = train_data)     pred = predict(model, newdata = subset(test_data, select = -respon));     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); } hitungFeaturesImportance = function(train_data,test_data,modelRandomForest) {     library(dplyr);     set.seed(12345);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     importances = data.frame(importance(modelRandomForest));     kolom_train_data = colnames(train_data)[1:ncol(train_data) - 1];     importances$kolom = kolom_train_data;     importances = rbind(importances, importances[1,]);     importancesMDA = importances %>%     select(kolom, MeanDecreaseAccuracy) %>%     arrange(-MeanDecreaseAccuracy) %>%     as.data.frame();     importancesMDG = importances %>%     select(kolom, MeanDecreaseGini) %>%     arrange(-MeanDecreaseGini) %>%     as.data.frame();     importancesMDA$results = -1;     for (i in 1:nrow(importancesMDA)) {         kolom = importancesMDA$kolom[1:(nrow(importancesMDA) - i)];         train_dataset1_normMDA = train_data %>%         select(kolom) %>%         as.data.frame();         train_dataset1_normMDA$respon = as.factor(train_data$respon);         test_dataset1_normMDA = test_data %>%         select(kolom) %>%         as.data.frame();         test_dataset1_normMDA$respon = as.factor(test_data$respon);         model = randomForest(respon ~ ., data = train_data, importance = TRUE);         pred = predict(model, newdata = test_data);         hasil = confusionMatrix(pred, test_data$respon);         akurasi = as.numeric(hasil$overall[1]);         importancesMDA$results[i] = akurasi;     }     return(importancesMDA); } hitungSoftmax = function(train_data,test_data) {     library(keras);     train_data$respon = as.numeric(train_data$respon);     test_data$respon = as.numeric(test_data$respon);     train_data_matrix = as.matrix(train_data);     test_data_matrix = as.matrix(test_data);     dimnames(train_data_matrix) = NULL;     dimnames(test_data_matrix) = NULL;     train_data_matrix_wTarget = train_data_matrix[, 1:(ncol(train_data_matrix) - 1)];     train_data_matrix_target = train_data_matrix[, ncol(train_data_matrix)];     test_data_matrix_wTarget = test_data_matrix[, 1:(ncol(test_data_matrix) - 1)];     test_data_matrix_target = test_data_matrix[, ncol(test_data_matrix)];     train_data_matrix_labels = to_categorical(train_data_matrix_target);     test_data_matrix_labels = to_categorical(test_data_matrix_target);     # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     model %>%     layer_dense(units = 8, activation = 'relu', input_shape = c(4)) %>%     layer_dense(units = 3, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )     # Plot the history     plot(history)     # Plot the model loss of the training data     plot(history$metrics$loss, main = "Model Loss", xlab = "epoch", ylab = "loss", col = "blue", type = "l")     # Plot the model loss of the test data     lines(history$metrics$val_loss, col = "green")     # Add legend     legend("topright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Plot the accuracy of the training data      plot(history$metrics$acc, main = "Model Accuracy", xlab = "epoch", ylab = "accuracy", col = "blue", type = "l")     # Plot the accuracy of the validation data     lines(history$metrics$val_acc, col = "green")     # Add Legend     legend("bottomright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)     return(output); }
library(imputeTS); library(dplyr); train_file = "Training Data.csv"; test_file = "Test Data.csv"; target_column = "manual_assessment"; train_data = baca(train_file); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; test_data = baca(test_file); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
hitungSoftmax(train_dataset1_norm, test_dataset1_norm);
library(keras)
hitungSoftmax(train_dataset1_norm, test_dataset1_norm);
train_data_back = train_dataset1_norm;
test_data_back = test_dataset1_norm;
test_data_back = test_dataset;
test_data_back = test_data;
train_data_back = train_data;
train_data = train_dataset1_norm;
test_data = test_dataset1_norm;
    library(keras);     train_data$respon = as.numeric(train_data$respon);     test_data$respon = as.numeric(test_data$respon);     train_data_matrix = as.matrix(train_data);     test_data_matrix = as.matrix(test_data);     dimnames(train_data_matrix) = NULL;     dimnames(test_data_matrix) = NULL;
    train_data_matrix_wTarget = train_data_matrix[, 1:(ncol(train_data_matrix) - 1)];     train_data_matrix_target = train_data_matrix[, ncol(train_data_matrix)];
    test_data_matrix_wTarget = test_data_matrix[, 1:(ncol(test_data_matrix) - 1)];     test_data_matrix_target = test_data_matrix[, ncol(test_data_matrix)];     train_data_matrix_labels = to_categorical(train_data_matrix_target);     test_data_matrix_labels = to_categorical(test_data_matrix_target);
    # Initialize a sequential model     model = keras_model_sequential()
ncol(train_data_matrix_wTarget)
    # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     model %>%     layer_dense(units = 180, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 80, activation = 'softmax');
    # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )
    # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )
    # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     model %>%     layer_dense(units = 180, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 18668, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )
str(iris.training)
str(iris.trainLabels)
str(train_data_matrix_wTarget)
str(train_data_matrix_labels)
# Initialize a sequential model model <- keras_model_sequential() # Add layers to the model model %>%     layer_dense(units = 100, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 6, activation = 'softmax')
    # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     model %>%     layer_dense(units = 100, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 6, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )
    # Plot the history     plot(history)     # Plot the model loss of the training data     plot(history$metrics$loss, main = "Model Loss", xlab = "epoch", ylab = "loss", col = "blue", type = "l")     # Plot the model loss of the test data     lines(history$metrics$val_loss, col = "green")     # Add legend     legend("topright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Plot the accuracy of the training data      plot(history$metrics$acc, main = "Model Accuracy", xlab = "epoch", ylab = "accuracy", col = "blue", type = "l")     # Plot the accuracy of the validation data     lines(history$metrics$val_acc, col = "green")     # Add Legend     legend("bottomright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)
    # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)
score
classes
head(train_data_matrix_labels);
head(train_data_matrix_target);
unique(train_data_matrix_target[,1])
unique(train_data_matrix_target[1])
unique(train_data_matrix_labels[,1])
unique(train_data_matrix_labels[,2])
unique(train_data_matrix_labels[,3])
unique(train_data_matrix_labels[,4])
unique(train_data_matrix_labels[,5])
unique(train_data_matrix_target);
iris.trainLabels
unique(iris.trainingtarget)
train_data = train_dataset1_norm;
test_data = test_dataset1_norm;
    train_data$respon = as.numeric(train_data$respon)-1;     test_data$respon = as.numeric(test_data$respon)-1;     train_data_matrix = as.matrix(train_data);     test_data_matrix = as.matrix(test_data);     dimnames(train_data_matrix) = NULL;     dimnames(test_data_matrix) = NULL;     train_data_matrix_wTarget = train_data_matrix[, 1:(ncol(train_data_matrix) - 1)];     train_data_matrix_target = train_data_matrix[, ncol(train_data_matrix)];     test_data_matrix_wTarget = test_data_matrix[, 1:(ncol(test_data_matrix) - 1)];     test_data_matrix_target = test_data_matrix[, ncol(test_data_matrix)];     train_data_matrix_labels = to_categorical(train_data_matrix_target);     test_data_matrix_labels = to_categorical(test_data_matrix_target);     # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     model %>%     layer_dense(units = 100, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 6, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )     # Plot the history     plot(history)     # Plot the model loss of the training data     plot(history$metrics$loss, main = "Model Loss", xlab = "epoch", ylab = "loss", col = "blue", type = "l")     # Plot the model loss of the test data     lines(history$metrics$val_loss, col = "green")     # Add legend     legend("topright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Plot the accuracy of the training data      plot(history$metrics$acc, main = "Model Accuracy", xlab = "epoch", ylab = "accuracy", col = "blue", type = "l")     # Plot the accuracy of the validation data     lines(history$metrics$val_acc, col = "green")     # Add Legend     legend("bottomright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)
    # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     model %>%     layer_dense(units = 100, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 5, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )     # Plot the history     plot(history)     # Plot the model loss of the training data     plot(history$metrics$loss, main = "Model Loss", xlab = "epoch", ylab = "loss", col = "blue", type = "l")     # Plot the model loss of the test data     lines(history$metrics$val_loss, col = "green")     # Add legend     legend("topright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Plot the accuracy of the training data      plot(history$metrics$acc, main = "Model Accuracy", xlab = "epoch", ylab = "accuracy", col = "blue", type = "l")     # Plot the accuracy of the validation data     lines(history$metrics$val_acc, col = "green")     # Add Legend     legend("bottomright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)
head(train_dataset1_norm)
normalize <- function(x) {     num <- x - min(x)     denom <- max(x) - min(x)     return(num / denom) };
train_data = train_dataset1_norm;
test_data = test_dataset1_norm;
    library(keras);     train_data$respon = as.numeric(train_data$respon)-1;     test_data$respon = as.numeric(test_data$respon) - 1;     train_data_norm = as.data.frame(lapply(train_data[1:(ncol(train_data)-1)], normalize));     test_data_norm = as.data.frame(lapply(test_data[1:(ncol(test_data) - 1)], normalize));
str(train_data_norm)
train_data = train_dataset1_norm;
test_data = test_dataset1_norm;
    train_data$respon = as.numeric(train_data$respon)-1;     test_data$respon = as.numeric(test_data$respon) - 1;     train_data_norm = as.data.frame(lapply(train_data[1:(ncol(train_data)-1)], normalize));     test_data_norm = as.data.frame(lapply(test_data[1:(ncol(test_data) - 1)], normalize));     train_data_norm$respon = train_data$respon;     test_data_norm$respon = test_data$respon;     train_data_matrix = as.matrix(train_data);     test_data_matrix = as.matrix(test_data);     dimnames(train_data_matrix) = NULL;     dimnames(test_data_matrix) = NULL;     train_data_matrix_wTarget = train_data_matrix[, 1:(ncol(train_data_matrix) - 1)];     train_data_matrix_target = train_data_matrix[, ncol(train_data_matrix)];     test_data_matrix_wTarget = test_data_matrix[, 1:(ncol(test_data_matrix) - 1)];     test_data_matrix_target = test_data_matrix[, ncol(test_data_matrix)];     train_data_matrix_labels = to_categorical(train_data_matrix_target);     test_data_matrix_labels = to_categorical(test_data_matrix_target);     # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     model %>%     layer_dense(units = 100, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 5, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )     # Plot the history     plot(history)     # Plot the model loss of the training data     plot(history$metrics$loss, main = "Model Loss", xlab = "epoch", ylab = "loss", col = "blue", type = "l")     # Plot the model loss of the test data     lines(history$metrics$val_loss, col = "green")     # Add legend     legend("topright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Plot the accuracy of the training data      plot(history$metrics$acc, main = "Model Accuracy", xlab = "epoch", ylab = "accuracy", col = "blue", type = "l")     # Plot the accuracy of the validation data     lines(history$metrics$val_acc, col = "green")     # Add Legend     legend("bottomright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)
head(iris.training)
head(iris.trainLabels)
head(train_data)
train_data = train_dataset1_norm;
test_data = test_dataset1_norm;
    library(keras);     train_data$respon = as.numeric(train_data$respon)-1;     test_data$respon = as.numeric(test_data$respon) - 1;     train_data_norm = as.data.frame(lapply(train_data[1:(ncol(train_data)-1)], normalize));     test_data_norm = as.data.frame(lapply(test_data[1:(ncol(test_data) - 1)], normalize));     train_data_norm$respon = train_data$respon;     test_data_norm$respon = test_data$respon;     train_data_matrix = as.matrix(train_data);     test_data_matrix = as.matrix(test_data);     dimnames(train_data_matrix) = NULL;     dimnames(test_data_matrix) = NULL;     train_data_matrix_wTarget = train_data_matrix[, 1:(ncol(train_data_matrix) - 1)];     train_data_matrix_target = train_data_matrix[, ncol(train_data_matrix)];     test_data_matrix_wTarget = test_data_matrix[, 1:(ncol(test_data_matrix) - 1)];     test_data_matrix_target = test_data_matrix[, ncol(test_data_matrix)];     train_data_matrix_labels = to_categorical(train_data_matrix_target);     test_data_matrix_labels = to_categorical(test_data_matrix_target);
head(train_data)
head(train_data_norm)
nrow(train_data_matrix_labels)
nrow(test_data_matrix_labels)
nrow(test_data)
nrow(train_data)
ncol(train_data)
ncol(test_data)
ncol(train_data_matrix_labels)
nrow(test_data_matrix_labels)
ncol(test_data_matrix_labels)
head(test_data_matrix_labels)
head(test_data$respon)
head(test_data_matrix_labels)
head(train_data$respon)
head(train_data_matrix_labels)
train_data = train_dataset1_norm;
test_data = test_dataset1_norm;
    library(keras);     train_data$respon = as.numeric(train_data$respon)-1;     test_data$respon = as.numeric(test_data$respon) - 1;     train_data_norm = as.data.frame(lapply(train_data[1:(ncol(train_data)-1)], normalize));     test_data_norm = as.data.frame(lapply(test_data[1:(ncol(test_data) - 1)], normalize));     train_data_norm$respon = train_data$respon;     test_data_norm$respon = test_data$respon;     train_data_matrix = as.matrix(train_data);     test_data_matrix = as.matrix(test_data);     dimnames(train_data_matrix) = NULL;     dimnames(test_data_matrix) = NULL;     train_data_matrix_wTarget = train_data_matrix[, 1:(ncol(train_data_matrix) - 1)];     train_data_matrix_target = train_data_matrix[, ncol(train_data_matrix)];     test_data_matrix_wTarget = test_data_matrix[, 1:(ncol(test_data_matrix) - 1)];     test_data_matrix_target = test_data_matrix[, ncol(test_data_matrix)];     train_data_matrix_labels = to_categorical(train_data_matrix_target);     test_data_matrix_labels = to_categorical(test_data_matrix_target);     # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     model %>%     layer_dense(units = 180, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 5, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )     # Plot the history     plot(history)     # Plot the model loss of the training data     plot(history$metrics$loss, main = "Model Loss", xlab = "epoch", ylab = "loss", col = "blue", type = "l")     # Plot the model loss of the test data     lines(history$metrics$val_loss, col = "green")     # Add legend     legend("topright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Plot the accuracy of the training data      plot(history$metrics$acc, main = "Model Accuracy", xlab = "epoch", ylab = "accuracy", col = "blue", type = "l")     # Plot the accuracy of the validation data     lines(history$metrics$val_acc, col = "green")     # Add Legend     legend("bottomright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)
train_data = train_dataset1_norm;
test_data = test_dataset1_norm;
    library(keras);     train_data$respon = as.numeric(train_data$respon)-1;     test_data$respon = as.numeric(test_data$respon) - 1;     train_data_norm = as.data.frame(lapply(train_data[1:(ncol(train_data)-1)], normalize));     test_data_norm = as.data.frame(lapply(test_data[1:(ncol(test_data) - 1)], normalize));     train_data_norm$respon = train_data$respon;     test_data_norm$respon = test_data$respon;     train_data_matrix = as.matrix(train_data);     test_data_matrix = as.matrix(test_data);     dimnames(train_data_matrix) = NULL;     dimnames(test_data_matrix) = NULL;     train_data_matrix_wTarget = train_data_matrix[, 1:(ncol(train_data_matrix) - 1)];     train_data_matrix_target = train_data_matrix[, ncol(train_data_matrix)];     test_data_matrix_wTarget = test_data_matrix[, 1:(ncol(test_data_matrix) - 1)];     test_data_matrix_target = test_data_matrix[, ncol(test_data_matrix)];     train_data_matrix_labels = to_categorical(train_data_matrix_target);     test_data_matrix_labels = to_categorical(test_data_matrix_target);     # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     model %>%     layer_dense(units = 270, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 90, activation = 'relu') %>%     layer_dense(units = 5, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )     # Plot the history     plot(history)     # Plot the model loss of the training data     plot(history$metrics$loss, main = "Model Loss", xlab = "epoch", ylab = "loss", col = "blue", type = "l")     # Plot the model loss of the test data     lines(history$metrics$val_loss, col = "green")     # Add legend     legend("topright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Plot the accuracy of the training data      plot(history$metrics$acc, main = "Model Accuracy", xlab = "epoch", ylab = "accuracy", col = "blue", type = "l")     # Plot the accuracy of the validation data     lines(history$metrics$val_acc, col = "green")     # Add Legend     legend("bottomright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)
train_data = train_dataset1_norm;
test_data = test_dataset1_norm;
    library(keras);     train_data$respon = as.numeric(train_data$respon)-1;     test_data$respon = as.numeric(test_data$respon) - 1;     train_data_norm = as.data.frame(lapply(train_data[1:(ncol(train_data)-1)], normalize));     test_data_norm = as.data.frame(lapply(test_data[1:(ncol(test_data) - 1)], normalize));     train_data_norm$respon = train_data$respon;     test_data_norm$respon = test_data$respon;     train_data_matrix = as.matrix(train_data);     test_data_matrix = as.matrix(test_data);     dimnames(train_data_matrix) = NULL;     dimnames(test_data_matrix) = NULL;     train_data_matrix_wTarget = train_data_matrix[, 1:(ncol(train_data_matrix) - 1)];     train_data_matrix_target = train_data_matrix[, ncol(train_data_matrix)];     test_data_matrix_wTarget = test_data_matrix[, 1:(ncol(test_data_matrix) - 1)];     test_data_matrix_target = test_data_matrix[, ncol(test_data_matrix)];     train_data_matrix_labels = to_categorical(train_data_matrix_target);     test_data_matrix_labels = to_categorical(test_data_matrix_target);     # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     model %>%     layer_dense(units = 180, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 5, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )     # Plot the history     plot(history)     # Plot the model loss of the training data     plot(history$metrics$loss, main = "Model Loss", xlab = "epoch", ylab = "loss", col = "blue", type = "l")     # Plot the model loss of the test data     lines(history$metrics$val_loss, col = "green")     # Add legend     legend("topright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Plot the accuracy of the training data      plot(history$metrics$acc, main = "Model Accuracy", xlab = "epoch", ylab = "accuracy", col = "blue", type = "l")     # Plot the accuracy of the validation data     lines(history$metrics$val_acc, col = "green")     # Add Legend     legend("bottomright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)
# Plot the accuracy of the training data      plot(history$metrics$acc, main = "Model Accuracy", xlab = "epoch", ylab = "accuracy", col = "blue", type = "l")     # Plot the accuracy of the validation data     lines(history$metrics$val_acc, col = "green")     # Add Legend     legend("bottomright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))
# Plot the model loss of the training data     plot(history$metrics$loss, main = "Model Loss", xlab = "epoch", ylab = "loss", col = "blue", type = "l")     # Plot the model loss of the test data     lines(history$metrics$val_loss, col = "green")     # Add legend     legend("topright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))
train_data = train_dataset1_norm
test_data = test_dataset1_norm
    library(keras);     train_data$respon = as.numeric(train_data$respon)-1;     test_data$respon = as.numeric(test_data$respon) - 1;     train_data_norm = as.data.frame(lapply(train_data[1:(ncol(train_data)-1)], normalize));     test_data_norm = as.data.frame(lapply(test_data[1:(ncol(test_data) - 1)], normalize));     train_data_norm$respon = train_data$respon;     test_data_norm$respon = test_data$respon;     train_data_matrix = as.matrix(train_data);     test_data_matrix = as.matrix(test_data);     dimnames(train_data_matrix) = NULL;     dimnames(test_data_matrix) = NULL;     train_data_matrix_wTarget = train_data_matrix[, 1:(ncol(train_data_matrix) - 1)];     train_data_matrix_target = train_data_matrix[, ncol(train_data_matrix)];     test_data_matrix_wTarget = test_data_matrix[, 1:(ncol(test_data_matrix) - 1)];     test_data_matrix_target = test_data_matrix[, ncol(test_data_matrix)];     train_data_matrix_labels = to_categorical(train_data_matrix_target);     test_data_matrix_labels = to_categorical(test_data_matrix_target);     # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     model %>%     layer_dense(units = 270, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 5, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )     # Plot the history     plot(history)     # Plot the model loss of the training data     plot(history$metrics$loss, main = "Model Loss", xlab = "epoch", ylab = "loss", col = "blue", type = "l")     # Plot the model loss of the test data     lines(history$metrics$val_loss, col = "green")     # Add legend     legend("topright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Plot the accuracy of the training data      plot(history$metrics$acc, main = "Model Accuracy", xlab = "epoch", ylab = "accuracy", col = "blue", type = "l")     # Plot the accuracy of the validation data     lines(history$metrics$val_acc, col = "green")     # Add Legend     legend("bottomright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)
    # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     model %>%     layer_dense(units = 180, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 90, activation = 'relu') %>%     layer_dense(units = 5, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )     # Plot the history     plot(history)     # Plot the model loss of the training data     plot(history$metrics$loss, main = "Model Loss", xlab = "epoch", ylab = "loss", col = "blue", type = "l")     # Plot the model loss of the test data     lines(history$metrics$val_loss, col = "green")     # Add legend     legend("topright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Plot the accuracy of the training data      plot(history$metrics$acc, main = "Model Accuracy", xlab = "epoch", ylab = "accuracy", col = "blue", type = "l")     # Plot the accuracy of the validation data     lines(history$metrics$val_acc, col = "green")     # Add Legend     legend("bottomright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)
library(keras)
library(imputeTS); library(dplyr); train_file = "Training Data.csv"; test_file = "Test Data.csv"; target_column = "manual_assessment"; train_data = baca(train_file); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; test_data = baca(test_file); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
baca = function(nama_file) {     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } partisi = function(input_data,response_name) {     #70/30 partition     #column response as y     colnames(input_data)[colnames(input_data) == response_name] = "respon";     partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1);     dataTrain = input_data[partition_data,];     dataTrain$tipe = "training";     dataTest = input_data[-partition_data,];     dataTest$tipe = "testing";     output_data = rbind(dataTrain, dataTest);     return(output_data); } hitungSVM2 = function(train_data,test_data, target_respon, nu_value, gamma_value) {     library(e1071);     model = svm(subset(train_data,select = -respon), train_data$respon, type = 'one-classification', nu = nu_value, gamma=gamma_value);     pred_trains = predict(model, subset(train_data,select= -respon));     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM = function(input_data,target_respon,nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification',nu=nu_value);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi = function(input_data, target_respon) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data);     x = subset(df, select = -respon);     y = as.factor(df$respon);     model = svm(x, y, probability = TRUE);     pred_train = predict(model, x, decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon),decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i,1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi2 = function(train_data,test_data, c_value, gamma_value) {     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = svm(subset(train_data,select=-respon), train_data$respon, probability = TRUE,C=c_value,gamma=gamma_value);     pred_train = predict(model, subset(train_data, select = -respon), decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon), decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungDecisionTree = function(train_data,test_data) {     library(C50);     library(printr);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     print("CHAID");     library(party);     model = ctree(respon ~ ., data = train_data);     pred = predict(model, test_data);     print(confusionMatrix(pred, test_data$respon));     print("CART");     library(rpart);     model = rpart(respon ~ ., data = train_data, method = "class");     pred = predict(model, test_data, type = "class");     print(confusionMatrix(pred, test_data$respon));     print("C50");     model = C5.0(respon ~ ., data = train_data);     results = predict(object = model, newdata = test_data, type = "class");     pred = predict(model, test_data);     print(confusionMatrix(pred, test_data$respon)); } hitungRandomForest = function(train_data, test_data) {     library(caret);     library(randomForest);     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = randomForest(respon ~ ., data = train_data,importance=TRUE);     pred = predict(model, newdata = test_data);     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon));     return(model); } hitungNaiveBayes = function(train_data,test_data) {     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = naiveBayes(respon ~ ., data = train_data)     pred = predict(model, newdata = subset(test_data, select = -respon));     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); } hitungNaiveBayes_normalization = function(train_data, test_data) {     library(e1071)     library(forecast)     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     for (i in 1:(ncol(train_data)-1)) {             train_data[, i] = BoxCox(train_data[, i], BoxCox.lambda(train_data[, i]));     }     for (i in 1:(ncol(test_data)-1)) {             test_data[, i] = BoxCox(test_data[, i], BoxCox.lambda(test_data[, i]));     }     model = naiveBayes(respon ~ ., data = train_data)     pred = predict(model, newdata = subset(test_data, select = -respon));     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); } hitungFeaturesImportance = function(train_data,test_data,modelRandomForest) {     library(dplyr);     set.seed(12345);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     importances = data.frame(importance(modelRandomForest));     kolom_train_data = colnames(train_data)[1:ncol(train_data) - 1];     importances$kolom = kolom_train_data;     importances = rbind(importances, importances[1,]);     importancesMDA = importances %>%     select(kolom, MeanDecreaseAccuracy) %>%     arrange(-MeanDecreaseAccuracy) %>%     as.data.frame();     importancesMDG = importances %>%     select(kolom, MeanDecreaseGini) %>%     arrange(-MeanDecreaseGini) %>%     as.data.frame();     importancesMDA$results = -1;     for (i in 1:nrow(importancesMDA)) {         kolom = importancesMDA$kolom[1:(nrow(importancesMDA) - i)];         train_dataset1_normMDA = train_data %>%         select(kolom) %>%         as.data.frame();         train_dataset1_normMDA$respon = as.factor(train_data$respon);         test_dataset1_normMDA = test_data %>%         select(kolom) %>%         as.data.frame();         test_dataset1_normMDA$respon = as.factor(test_data$respon);         model = randomForest(respon ~ ., data = train_data, importance = TRUE);         pred = predict(model, newdata = test_data);         hasil = confusionMatrix(pred, test_data$respon);         akurasi = as.numeric(hasil$overall[1]);         importancesMDA$results[i] = akurasi;     }     return(importancesMDA); } # Build your own `normalize()` function normalize <- function(x) {     num <- x - min(x)     denom <- max(x) - min(x)     return(num / denom) }; hitungSoftmax = function(train_data,test_data) {     library(keras);     train_data$respon = as.numeric(train_data$respon)-1;     test_data$respon = as.numeric(test_data$respon) - 1;     train_data_norm = as.data.frame(lapply(train_data[1:(ncol(train_data)-1)], normalize));     test_data_norm = as.data.frame(lapply(test_data[1:(ncol(test_data) - 1)], normalize));     train_data_norm$respon = train_data$respon;     test_data_norm$respon = test_data$respon;     train_data_matrix = as.matrix(train_data);     test_data_matrix = as.matrix(test_data);     dimnames(train_data_matrix) = NULL;     dimnames(test_data_matrix) = NULL;     train_data_matrix_wTarget = train_data_matrix[, 1:(ncol(train_data_matrix) - 1)];     train_data_matrix_target = train_data_matrix[, ncol(train_data_matrix)];     test_data_matrix_wTarget = test_data_matrix[, 1:(ncol(test_data_matrix) - 1)];     test_data_matrix_target = test_data_matrix[, ncol(test_data_matrix)];     train_data_matrix_labels = to_categorical(train_data_matrix_target);     test_data_matrix_labels = to_categorical(test_data_matrix_target);     # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     # BEST RESULTS 1 hidden 180 units : 77.80%     # 2 hidden: 180 units + 90 units : 78.49968%     model %>%     layer_dense(units = 180, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 90, activation = 'relu') %>%     layer_dense(units = 45, activation = 'relu') %>%     layer_dense(units = 10, activation = 'relu') %>%     layer_dense(units = 5, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )     # Plot the history     plot(history)     # Plot the model loss of the training data     plot(history$metrics$loss, main = "Model Loss", xlab = "epoch", ylab = "loss", col = "blue", type = "l")     # Plot the model loss of the test data     lines(history$metrics$val_loss, col = "green")     # Add legend     legend("topright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Plot the accuracy of the training data      plot(history$metrics$acc, main = "Model Accuracy", xlab = "epoch", ylab = "accuracy", col = "blue", type = "l")     # Plot the accuracy of the validation data     lines(history$metrics$val_acc, col = "green")     # Add Legend     legend("bottomright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)     return(output); }
library(imputeTS); library(dplyr); train_file = "Training Data.csv"; test_file = "Test Data.csv"; target_column = "manual_assessment"; train_data = baca(train_file); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; test_data = baca(test_file); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
set.seed(12345);
hitungSoftmax = function(train_data,test_data) {     library(keras);     train_data$respon = as.numeric(train_data$respon)-1;     test_data$respon = as.numeric(test_data$respon) - 1;     train_data_norm = as.data.frame(lapply(train_data[1:(ncol(train_data)-1)], normalize));     test_data_norm = as.data.frame(lapply(test_data[1:(ncol(test_data) - 1)], normalize));     train_data_norm$respon = train_data$respon;     test_data_norm$respon = test_data$respon;     train_data_matrix = as.matrix(train_data);     test_data_matrix = as.matrix(test_data);     dimnames(train_data_matrix) = NULL;     dimnames(test_data_matrix) = NULL;     train_data_matrix_wTarget = train_data_matrix[, 1:(ncol(train_data_matrix) - 1)];     train_data_matrix_target = train_data_matrix[, ncol(train_data_matrix)];     test_data_matrix_wTarget = test_data_matrix[, 1:(ncol(test_data_matrix) - 1)];     test_data_matrix_target = test_data_matrix[, ncol(test_data_matrix)];     train_data_matrix_labels = to_categorical(train_data_matrix_target);     test_data_matrix_labels = to_categorical(test_data_matrix_target);     # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     # BEST RESULTS 1 hidden 180 units : 77.80%     # 2 hidden: 180 units + 90 units : 78.49968%     model %>%     layer_dense(units = 180, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 90, activation = 'relu') %>%     layer_dense(units = 45, activation = 'relu') %>%     layer_dense(units = 10, activation = 'relu') %>%     layer_dense(units = 5, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )     # Plot the history     plot(history)     # Plot the model loss of the training data     plot(history$metrics$loss, main = "Model Loss", xlab = "epoch", ylab = "loss", col = "blue", type = "l")     # Plot the model loss of the test data     lines(history$metrics$val_loss, col = "green")     # Add legend     legend("topright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Plot the accuracy of the training data      plot(history$metrics$acc, main = "Model Accuracy", xlab = "epoch", ylab = "accuracy", col = "blue", type = "l")     # Plot the accuracy of the validation data     lines(history$metrics$val_acc, col = "green")     # Add Legend     legend("bottomright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)     return(output); }
hitungSoftmax(train_dataset1_norm, test_dataset1_norm);
baca = function(nama_file) {     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } partisi = function(input_data,response_name) {     #70/30 partition     #column response as y     colnames(input_data)[colnames(input_data) == response_name] = "respon";     partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1);     dataTrain = input_data[partition_data,];     dataTrain$tipe = "training";     dataTest = input_data[-partition_data,];     dataTest$tipe = "testing";     output_data = rbind(dataTrain, dataTest);     return(output_data); } hitungSVM2 = function(train_data,test_data, target_respon, nu_value, gamma_value) {     library(e1071);     model = svm(subset(train_data,select = -respon), train_data$respon, type = 'one-classification', nu = nu_value, gamma=gamma_value);     pred_trains = predict(model, subset(train_data,select= -respon));     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM = function(input_data,target_respon,nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification',nu=nu_value);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi = function(input_data, target_respon) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data);     x = subset(df, select = -respon);     y = as.factor(df$respon);     model = svm(x, y, probability = TRUE);     pred_train = predict(model, x, decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon),decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i,1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi2 = function(train_data,test_data, c_value, gamma_value) {     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = svm(subset(train_data,select=-respon), train_data$respon, probability = TRUE,C=c_value,gamma=gamma_value);     pred_train = predict(model, subset(train_data, select = -respon), decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon), decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungDecisionTree = function(train_data,test_data) {     library(C50);     library(printr);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     print("CHAID");     library(party);     model = ctree(respon ~ ., data = train_data);     pred = predict(model, test_data);     print(confusionMatrix(pred, test_data$respon));     print("CART");     library(rpart);     model = rpart(respon ~ ., data = train_data, method = "class");     pred = predict(model, test_data, type = "class");     print(confusionMatrix(pred, test_data$respon));     print("C50");     model = C5.0(respon ~ ., data = train_data);     results = predict(object = model, newdata = test_data, type = "class");     pred = predict(model, test_data);     print(confusionMatrix(pred, test_data$respon)); } hitungRandomForest = function(train_data, test_data) {     library(caret);     library(randomForest);     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = randomForest(respon ~ ., data = train_data,importance=TRUE);     pred = predict(model, newdata = test_data);     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon));     return(model); } hitungNaiveBayes = function(train_data,test_data) {     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = naiveBayes(respon ~ ., data = train_data)     pred = predict(model, newdata = subset(test_data, select = -respon));     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); } hitungNaiveBayes_normalization = function(train_data, test_data) {     library(e1071)     library(forecast)     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     for (i in 1:(ncol(train_data)-1)) {             train_data[, i] = BoxCox(train_data[, i], BoxCox.lambda(train_data[, i]));     }     for (i in 1:(ncol(test_data)-1)) {             test_data[, i] = BoxCox(test_data[, i], BoxCox.lambda(test_data[, i]));     }     model = naiveBayes(respon ~ ., data = train_data)     pred = predict(model, newdata = subset(test_data, select = -respon));     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); } hitungFeaturesImportance = function(train_data,test_data,modelRandomForest) {     library(dplyr);     set.seed(12345);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     importances = data.frame(importance(modelRandomForest));     kolom_train_data = colnames(train_data)[1:ncol(train_data) - 1];     importances$kolom = kolom_train_data;     importances = rbind(importances, importances[1,]);     importancesMDA = importances %>%     select(kolom, MeanDecreaseAccuracy) %>%     arrange(-MeanDecreaseAccuracy) %>%     as.data.frame();     importancesMDG = importances %>%     select(kolom, MeanDecreaseGini) %>%     arrange(-MeanDecreaseGini) %>%     as.data.frame();     importancesMDA$results = -1;     for (i in 1:nrow(importancesMDA)) {         kolom = importancesMDA$kolom[1:(nrow(importancesMDA) - i)];         train_dataset1_normMDA = train_data %>%         select(kolom) %>%         as.data.frame();         train_dataset1_normMDA$respon = as.factor(train_data$respon);         test_dataset1_normMDA = test_data %>%         select(kolom) %>%         as.data.frame();         test_dataset1_normMDA$respon = as.factor(test_data$respon);         model = randomForest(respon ~ ., data = train_data, importance = TRUE);         pred = predict(model, newdata = test_data);         hasil = confusionMatrix(pred, test_data$respon);         akurasi = as.numeric(hasil$overall[1]);         importancesMDA$results[i] = akurasi;     }     return(importancesMDA); } # Build your own `normalize()` function normalize <- function(x) {     num <- x - min(x)     denom <- max(x) - min(x)     return(num / denom) }; hitungSoftmax = function(train_data,test_data) {     library(keras);     train_data$respon = as.numeric(train_data$respon)-1;     test_data$respon = as.numeric(test_data$respon) - 1;     train_data_norm = as.data.frame(lapply(train_data[1:(ncol(train_data)-1)], normalize));     test_data_norm = as.data.frame(lapply(test_data[1:(ncol(test_data) - 1)], normalize));     train_data_norm$respon = train_data$respon;     test_data_norm$respon = test_data$respon;     train_data_matrix = as.matrix(train_data);     test_data_matrix = as.matrix(test_data);     dimnames(train_data_matrix) = NULL;     dimnames(test_data_matrix) = NULL;     train_data_matrix_wTarget = train_data_matrix[, 1:(ncol(train_data_matrix) - 1)];     train_data_matrix_target = train_data_matrix[, ncol(train_data_matrix)];     test_data_matrix_wTarget = test_data_matrix[, 1:(ncol(test_data_matrix) - 1)];     test_data_matrix_target = test_data_matrix[, ncol(test_data_matrix)];     train_data_matrix_labels = to_categorical(train_data_matrix_target);     test_data_matrix_labels = to_categorical(test_data_matrix_target);     # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     # BEST RESULTS 1 hidden 180 units : 77.80%     # 2 hidden: 180 units + 90 units : 78.49968%     model %>%     layer_dense(units = 180, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 90, activation = 'relu') %>%     layer_dense(units = 45, activation = 'relu') %>%     layer_dense(units = 10, activation = 'relu') %>%     layer_dense(units = 5, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )     # Plot the history     plot(history)     # Plot the model loss of the training data     plot(history$metrics$loss, main = "Model Loss", xlab = "epoch", ylab = "loss", col = "blue", type = "l")     # Plot the model loss of the test data     lines(history$metrics$val_loss, col = "green")     # Add legend     legend("topright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Plot the accuracy of the training data      plot(history$metrics$acc, main = "Model Accuracy", xlab = "epoch", ylab = "accuracy", col = "blue", type = "l")     # Plot the accuracy of the validation data     lines(history$metrics$val_acc, col = "green")     # Add Legend     legend("bottomright", c("train", "test"), col = c("blue", "green"), lty = c(1, 1))     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)     return(output); }
library(imputeTS); library(dplyr); train_file = "Training Data.csv"; test_file = "Test Data.csv"; target_column = "manual_assessment"; train_data = baca(train_file); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; test_data = baca(test_file); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
hitungSoftmax = function(train_data,test_data) {     library(keras);     train_data$respon = as.numeric(train_data$respon)-1;     test_data$respon = as.numeric(test_data$respon) - 1;     train_data_norm = as.data.frame(lapply(train_data[1:(ncol(train_data)-1)], normalize));     test_data_norm = as.data.frame(lapply(test_data[1:(ncol(test_data) - 1)], normalize));     train_data_norm$respon = train_data$respon;     test_data_norm$respon = test_data$respon;     train_data_matrix = as.matrix(train_data);     test_data_matrix = as.matrix(test_data);     dimnames(train_data_matrix) = NULL;     dimnames(test_data_matrix) = NULL;     train_data_matrix_wTarget = train_data_matrix[, 1:(ncol(train_data_matrix) - 1)];     train_data_matrix_target = train_data_matrix[, ncol(train_data_matrix)];     test_data_matrix_wTarget = test_data_matrix[, 1:(ncol(test_data_matrix) - 1)];     test_data_matrix_target = test_data_matrix[, ncol(test_data_matrix)];     train_data_matrix_labels = to_categorical(train_data_matrix_target);     test_data_matrix_labels = to_categorical(test_data_matrix_target);     # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     # BEST RESULTS 1 hidden 180 units : 77.80%     # 2 hidden: 180 units + 90 units : 78.49968%     model %>%     layer_dense(units = 180, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 90, activation = 'relu') %>%     layer_dense(units = 45, activation = 'relu') %>%     layer_dense(units = 10, activation = 'relu') %>%     layer_dense(units = 5, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)     return(output); }
hitungSoftmax(train_dataset1_norm, test_dataset1_norm);
hitungSoftmax = function(train_data,test_data) {     library(keras);     train_data$respon = as.numeric(train_data$respon)-1;     test_data$respon = as.numeric(test_data$respon) - 1;     train_data_norm = as.data.frame(lapply(train_data[1:(ncol(train_data)-1)], normalize));     test_data_norm = as.data.frame(lapply(test_data[1:(ncol(test_data) - 1)], normalize));     train_data_norm$respon = train_data$respon;     test_data_norm$respon = test_data$respon;     train_data_matrix = as.matrix(train_data);     test_data_matrix = as.matrix(test_data);     dimnames(train_data_matrix) = NULL;     dimnames(test_data_matrix) = NULL;     train_data_matrix_wTarget = train_data_matrix[, 1:(ncol(train_data_matrix) - 1)];     train_data_matrix_target = train_data_matrix[, ncol(train_data_matrix)];     test_data_matrix_wTarget = test_data_matrix[, 1:(ncol(test_data_matrix) - 1)];     test_data_matrix_target = test_data_matrix[, ncol(test_data_matrix)];     train_data_matrix_labels = to_categorical(train_data_matrix_target);     test_data_matrix_labels = to_categorical(test_data_matrix_target);     # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     # BEST RESULTS 1 hidden 180 units : 77.80%     # 2 hidden: 180 units + 90 units : 78.49968%     model %>%     layer_dense(units = 180, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 90, activation = 'relu') %>%     layer_dense(units = 45, activation = 'relu') %>%     layer_dense(units = 5, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)     return(output); }
hitungSoftmax(train_dataset1_norm, test_dataset1_norm);
hitungSoftmax = function(train_data,test_data) {     library(keras);     train_data$respon = as.numeric(train_data$respon)-1;     test_data$respon = as.numeric(test_data$respon) - 1;     train_data_norm = as.data.frame(lapply(train_data[1:(ncol(train_data)-1)], normalize));     test_data_norm = as.data.frame(lapply(test_data[1:(ncol(test_data) - 1)], normalize));     train_data_norm$respon = train_data$respon;     test_data_norm$respon = test_data$respon;     train_data_matrix = as.matrix(train_data);     test_data_matrix = as.matrix(test_data);     dimnames(train_data_matrix) = NULL;     dimnames(test_data_matrix) = NULL;     train_data_matrix_wTarget = train_data_matrix[, 1:(ncol(train_data_matrix) - 1)];     train_data_matrix_target = train_data_matrix[, ncol(train_data_matrix)];     test_data_matrix_wTarget = test_data_matrix[, 1:(ncol(test_data_matrix) - 1)];     test_data_matrix_target = test_data_matrix[, ncol(test_data_matrix)];     train_data_matrix_labels = to_categorical(train_data_matrix_target);     test_data_matrix_labels = to_categorical(test_data_matrix_target);     # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     # BEST RESULTS 1 hidden 180 units : 77.80%     # 2 hidden: 180 relu units + 90 relu units : 78.49968%     model %>%     layer_dense(units = 70, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 35, activation = 'relu') %>%     layer_dense(units = 5, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)     return(output); }
hitungSoftmax(train_dataset1_norm, test_dataset1_norm);
install.packages("Kendall");
library(Kendal)
library(Kendall)
baca = function(nama_file) {     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } partisi = function(input_data,response_name) {     #70/30 partition     #column response as y     colnames(input_data)[colnames(input_data) == response_name] = "respon";     partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1);     dataTrain = input_data[partition_data,];     dataTrain$tipe = "training";     dataTest = input_data[-partition_data,];     dataTest$tipe = "testing";     output_data = rbind(dataTrain, dataTest);     return(output_data); } hitungSVM2 = function(train_data,test_data, target_respon, nu_value, gamma_value) {     library(e1071);     model = svm(subset(train_data,select = -respon), train_data$respon, type = 'one-classification', nu = nu_value, gamma=gamma_value);     pred_trains = predict(model, subset(train_data,select= -respon));     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM = function(input_data,target_respon,nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification',nu=nu_value);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi = function(input_data, target_respon) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data);     x = subset(df, select = -respon);     y = as.factor(df$respon);     model = svm(x, y, probability = TRUE);     pred_train = predict(model, x, decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon),decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i,1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi2 = function(train_data,test_data, c_value, gamma_value) {     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = svm(subset(train_data,select=-respon), train_data$respon, probability = TRUE,C=c_value,gamma=gamma_value);     pred_train = predict(model, subset(train_data, select = -respon), decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon), decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungDecisionTree = function(train_data,test_data) {     library(C50);     library(printr);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     print("CHAID");     library(party);     model = ctree(respon ~ ., data = train_data);     pred = predict(model, test_data);     print(confusionMatrix(pred, test_data$respon));     print("CART");     library(rpart);     model = rpart(respon ~ ., data = train_data, method = "class");     pred = predict(model, test_data, type = "class");     print(confusionMatrix(pred, test_data$respon));     print("C50");     model = C5.0(respon ~ ., data = train_data);     results = predict(object = model, newdata = test_data, type = "class");     pred = predict(model, test_data);     print(confusionMatrix(pred, test_data$respon)); } hitungRandomForest = function(train_data, test_data) {     library(caret);     library(randomForest);     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = randomForest(respon ~ ., data = train_data,importance=TRUE);     pred = predict(model, newdata = test_data);     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon));     return(model); } hitungNaiveBayes = function(train_data,test_data) {     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = naiveBayes(respon ~ ., data = train_data)     pred = predict(model, newdata = subset(test_data, select = -respon));     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); } hitungNaiveBayes_normalization = function(train_data, test_data) {     library(e1071)     library(forecast)     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     for (i in 1:(ncol(train_data)-1)) {             train_data[, i] = BoxCox(train_data[, i], BoxCox.lambda(train_data[, i]));     }     for (i in 1:(ncol(test_data)-1)) {             test_data[, i] = BoxCox(test_data[, i], BoxCox.lambda(test_data[, i]));     }     model = naiveBayes(respon ~ ., data = train_data)     pred = predict(model, newdata = subset(test_data, select = -respon));     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); } hitungFeaturesImportance = function(train_data,test_data,modelRandomForest) {     library(dplyr);     set.seed(12345);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     importances = data.frame(importance(modelRandomForest));     kolom_train_data = colnames(train_data)[1:ncol(train_data) - 1];     importances$kolom = kolom_train_data;     importances = rbind(importances, importances[1,]);     importancesMDA = importances %>%     select(kolom, MeanDecreaseAccuracy) %>%     arrange(-MeanDecreaseAccuracy) %>%     as.data.frame();     importancesMDG = importances %>%     select(kolom, MeanDecreaseGini) %>%     arrange(-MeanDecreaseGini) %>%     as.data.frame();     importancesMDA$results = -1;     for (i in 1:nrow(importancesMDA)) {         kolom = importancesMDA$kolom[1:(nrow(importancesMDA) - i)];         train_dataset1_normMDA = train_data %>%         select(kolom) %>%         as.data.frame();         train_dataset1_normMDA$respon = as.factor(train_data$respon);         test_dataset1_normMDA = test_data %>%         select(kolom) %>%         as.data.frame();         test_dataset1_normMDA$respon = as.factor(test_data$respon);         model = randomForest(respon ~ ., data = train_data, importance = TRUE);         pred = predict(model, newdata = test_data);         hasil = confusionMatrix(pred, test_data$respon);         akurasi = as.numeric(hasil$overall[1]);         importancesMDA$results[i] = akurasi;     }     return(importancesMDA); } # Build your own `normalize()` function normalize <- function(x) {     num <- x - min(x)     denom <- max(x) - min(x)     return(num / denom) }; hitungSoftmax = function(train_data,test_data) {     library(keras);     train_data$respon = as.numeric(train_data$respon)-1;     test_data$respon = as.numeric(test_data$respon) - 1;     train_data_norm = as.data.frame(lapply(train_data[1:(ncol(train_data)-1)], normalize));     test_data_norm = as.data.frame(lapply(test_data[1:(ncol(test_data) - 1)], normalize));     train_data_norm$respon = train_data$respon;     test_data_norm$respon = test_data$respon;     train_data_matrix = as.matrix(train_data);     test_data_matrix = as.matrix(test_data);     dimnames(train_data_matrix) = NULL;     dimnames(test_data_matrix) = NULL;     train_data_matrix_wTarget = train_data_matrix[, 1:(ncol(train_data_matrix) - 1)];     train_data_matrix_target = train_data_matrix[, ncol(train_data_matrix)];     test_data_matrix_wTarget = test_data_matrix[, 1:(ncol(test_data_matrix) - 1)];     test_data_matrix_target = test_data_matrix[, ncol(test_data_matrix)];     train_data_matrix_labels = to_categorical(train_data_matrix_target);     test_data_matrix_labels = to_categorical(test_data_matrix_target);     # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     # BEST RESULTS 1 hidden 180 units : 77.80%     # 2 hidden: 180 relu units + 90 relu units : 78.49968%     model %>%     layer_dense(units = 70, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 35, activation = 'relu') %>%     layer_dense(units = 5, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)     return(output); }
library(imputeTS); library(dplyr); train_file_action = "Training Data 1601 - Drop Column.csv"; test_file_action = "Test Data 1601 - Drop Column.csv"; train_file_word = "Training Data 1601 - Aggregated.csv"; test_file_word = "Test Data 1601 - Aggregated.csv"; target_column = "manual_assessment"; train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
set.seed(12345);
modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm);
hitungNaiveBayes(train_dataset1_norm, test_dataset1_norm); hitungDecisionTree(train_dataset1_norm, test_dataset1_norm);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]);
head(importances)
head(importances[,6:8])
write.csv(importances[,6:8])
write.csv(importances[, 6:8], file = "C:/features_importance");
real_value = test_dataset1_norm$respon;
train_data_back = train_data;
test_data_back = test_data;
train_data = train_dataset1_norm;
test_data = test_dataset1_norm;
    train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = randomForest(respon ~ ., data = train_data,importance=TRUE);     pred = predict(model, newdata = test_data);
str(train_dataset1_assesed)
str(train_dataset1_norm)
head(pred)
head(train_dataset1_norm$respon)
head(pred,15)
tail(pred,15)
tail(pred,25)
tail(pred,50)
nrow(pred)
length(pred)
length(train_dataset1_norm)
nrow(train_dataset1_norm)
nrow(train_dataset1_norm$respon)
respon(train_dataset1_norm$respon)
length(train_dataset1_norm$respon)
nrow(test_dataset1_norm)
Kendall(pred,test_dataset1_norm$respon)
pred[pred==5]
length(pred[pred==5])
length(pred[pred!=5])
Kendall(pred,test_dataset1_norm$respon)
str(train_dataset1_norm)
str(Kendall(pred,test_dataset1_norm$respon))
str(Kendall(pred,test_dataset1_norm$respon))[1]
Kendall(pred,test_dataset1_norm$respon)[[1]]
Kendall(pred,test_dataset1_norm$respon)[[1]][1]
tau_value = Kendall(pred,test_dataset1_norm$respon)[[1]][1]
(tau_value * 2) / (5 * 4);
Kendall(pred,pred)
Kendall(pred,test_dataset1_norm$respon)
unique(pred,test_dataset1_norm$respon)
(pred, test_dataset1_norm$respon); ;
library(dplyr)
head(test_dataset1_norm$respon,50)
head(pred,50)
confusionMatrix(pred,test_dataset1_norm$respon)
predict_value = pred;
nrow(train_file_action)
nrow(train_file_actilibrary(imputeTS); library(dplyr); train_file_action = "Training Data 1601 - Drop Column.csv"; test_file_action = "Test Data 1601 - Drop Column.csv"; train_file_word = "Training Data 1601 - Aggregated.csv"; test_file_word = "Test Data 1601 - Aggregated.csv"; target_column = "manual_assessment"; on)
library(imputeTS); library(dplyr); train_file_action = "Training Data 1601 - Drop Column.csv"; test_file_action = "Test Data 1601 - Drop Column.csv"; train_file_word = "Training Data 1601 - Aggregated.csv"; test_file_word = "Test Data 1601 - Aggregated.csv"; target_column = "manual_assessment";
train_data = baca(train_file_action);
nrow(train_data);
nrow(train_data)library(imputeTS); library(dplyr); train_file_action = "Training Data 1601 - Drop Column.csv"; test_file_action = "Test Data 1601 - Drop Column.csv"; train_file_word = "Training Data 1601 - Aggregated.csv"; test_file_word = "Test Data 1601 - Aggregated.csv"; target_column = "manual_assessment"; train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0] ;
nrow(train_dataset1_norm)
nrow(train_data)
nrow(train_data library(imputeTS); library(dplyr); train_file_action = "Training Data 1601 - Drop Column.csv"; test_file_action = "Test Data 1601 - Drop Column.csv"; train_file_word = "Training Data 1601 - Aggregated.csv"; test_file_word = "Test Data 1601 - Aggregated.csv"; target_column = "manual_assessment"; train_data = baca(train_file_word); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; test_data = baca(test_file_word); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0] )
nrow(train_data)
nrow(test_data)
baca = function(nama_file) {     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } partisi = function(input_data,response_name) {     #70/30 partition     #column response as y     colnames(input_data)[colnames(input_data) == response_name] = "respon";     partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1);     dataTrain = input_data[partition_data,];     dataTrain$tipe = "training";     dataTest = input_data[-partition_data,];     dataTest$tipe = "testing";     output_data = rbind(dataTrain, dataTest);     return(output_data); } hitungSVM2 = function(train_data,test_data, target_respon, nu_value, gamma_value) {     library(e1071);     model = svm(subset(train_data,select = -respon), train_data$respon, type = 'one-classification', nu = nu_value, gamma=gamma_value);     pred_trains = predict(model, subset(train_data,select= -respon));     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM = function(input_data,target_respon,nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification',nu=nu_value);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi = function(input_data, target_respon) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data);     x = subset(df, select = -respon);     y = as.factor(df$respon);     model = svm(x, y, probability = TRUE);     pred_train = predict(model, x, decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon),decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i,1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi2 = function(train_data,test_data, c_value, gamma_value) {     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = svm(subset(train_data,select=-respon), train_data$respon, probability = TRUE,C=c_value,gamma=gamma_value);     pred_train = predict(model, subset(train_data, select = -respon), decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon), decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungDecisionTree = function(train_data,test_data) {     library(C50);     library(printr);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     print("CHAID");     library(party);     model = ctree(respon ~ ., data = train_data);     pred = predict(model, test_data);     print(confusionMatrix(pred, test_data$respon));     print("CART");     library(rpart);     model = rpart(respon ~ ., data = train_data, method = "class");     pred = predict(model, test_data, type = "class");     print(confusionMatrix(pred, test_data$respon));     print("C50");     model = C5.0(respon ~ ., data = train_data);     results = predict(object = model, newdata = test_data, type = "class");     pred = predict(model, test_data);     print(confusionMatrix(pred, test_data$respon)); } hitungRandomForest = function(train_data, test_data) {     library(caret);     library(randomForest);     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = randomForest(respon ~ ., data = train_data,importance=TRUE);     pred = predict(model, newdata = test_data);     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon));     return(model); } hitungNaiveBayes = function(train_data,test_data) {     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = naiveBayes(respon ~ ., data = train_data)     pred = predict(model, newdata = subset(test_data, select = -respon));     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); } hitungNaiveBayes_normalization = function(train_data, test_data) {     library(e1071)     library(forecast)     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     for (i in 1:(ncol(train_data)-1)) {             train_data[, i] = BoxCox(train_data[, i], BoxCox.lambda(train_data[, i]));     }     for (i in 1:(ncol(test_data)-1)) {             test_data[, i] = BoxCox(test_data[, i], BoxCox.lambda(test_data[, i]));     }     model = naiveBayes(respon ~ ., data = train_data)     pred = predict(model, newdata = subset(test_data, select = -respon));     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); } hitungFeaturesImportance = function(train_data,test_data,modelRandomForest) {     library(dplyr);     set.seed(12345);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     importances = data.frame(importance(modelRandomForest));     kolom_train_data = colnames(train_data)[1:ncol(train_data) - 1];     importances$kolom = kolom_train_data;     importances = rbind(importances, importances[1,]);     importancesMDA = importances %>%     select(kolom, MeanDecreaseAccuracy) %>%     arrange(-MeanDecreaseAccuracy) %>%     as.data.frame();     importancesMDG = importances %>%     select(kolom, MeanDecreaseGini) %>%     arrange(-MeanDecreaseGini) %>%     as.data.frame();     importancesMDA$results = -1;     for (i in 1:nrow(importancesMDA)) {         kolom = importancesMDA$kolom[1:(nrow(importancesMDA) - i)];         train_dataset1_normMDA = train_data %>%         select(kolom) %>%         as.data.frame();         train_dataset1_normMDA$respon = as.factor(train_data$respon);         test_dataset1_normMDA = test_data %>%         select(kolom) %>%         as.data.frame();         test_dataset1_normMDA$respon = as.factor(test_data$respon);         model = randomForest(respon ~ ., data = train_data, importance = TRUE);         pred = predict(model, newdata = test_data);         hasil = confusionMatrix(pred, test_data$respon);         akurasi = as.numeric(hasil$overall[1]);         importancesMDA$results[i] = akurasi;     }     return(importancesMDA); } # Build your own `normalize()` function normalize <- function(x) {     num <- x - min(x)     denom <- max(x) - min(x)     return(num / denom) }; hitungSoftmax = function(train_data,test_data) {     library(keras);     train_data$respon = as.numeric(train_data$respon)-1;     test_data$respon = as.numeric(test_data$respon) - 1;     train_data_norm = as.data.frame(lapply(train_data[1:(ncol(train_data)-1)], normalize));     test_data_norm = as.data.frame(lapply(test_data[1:(ncol(test_data) - 1)], normalize));     train_data_norm$respon = train_data$respon;     test_data_norm$respon = test_data$respon;     train_data_matrix = as.matrix(train_data);     test_data_matrix = as.matrix(test_data);     dimnames(train_data_matrix) = NULL;     dimnames(test_data_matrix) = NULL;     train_data_matrix_wTarget = train_data_matrix[, 1:(ncol(train_data_matrix) - 1)];     train_data_matrix_target = train_data_matrix[, ncol(train_data_matrix)];     test_data_matrix_wTarget = test_data_matrix[, 1:(ncol(test_data_matrix) - 1)];     test_data_matrix_target = test_data_matrix[, ncol(test_data_matrix)];     train_data_matrix_labels = to_categorical(train_data_matrix_target);     test_data_matrix_labels = to_categorical(test_data_matrix_target);     # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     # BEST RESULTS 1 hidden 180 units : 77.80%     # 2 hidden: 180 relu units + 90 relu units : 78.49968%     model %>%     layer_dense(units = 70, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 35, activation = 'relu') %>%     layer_dense(units = 5, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)     return(output); }
library(imputeTS); library(dplyr); train_file_action = "Training Data 1601 - Drop Column.csv"; test_file_action = "Test Data 1601 - Drop Column.csv"; train_file_word = "Training Data 1601 - Aggregated.csv"; test_file_word = "Test Data 1601 - Aggregated.csv"; target_column = "manual_assessment"; train_data = baca(train_file_word); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; test_data = baca(test_file_word); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm);
set.seed(12345);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q96MDA = quantile(importances$MeanDecreaseAccuracy, 0.96); q96MDG = quantile(importances$MeanDecreaseGini, 0.96); q97MDA = quantile(importances$MeanDecreaseAccuracy, 0.97); q97MDG = quantile(importances$MeanDecreaseGini, 0.97); q98MDA = quantile(importances$MeanDecreaseAccuracy, 0.98); q98MDG = quantile(importances$MeanDecreaseGini, 0.98); #Spearman, Kendall, Polycholic importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= meanMDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= meanMDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
hitungNaiveBayes(train_dataset1_norm, test_dataset1_norm); hitungDecisionTree(train_dataset1_norm, test_dataset1_norm);
str(train_data)
str(train_dataset1_norm)
library(e1071); train_data_back = train_data; test_data_back = test_data; train_data = train_dataset1_norm; test_data = test_dataset1_norm; train_data5 = subset(train_data, respon == 5, select = -respon); train_data54 = subset(train_data, respon >= 4, select = -respon); train_data543 = subset(train_data, respon >= 3, select = -respon); train_data5432 = subset(train_data, respon >= 2, select = -respon); #Best nu=0.001, gamma=0.01 accuracy=78.03 #model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); #model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.1,gamma=0.01); model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.1, gamma = 1); model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.1, gamma = 0.01); model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.1, gamma = 1); pred5 = predict(model5, subset(test_data,select=-respon)); pred4 = predict(model54, subset(test_data, select = -respon)); pred3 = predict(model543, subset(test_data, select = -respon)); pred2 = predict(model5432, subset(test_data, select = -respon)); head(pred5); head(pred4); head(pred3); head(pred2); head(test_data$respon); preds = data.frame(pred5, pred4, pred3, pred2); preds$pred = -1; for (i in 1:nrow(preds)) {     if (preds$pred5[i]) {         preds$pred[i] = 5;     } else {         if (preds$pred4[i]) {             preds$pred[i] = 4;         } else {             if (preds$pred3[i]) {                 preds$pred[i] = 3;             } else {                 if (preds$pred2[i]) {                     preds$pred[i] = 2;                 } else {                     preds$pred[i] = 1;                 }             }         }     } } preds$target = test_data$respon; confusionMatrix(preds$pred, test_data$respon); test_data %>% group_by(respon) %>% summarise(jumlah_data = n(), persentase = n() / 4679) %>% as.data.frame();
str(train_data)
head(train_dataset1_norm$respon,10)
head(pred,10)
data12 = subset(test_dataset1_norm, respon == 1 | respon == 2) data23 = subset(test_dataset1_norm, respon == 2 | respon == 3) data34 = subset(test_dataset1_norm, respon == 3 | respon == 4) data45 = subset(test_dataset1_norm, respon == 4 | respon == 5)
test_dataset1_norm$pred = pred;
library(imputeTS); library(dplyr); train_file_action = "Training Data 1601 - Drop Column.csv"; test_file_action = "Test Data 1601 - Drop Column.csv"; train_file_word = "Training Data 1601 - Aggregated.csv"; test_file_word = "Test Data 1601 - Aggregated.csv"; target_column = "manual_assessment"; train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
set.seed(12345);
modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm);
train_data_back = train_data
test_data_back = test_data
train_data = train_dataset1_norm
test_data = test_dataset1_norm
modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm);
str(train_data)
str(train_dataset1_norm)
library(caret);     library(randomForest);     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = randomForest(respon ~ ., data = train_data,importance=TRUE);     pred = predict(model, newdata = test_data);
test_dataset1_norm$pred = pred; data12 = subset(test_dataset1_norm, respon == 1 | respon == 2) data23 = subset(test_dataset1_norm, respon == 2 | respon == 3) data34 = subset(test_dataset1_norm, respon == 3 | respon == 4) data45 = subset(test_dataset1_norm, respon == 4 | respon == 5) data12$pred[respon != 1] = 2; data23$pred[respon != 2] = 3; data34$pred[respon != 3] = 4; data45$pred[respon != 4] = 5;
str(pred)
test_dataset1_norm$pred = as.numeric(pred); test_dataset1_norm$respon = as.numeric(respon);
str(test_dataset1_norm)
data12 = subset(test_dataset1_norm, respon == 1 | respon == 2) data23 = subset(test_dataset1_norm, respon == 2 | respon == 3) data34 = subset(test_dataset1_norm, respon == 3 | respon == 4) data45 = subset(test_dataset1_norm, respon == 4 | respon == 5) data12$pred[respon != 1] = 2; data23$pred[respon != 2] = 3; data34$pred[respon != 3] = 4; data45$pred[respon != 4] = 5;
data12 = subset(test_dataset1_norm, test_dataset1_norm$respon == 1 | test_dataset1_norm$respon == 2) data23 = subset(test_dataset1_norm, test_dataset1_norm$respon == 2 | test_dataset1_norm$respon == 3) data34 = subset(test_dataset1_norm, test_dataset1_norm$respon == 3 | test_dataset1_norm$respon == 4) data45 = subset(test_dataset1_norm, test_dataset1_norm$respon == 4 | test_dataset1_norm$respon == 5) data12$pred[test_dataset1_norm$respon != 1] = 2; data23$pred[test_dataset1_norm$respon != 2] = 3; data34$pred[test_dataset1_norm$respon != 3] = 4; data45$pred[test_dataset1_norm$respon != 4] = 5;
baca = function(nama_file) {     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } partisi = function(input_data,response_name) {     #70/30 partition     #column response as y     colnames(input_data)[colnames(input_data) == response_name] = "respon";     partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1);     dataTrain = input_data[partition_data,];     dataTrain$tipe = "training";     dataTest = input_data[-partition_data,];     dataTest$tipe = "testing";     output_data = rbind(dataTrain, dataTest);     return(output_data); } hitungSVM2 = function(train_data,test_data, target_respon, nu_value, gamma_value) {     library(e1071);     model = svm(subset(train_data,select = -respon), train_data$respon, type = 'one-classification', nu = nu_value, gamma=gamma_value);     pred_trains = predict(model, subset(train_data,select= -respon));     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM = function(input_data,target_respon,nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification',nu=nu_value);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi = function(input_data, target_respon) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data);     x = subset(df, select = -respon);     y = as.factor(df$respon);     model = svm(x, y, probability = TRUE);     pred_train = predict(model, x, decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon),decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i,1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi2 = function(train_data,test_data, c_value, gamma_value) {     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = svm(subset(train_data,select=-respon), train_data$respon, probability = TRUE,C=c_value,gamma=gamma_value);     pred_train = predict(model, subset(train_data, select = -respon), decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon), decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungDecisionTree = function(train_data,test_data) {     library(C50);     library(printr);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     print("CHAID");     library(party);     model = ctree(respon ~ ., data = train_data);     pred = predict(model, test_data);     print(confusionMatrix(pred, test_data$respon));     print("CART");     library(rpart);     model = rpart(respon ~ ., data = train_data, method = "class");     pred = predict(model, test_data, type = "class");     print(confusionMatrix(pred, test_data$respon));     print("C50");     model = C5.0(respon ~ ., data = train_data);     results = predict(object = model, newdata = test_data, type = "class");     pred = predict(model, test_data);     print(confusionMatrix(pred, test_data$respon)); } hitungRandomForest = function(train_data, test_data) {     library(caret);     library(randomForest);     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = randomForest(respon ~ ., data = train_data,importance=TRUE);     pred = predict(model, newdata = test_data);     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon));     return(model); } hitungNaiveBayes = function(train_data,test_data) {     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = naiveBayes(respon ~ ., data = train_data)     pred = predict(model, newdata = subset(test_data, select = -respon));     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); } hitungNaiveBayes_normalization = function(train_data, test_data) {     library(e1071)     library(forecast)     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     for (i in 1:(ncol(train_data)-1)) {             train_data[, i] = BoxCox(train_data[, i], BoxCox.lambda(train_data[, i]));     }     for (i in 1:(ncol(test_data)-1)) {             test_data[, i] = BoxCox(test_data[, i], BoxCox.lambda(test_data[, i]));     }     model = naiveBayes(respon ~ ., data = train_data)     pred = predict(model, newdata = subset(test_data, select = -respon));     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); } hitungFeaturesImportance = function(train_data,test_data,modelRandomForest) {     library(dplyr);     set.seed(12345);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     importances = data.frame(importance(modelRandomForest));     kolom_train_data = colnames(train_data)[1:ncol(train_data) - 1];     importances$kolom = kolom_train_data;     importances = rbind(importances, importances[1,]);     importancesMDA = importances %>%     select(kolom, MeanDecreaseAccuracy) %>%     arrange(-MeanDecreaseAccuracy) %>%     as.data.frame();     importancesMDG = importances %>%     select(kolom, MeanDecreaseGini) %>%     arrange(-MeanDecreaseGini) %>%     as.data.frame();     importancesMDA$results = -1;     for (i in 1:nrow(importancesMDA)) {         kolom = importancesMDA$kolom[1:(nrow(importancesMDA) - i)];         train_dataset1_normMDA = train_data %>%         select(kolom) %>%         as.data.frame();         train_dataset1_normMDA$respon = as.factor(train_data$respon);         test_dataset1_normMDA = test_data %>%         select(kolom) %>%         as.data.frame();         test_dataset1_normMDA$respon = as.factor(test_data$respon);         model = randomForest(respon ~ ., data = train_data, importance = TRUE);         pred = predict(model, newdata = test_data);         hasil = confusionMatrix(pred, test_data$respon);         akurasi = as.numeric(hasil$overall[1]);         importancesMDA$results[i] = akurasi;     }     return(importancesMDA); } # Build your own `normalize()` function normalize <- function(x) {     num <- x - min(x)     denom <- max(x) - min(x)     return(num / denom) }; hitungSoftmax = function(train_data,test_data) {     library(keras);     train_data$respon = as.numeric(train_data$respon)-1;     test_data$respon = as.numeric(test_data$respon) - 1;     train_data_norm = as.data.frame(lapply(train_data[1:(ncol(train_data)-1)], normalize));     test_data_norm = as.data.frame(lapply(test_data[1:(ncol(test_data) - 1)], normalize));     train_data_norm$respon = train_data$respon;     test_data_norm$respon = test_data$respon;     train_data_matrix = as.matrix(train_data);     test_data_matrix = as.matrix(test_data);     dimnames(train_data_matrix) = NULL;     dimnames(test_data_matrix) = NULL;     train_data_matrix_wTarget = train_data_matrix[, 1:(ncol(train_data_matrix) - 1)];     train_data_matrix_target = train_data_matrix[, ncol(train_data_matrix)];     test_data_matrix_wTarget = test_data_matrix[, 1:(ncol(test_data_matrix) - 1)];     test_data_matrix_target = test_data_matrix[, ncol(test_data_matrix)];     train_data_matrix_labels = to_categorical(train_data_matrix_target);     test_data_matrix_labels = to_categorical(test_data_matrix_target);     # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     # BEST RESULTS 1 hidden 180 units : 77.80%     # 2 hidden: 180 relu units + 90 relu units : 78.49968%     model %>%     layer_dense(units = 70, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 35, activation = 'relu') %>%     layer_dense(units = 5, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)     return(output); }
library(imputeTS); library(dplyr); train_file_action = "Training Data 1801 - Drop Column.csv"; test_file_action = "Test Data 1801 - Drop Column.csv";
train_file_word = "Training Data 1801 - Aggregated.csv"; test_file_word = "Test Data 1801 - Aggregated.csv"; target_column = "manual_assessment";
train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL;
train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm);
hitungNaiveBayes(train_dataset1_norm, test_dataset1_norm); hitungDecisionTree(train_dataset1_norm, test_dataset1_norm);
train_file_action = "Training Data 1801 - Drop Column - Balanced.csv"; test_file_action = "Test Data 1801 - Drop Column - Balanced.csv";
train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL;
nrow(train_data)
train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
set.seed(12345); modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm); hitungNaiveBayes(train_dataset1_norm, test_dataset1_norm); hitungDecisionTree(train_dataset1_norm, test_dataset1_norm);
train_file_action = "Training Data 1801.csv"; test_file_action = "Test Data 1801.csv";
train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
set.seed(12345); modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm); hitungNaiveBayes(train_dataset1_norm, test_dataset1_norm); hitungDecisionTree(train_dataset1_norm, test_dataset1_norm);
train_file_action = "Training Data 1801 - Balanced.csv"; test_file_action = "Test Data 1801 - Balanced.csv";
train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
set.seed(12345); modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm); hitungNaiveBayes(train_dataset1_norm, test_dataset1_norm); hitungDecisionTree(train_dataset1_norm, test_dataset1_norm);
train_file_action = "Training Data 1801 - Aggregated.csv"; test_file_action = "Test Data 1801 - Aggregated.csv";
train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
library(imputeTS); library(dplyr); train_file_action = "Training Data 1801 - Aggregated.csv"; test_file_action = "Test Data 1801 - Aggregated.csv"; train_file_word = "Training Data 1801 - Aggregated.csv"; test_file_word = "Test Data 1801 - Aggregated.csv"; target_column = "manual_assessment"; train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
str(train_data)
library(imputeTS); library(dplyr); train_file_action = "Training Data 1801 - Aggregated.csv"; test_file_action = "Test Data 1801 - Aggregated.csv"; train_file_word = "Training Data 1801 - Aggregated.csv"; test_file_word = "Test Data 1801 - Aggregated.csv"; target_column = "manual_assessment"; train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; train_data$source.word = NULL; train_data$target.word = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; test_data$source.word = NULL; test_data$target.word = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
str(train_data)
set.seed(12345); modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm); hitungNaiveBayes(train_dataset1_norm, test_dataset1_norm); hitungDecisionTree(train_dataset1_norm, test_dataset1_norm);
library(imputeTS); library(dplyr); train_file_action = "Training Data 1801 - Aggregated Balanced.csv"; test_file_action = "Test Data 1801 - Aggregated Balanced.csv"; train_file_word = "Training Data 1801 - Aggregated.csv"; test_file_word = "Test Data 1801 - Aggregated.csv"; target_column = "manual_assessment"; train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; train_data$source.word = NULL; train_data$target.word = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; test_data$source.word = NULL; test_data$target.word = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
set.seed(12345); modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm); hitungNaiveBayes(train_dataset1_norm, test_dataset1_norm); hitungDecisionTree(train_dataset1_norm, test_dataset1_norm);
baca = function(nama_file) {     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } partisi = function(input_data,response_name) {     #70/30 partition     #column response as y     colnames(input_data)[colnames(input_data) == response_name] = "respon";     partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1);     dataTrain = input_data[partition_data,];     dataTrain$tipe = "training";     dataTest = input_data[-partition_data,];     dataTest$tipe = "testing";     output_data = rbind(dataTrain, dataTest);     return(output_data); } hitungSVM2 = function(train_data,test_data, target_respon, nu_value, gamma_value) {     library(e1071);     model = svm(subset(train_data,select = -respon), train_data$respon, type = 'one-classification', nu = nu_value, gamma=gamma_value);     pred_trains = predict(model, subset(train_data,select= -respon));     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM = function(input_data,target_respon,nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification',nu=nu_value);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi = function(input_data, target_respon) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data);     x = subset(df, select = -respon);     y = as.factor(df$respon);     model = svm(x, y, probability = TRUE);     pred_train = predict(model, x, decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon),decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i,1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi2 = function(train_data,test_data, c_value, gamma_value) {     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = svm(subset(train_data,select=-respon), train_data$respon, probability = TRUE,C=c_value,gamma=gamma_value);     pred_train = predict(model, subset(train_data, select = -respon), decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon), decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungDecisionTree = function(train_data,test_data) {     library(C50);     library(printr);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     print("CHAID");     library(party);     model = ctree(respon ~ ., data = train_data);     pred = predict(model, test_data);     print(confusionMatrix(pred, test_data$respon));     print("CART");     library(rpart);     model = rpart(respon ~ ., data = train_data, method = "class");     pred = predict(model, test_data, type = "class");     print(confusionMatrix(pred, test_data$respon));     print("C50");     model = C5.0(respon ~ ., data = train_data);     results = predict(object = model, newdata = test_data, type = "class");     pred = predict(model, test_data);     print(confusionMatrix(pred, test_data$respon)); } hitungRandomForest = function(train_data, test_data) {     library(caret);     library(randomForest);     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = randomForest(respon ~ ., data = train_data,importance=TRUE);     pred = predict(model, newdata = test_data);     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon));     return(model); } hitungNaiveBayes = function(train_data,test_data) {     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = naiveBayes(respon ~ ., data = train_data)     pred = predict(model, newdata = subset(test_data, select = -respon));     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); } hitungNaiveBayes_normalization = function(train_data, test_data) {     library(e1071)     library(forecast)     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     for (i in 1:(ncol(train_data)-1)) {             train_data[, i] = BoxCox(train_data[, i], BoxCox.lambda(train_data[, i]));     }     for (i in 1:(ncol(test_data)-1)) {             test_data[, i] = BoxCox(test_data[, i], BoxCox.lambda(test_data[, i]));     }     model = naiveBayes(respon ~ ., data = train_data)     pred = predict(model, newdata = subset(test_data, select = -respon));     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); } hitungFeaturesImportance = function(train_data,test_data,modelRandomForest) {     library(dplyr);     set.seed(12345);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     importances = data.frame(importance(modelRandomForest));     kolom_train_data = colnames(train_data)[1:ncol(train_data) - 1];     importances$kolom = kolom_train_data;     importances = rbind(importances, importances[1,]);     importancesMDA = importances %>%     select(kolom, MeanDecreaseAccuracy) %>%     arrange(-MeanDecreaseAccuracy) %>%     as.data.frame();     importancesMDG = importances %>%     select(kolom, MeanDecreaseGini) %>%     arrange(-MeanDecreaseGini) %>%     as.data.frame();     importancesMDA$results = -1;     for (i in 1:nrow(importancesMDA)) {         kolom = importancesMDA$kolom[1:(nrow(importancesMDA) - i)];         train_dataset1_normMDA = train_data %>%         select(kolom) %>%         as.data.frame();         train_dataset1_normMDA$respon = as.factor(train_data$respon);         test_dataset1_normMDA = test_data %>%         select(kolom) %>%         as.data.frame();         test_dataset1_normMDA$respon = as.factor(test_data$respon);         model = randomForest(respon ~ ., data = train_data, importance = TRUE);         pred = predict(model, newdata = test_data);         hasil = confusionMatrix(pred, test_data$respon);         akurasi = as.numeric(hasil$overall[1]);         importancesMDA$results[i] = akurasi;     }     return(importancesMDA); } # Build your own `normalize()` function normalize <- function(x) {     num <- x - min(x)     denom <- max(x) - min(x)     return(num / denom) }; hitungSoftmax = function(train_data,test_data) {     library(keras);     train_data$respon = as.numeric(train_data$respon)-1;     test_data$respon = as.numeric(test_data$respon) - 1;     train_data_norm = as.data.frame(lapply(train_data[1:(ncol(train_data)-1)], normalize));     test_data_norm = as.data.frame(lapply(test_data[1:(ncol(test_data) - 1)], normalize));     train_data_norm$respon = train_data$respon;     test_data_norm$respon = test_data$respon;     train_data_matrix = as.matrix(train_data);     test_data_matrix = as.matrix(test_data);     dimnames(train_data_matrix) = NULL;     dimnames(test_data_matrix) = NULL;     train_data_matrix_wTarget = train_data_matrix[, 1:(ncol(train_data_matrix) - 1)];     train_data_matrix_target = train_data_matrix[, ncol(train_data_matrix)];     test_data_matrix_wTarget = test_data_matrix[, 1:(ncol(test_data_matrix) - 1)];     test_data_matrix_target = test_data_matrix[, ncol(test_data_matrix)];     train_data_matrix_labels = to_categorical(train_data_matrix_target);     test_data_matrix_labels = to_categorical(test_data_matrix_target);     # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     # BEST RESULTS 1 hidden 180 units : 77.80%     # 2 hidden: 180 relu units + 90 relu units : 78.49968%     model %>%     layer_dense(units = 70, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 35, activation = 'relu') %>%     layer_dense(units = 5, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)     return(output); }
library(imputeTS); library(dplyr); train_file_action = "Training Data 1801 - Drop Column - Balanced.csv"; test_file_action = "Test Data 1801 - Drop Column - Balanced.csv"; train_file_word = "Training Data 1801 - Aggregated.csv"; test_file_word = "Test Data 1801 - Aggregated.csv"; target_column = "manual_assessment"; train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; train_data$source.word = NULL; train_data$target.word = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; test_data$source.word = NULL; test_data$target.word = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
set.seed(12345); modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini);
importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= meanMDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= meanMDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q96MDA = quantile(importances$MeanDecreaseAccuracy, 0.96); q96MDG = quantile(importances$MeanDecreaseGini, 0.96); q97MDA = quantile(importances$MeanDecreaseAccuracy, 0.97); q97MDG = quantile(importances$MeanDecreaseGini, 0.97); q98MDA = quantile(importances$MeanDecreaseAccuracy, 0.98); q98MDG = quantile(importances$MeanDecreaseGini, 0.98); #Spearman, Kendall, Polycholic importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= q96MDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= q96MDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q96MDA = quantile(importances$MeanDecreaseAccuracy, 0.96); q96MDG = quantile(importances$MeanDecreaseGini, 0.96); q97MDA = quantile(importances$MeanDecreaseAccuracy, 0.97); q97MDG = quantile(importances$MeanDecreaseGini, 0.97); q98MDA = quantile(importances$MeanDecreaseAccuracy, 0.98); q98MDG = quantile(importances$MeanDecreaseGini, 0.98); #Spearman, Kendall, Polycholic importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= q95MDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= q95MDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q96MDA = quantile(importances$MeanDecreaseAccuracy, 0.96); q96MDG = quantile(importances$MeanDecreaseGini, 0.96); q97MDA = quantile(importances$MeanDecreaseAccuracy, 0.97); q97MDG = quantile(importances$MeanDecreaseGini, 0.97); q98MDA = quantile(importances$MeanDecreaseAccuracy, 0.98); q98MDG = quantile(importances$MeanDecreaseGini, 0.98); #Spearman, Kendall, Polycholic importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= q90MDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= q90MDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q96MDA = quantile(importances$MeanDecreaseAccuracy, 0.96); q96MDG = quantile(importances$MeanDecreaseGini, 0.96); q97MDA = quantile(importances$MeanDecreaseAccuracy, 0.97); q97MDG = quantile(importances$MeanDecreaseGini, 0.97); q98MDA = quantile(importances$MeanDecreaseAccuracy, 0.98); q98MDG = quantile(importances$MeanDecreaseGini, 0.98); #Spearman, Kendall, Polycholic importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= q85MDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= q85MDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
str(train_dataset1_normMDA)
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q96MDA = quantile(importances$MeanDecreaseAccuracy, 0.96); q96MDG = quantile(importances$MeanDecreaseGini, 0.96); q97MDA = quantile(importances$MeanDecreaseAccuracy, 0.97); q97MDG = quantile(importances$MeanDecreaseGini, 0.97); q98MDA = quantile(importances$MeanDecreaseAccuracy, 0.98); q98MDG = quantile(importances$MeanDecreaseGini, 0.98); #Spearman, Kendall, Polycholic importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= meanMDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= meanMDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
str(train_dataset1_normMDA)
featuresMDA
library(dplyr)
featuresMDA %>% arrange(-MeanDecreaseAccuracy) %>% as.data.frame();
featuresMDA %>% arrange(-MeanDecreaseAccuracy) %>% select(kolom,MeanDecreaseAccuracy) %>% as.data.frame();
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q96MDA = quantile(importances$MeanDecreaseAccuracy, 0.96); q96MDG = quantile(importances$MeanDecreaseGini, 0.96); q97MDA = quantile(importances$MeanDecreaseAccuracy, 0.97); q97MDG = quantile(importances$MeanDecreaseGini, 0.97); q98MDA = quantile(importances$MeanDecreaseAccuracy, 0.98); q98MDG = quantile(importances$MeanDecreaseGini, 0.98); #Spearman, Kendall, Polycholic importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= q85MDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= q85MDA] = 1; featuresMDA %>% arrange(-MeanDecreaseAccuracy) %>% select(kolom, MeanDecreaseAccuracy) %>% as.data.frame(); featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
featuresMDA %>% arrange(-MeanDecreaseAccuracy) %>% select(kolom, MeanDecreaseAccuracy) %>% as.data.frame();
train_data_back = train_data;
test_data_back = test_data;
train_data = train_dataset1_norm;
test_data = test_dataset1_norm;
str(train_data)
    library(keras);     train_data$respon = as.numeric(train_data$respon)-1;     test_data$respon = as.numeric(test_data$respon) - 1;     train_data_norm = as.data.frame(lapply(train_data[1:(ncol(train_data)-1)], normalize));     test_data_norm = as.data.frame(lapply(test_data[1:(ncol(test_data) - 1)], normalize));     train_data_norm$respon = train_data$respon;     test_data_norm$respon = test_data$respon;     train_data_matrix = as.matrix(train_data);     test_data_matrix = as.matrix(test_data);     dimnames(train_data_matrix) = NULL;     dimnames(test_data_matrix) = NULL;     train_data_matrix_wTarget = train_data_matrix[, 1:(ncol(train_data_matrix) - 1)];     train_data_matrix_target = train_data_matrix[, ncol(train_data_matrix)];     test_data_matrix_wTarget = test_data_matrix[, 1:(ncol(test_data_matrix) - 1)];     test_data_matrix_target = test_data_matrix[, ncol(test_data_matrix)];     train_data_matrix_labels = to_categorical(train_data_matrix_target);     test_data_matrix_labels = to_categorical(test_data_matrix_target);     # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     # BEST RESULTS 1 hidden 180 units : 77.80%     # 2 hidden: 180 relu units + 90 relu units : 78.49968%     model %>%     layer_dense(units = 180, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 90, activation = 'relu') %>%     layer_dense(units = 5, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)
    # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     # BEST RESULTS 1 hidden 180 units : 77.80%     # 2 hidden: 180 relu units + 90 relu units : 78.49968%     model %>%     layer_dense(units = 180, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 5, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)
train_data = train_dataset1_norm; test_data = test_dataset1_norm; train_data5 = subset(train_data, respon == 5, select = -respon); train_data54 = subset(train_data, respon >= 4, select = -respon); train_data543 = subset(train_data, respon >= 3, select = -respon); train_data5432 = subset(train_data, respon >= 2, select = -respon); #Best nu=0.001, gamma=0.01 accuracy=78.03 #model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); #model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.1,gamma=0.01); model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.1, gamma = 1); model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.1, gamma = 0.01); model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.1, gamma = 1); pred5 = predict(model5, subset(test_data,select=-respon)); pred4 = predict(model54, subset(test_data, select = -respon)); pred3 = predict(model543, subset(test_data, select = -respon)); pred2 = predict(model5432, subset(test_data, select = -respon)); head(pred5); head(pred4); head(pred3); head(pred2); head(test_data$respon); preds = data.frame(pred5, pred4, pred3, pred2); preds$pred = -1; for (i in 1:nrow(preds)) {     if (preds$pred5[i]) {         preds$pred[i] = 5;     } else {         if (preds$pred4[i]) {             preds$pred[i] = 4;         } else {             if (preds$pred3[i]) {                 preds$pred[i] = 3;             } else {                 if (preds$pred2[i]) {                     preds$pred[i] = 2;                 } else {                     preds$pred[i] = 1;                 }             }         }     } } preds$target = test_data$respon; confusionMatrix(preds$pred, test_data$respon); test_data %>% group_by(respon) %>% summarise(jumlah_data = n(), persentase = n() / 4679) %>% as.data.frame();
library(imputeTS); library(dplyr); train_file_action = "Training Data 1801.csv"; test_file_action = "Test Data 1801.csv"; train_file_word = "Training Data 1801 - Aggregated.csv"; test_file_word = "Test Data 1801 - Aggregated.csv"; target_column = "manual_assessment"; train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; train_data$source.word = NULL; train_data$target.word = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; test_data$source.word = NULL; test_data$target.word = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
library(imputeTS); library(dplyr); train_file_action = "Training Data 1801.csv"; test_file_action = "Test Data 1801.csv"; train_file_word = "Training Data 1801 - Aggregated.csv"; test_file_word = "Test Data 1801 - Aggregated.csv"; target_column = "manual_assessment"; train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; train_data$source.word = NULL; train_data$target.word = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; test_data$source.word = NULL; test_data$target.word = NULL;
baca = function(nama_file) {     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } partisi = function(input_data,response_name) {     #70/30 partition     #column response as y     colnames(input_data)[colnames(input_data) == response_name] = "respon";     partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1);     dataTrain = input_data[partition_data,];     dataTrain$tipe = "training";     dataTest = input_data[-partition_data,];     dataTest$tipe = "testing";     output_data = rbind(dataTrain, dataTest);     return(output_data); } hitungSVM2 = function(train_data,test_data, target_respon, nu_value, gamma_value) {     library(e1071);     model = svm(subset(train_data,select = -respon), train_data$respon, type = 'one-classification', nu = nu_value, gamma=gamma_value);     pred_trains = predict(model, subset(train_data,select= -respon));     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM = function(input_data,target_respon,nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification',nu=nu_value);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi = function(input_data, target_respon) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data);     x = subset(df, select = -respon);     y = as.factor(df$respon);     model = svm(x, y, probability = TRUE);     pred_train = predict(model, x, decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon),decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i,1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi2 = function(train_data,test_data, c_value, gamma_value) {     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = svm(subset(train_data,select=-respon), train_data$respon, probability = TRUE,C=c_value,gamma=gamma_value);     pred_train = predict(model, subset(train_data, select = -respon), decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon), decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungDecisionTree = function(train_data,test_data) {     library(C50);     library(printr);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     print("CHAID");     library(party);     model = ctree(respon ~ ., data = train_data);     pred = predict(model, test_data);     print(confusionMatrix(pred, test_data$respon));     print("CART");     library(rpart);     model = rpart(respon ~ ., data = train_data, method = "class");     pred = predict(model, test_data, type = "class");     print(confusionMatrix(pred, test_data$respon));     print("C50");     model = C5.0(respon ~ ., data = train_data);     results = predict(object = model, newdata = test_data, type = "class");     pred = predict(model, test_data);     print(confusionMatrix(pred, test_data$respon)); } hitungRandomForest = function(train_data, test_data) {     library(caret);     library(randomForest);     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = randomForest(respon ~ ., data = train_data,importance=TRUE);     pred = predict(model, newdata = test_data);     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon));     return(model); } hitungNaiveBayes = function(train_data,test_data) {     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = naiveBayes(respon ~ ., data = train_data)     pred = predict(model, newdata = subset(test_data, select = -respon));     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); } hitungNaiveBayes_normalization = function(train_data, test_data) {     library(e1071)     library(forecast)     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     for (i in 1:(ncol(train_data)-1)) {             train_data[, i] = BoxCox(train_data[, i], BoxCox.lambda(train_data[, i]));     }     for (i in 1:(ncol(test_data)-1)) {             test_data[, i] = BoxCox(test_data[, i], BoxCox.lambda(test_data[, i]));     }     model = naiveBayes(respon ~ ., data = train_data)     pred = predict(model, newdata = subset(test_data, select = -respon));     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); } hitungFeaturesImportance = function(train_data,test_data,modelRandomForest) {     library(dplyr);     set.seed(12345);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     importances = data.frame(importance(modelRandomForest));     kolom_train_data = colnames(train_data)[1:ncol(train_data) - 1];     importances$kolom = kolom_train_data;     importances = rbind(importances, importances[1,]);     importancesMDA = importances %>%     select(kolom, MeanDecreaseAccuracy) %>%     arrange(-MeanDecreaseAccuracy) %>%     as.data.frame();     importancesMDG = importances %>%     select(kolom, MeanDecreaseGini) %>%     arrange(-MeanDecreaseGini) %>%     as.data.frame();     importancesMDA$results = -1;     for (i in 1:nrow(importancesMDA)) {         kolom = importancesMDA$kolom[1:(nrow(importancesMDA) - i)];         train_dataset1_normMDA = train_data %>%         select(kolom) %>%         as.data.frame();         train_dataset1_normMDA$respon = as.factor(train_data$respon);         test_dataset1_normMDA = test_data %>%         select(kolom) %>%         as.data.frame();         test_dataset1_normMDA$respon = as.factor(test_data$respon);         model = randomForest(respon ~ ., data = train_data, importance = TRUE);         pred = predict(model, newdata = test_data);         hasil = confusionMatrix(pred, test_data$respon);         akurasi = as.numeric(hasil$overall[1]);         importancesMDA$results[i] = akurasi;     }     return(importancesMDA); } # Build your own `normalize()` function normalize <- function(x) {     num <- x - min(x)     denom <- max(x) - min(x)     return(num / denom) }; hitungSoftmax = function(train_data,test_data) {     library(keras);     train_data$respon = as.numeric(train_data$respon)-1;     test_data$respon = as.numeric(test_data$respon) - 1;     train_data_norm = as.data.frame(lapply(train_data[1:(ncol(train_data)-1)], normalize));     test_data_norm = as.data.frame(lapply(test_data[1:(ncol(test_data) - 1)], normalize));     train_data_norm$respon = train_data$respon;     test_data_norm$respon = test_data$respon;     train_data_matrix = as.matrix(train_data);     test_data_matrix = as.matrix(test_data);     dimnames(train_data_matrix) = NULL;     dimnames(test_data_matrix) = NULL;     train_data_matrix_wTarget = train_data_matrix[, 1:(ncol(train_data_matrix) - 1)];     train_data_matrix_target = train_data_matrix[, ncol(train_data_matrix)];     test_data_matrix_wTarget = test_data_matrix[, 1:(ncol(test_data_matrix) - 1)];     test_data_matrix_target = test_data_matrix[, ncol(test_data_matrix)];     train_data_matrix_labels = to_categorical(train_data_matrix_target);     test_data_matrix_labels = to_categorical(test_data_matrix_target);     # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     # BEST RESULTS 1 hidden 180 units : 77.80%     # 2 hidden: 180 relu units + 90 relu units : 78.49968%     model %>%     layer_dense(units = 180, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 5, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)     return(output); }
library(imputeTS); library(dplyr); train_file_action = "Training Data 1801.csv"; test_file_action = "Test Data 1801.csv"; train_file_word = "Training Data 1801 - Aggregated.csv"; test_file_word = "Test Data 1801 - Aggregated.csv"; target_column = "manual_assessment"; train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; train_data$source.word = NULL; train_data$target.word = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; test_data$source.word = NULL; test_data$target.word = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
library(Kendall); Kendall(test_dataset1_norm$respon, test_dataset1_norm$respon);
test_dataset1_norm$pred = as.numeric(pred); test_dataset1_norm$respon = as.numeric(respon); data12 = subset(test_dataset1_norm, test_dataset1_norm$respon == 1 | test_dataset1_norm$respon == 2); data23 = subset(test_dataset1_norm, test_dataset1_norm$respon == 2 | test_dataset1_norm$respon == 3); data34 = subset(test_dataset1_norm, test_dataset1_norm$respon == 3 | test_dataset1_norm$respon == 4); data45 = subset(test_dataset1_norm, test_dataset1_norm$respon == 4 | test_dataset1_norm$respon == 5);
test_dataset1_norm$pred = as.numeric(test_dataset1_norm$respon); test_dataset1_norm$respon = as.numeric(test_dataset1_norm$respon); data12 = subset(test_dataset1_norm, test_dataset1_norm$respon == 1 | test_dataset1_norm$respon == 2); data23 = subset(test_dataset1_norm, test_dataset1_norm$respon == 2 | test_dataset1_norm$respon == 3); data34 = subset(test_dataset1_norm, test_dataset1_norm$respon == 3 | test_dataset1_norm$respon == 4); data45 = subset(test_dataset1_norm, test_dataset1_norm$respon == 4 | test_dataset1_norm$respon == 5);
nrow(data12)
nrow(data23)
nrow(data34)
nrow(data45)
data12$pred[data12$respon != 1] = 2; data23$pred[data23$respon != 2] = 3; data34$pred[data34$respon != 3] = 4; data45$pred[data45$respon != 4] = 5;
unique(data12)
unique(data12$respon)
unique(data12$pred)
wilcox.test(data12$pred, data12$respon);
wilcox.test(data12$pred, data12$respon); wilcox.test(data23$pred, data23$respon); wilcox.test(data34$pred, data34$respon); wilcox.test(data45$pred, data45$respon);
library(dplyr)
data12 %>% group_by(respon,pred) %>% summarise(jumlah_data = n()) %>% as.data.frame();
data23 %>% group_by(respon,pred) %>% summarise(jumlah_data = n()) %>% as.data.frame();
library(imputeTS); library(dplyr); train_file_action = "Training Data 1801.csv"; test_file_action = "Test Data 1801.csv"; train_file_word = "Training Data 1801 - Aggregated.csv"; test_file_word = "Test Data 1801 - Aggregated.csv"; target_column = "manual_assessment"; train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; train_data$source.word = NULL; train_data$target.word = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; test_data$source.word = NULL; test_data$target.word = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
set.seed(12345); modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm);
train_data_back = train_data
test_data_back = test_data
train_data = train_dataset1_norm
test_data = test_dataset1_norm
    train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);
    pred = predict(model, newdata = test_data);
model = randomForest(respon ~ ., data = train_data,importance=TRUE);
pred = predict(model, newdata = test_data);
pred = predict(modelRandomForest, newdata = test_data);
print(table(pred, test_data$respon)); print(confusionMatrix(pred, test_data$respon));
str(pred)
Kendall(pred, test_data$respon); str(pred)
Kendall(pred, test_data$respon);
data12 = subset(test_dataset1_norm, test_dataset1_norm$respon == 1 | test_dataset1_norm$respon == 2); data23 = subset(test_dataset1_norm, test_dataset1_norm$respon == 2 | test_dataset1_norm$respon == 3); data34 = subset(test_dataset1_norm, test_dataset1_norm$respon == 3 | test_dataset1_norm$respon == 4); data45 = subset(test_dataset1_norm, test_dataset1_norm$respon == 4 | test_dataset1_norm$respon == 5);
test_dataset1_norm$pred = as.numeric(pred); test_dataset1_norm$respon = as.numeric(test_dataset1_norm$respon);
Kendall(pred, test_data$respon);
library(imputeTS); library(dplyr); train_file_action = "Training Data 1801.csv"; test_file_action = "Test Data 1801.csv"; train_file_word = "Training Data 1801 - Aggregated.csv"; test_file_word = "Test Data 1801 - Aggregated.csv"; target_column = "manual_assessment"; train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; train_data$source.word = NULL; train_data$target.word = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; test_data$source.word = NULL; test_data$target.word = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
train_data_back = train_data test_data_back = test_data train_data = train_dataset1_norm test_data = test_dataset1_norm train_data$respon = as.factor(train_data$respon); test_data$respon = as.factor(test_data$respon); pred = predict(modelRandomForest, newdata = test_data); print(table(pred, test_data$respon)); print(confusionMatrix(pred, test_data$respon)); #85.21% Accuracy test_data$pred = as.numeric(pred); test_data$respon = as.numeric(test_data$respon); Kendall(pred, test_data$respon); data12 = subset(test_data, test_data$respon == 1 | test_data$respon == 2); data23 = subset(test_data, test_data$respon == 2 | test_data$respon == 3); data34 = subset(test_data, test_data$respon == 3 | test_data$respon == 4); data45 = subset(test_data, test_data$respon == 4 | test_data$respon == 5); data12$pred[data12$respon != 1] = 2; data23$pred[data23$respon != 2] = 3; data34$pred[data34$respon != 3] = 4; data45$pred[data45$respon != 4] = 5; data23 %>% group_by(respon, pred) %>% summarise(jumlah_data = n()) %>% as.data.frame();
data12 %>% group_by(respon, pred) %>% summarise(jumlah_data = n()) %>% as.data.frame();
data12$pred[data12$pred != 1] = 2; data23$pred[data23$pred != 2] = 3; data34$pred[data34$pred != 3] = 4; data45$pred[data45$pred != 4] = 5; data12 %>% group_by(respon, pred) %>% summarise(jumlah_data = n()) %>% as.data.frame();
wilcox.test(data12$pred, data12$respon); wilcox.test(data23$pred, data23$respon); wilcox.test(data34$pred, data34$respon); wilcox.test(data45$pred, data45$respon);
data45 %>% group_by(respon, pred) %>% summarise(jumlah_data = n()) %>% as.data.frame();
data34 %>% group_by(respon, pred) %>% summarise(jumlah_data = n()) %>% as.data.frame();
data23 %>% group_by(respon, pred) %>% summarise(jumlah_data = n()) %>% as.data.frame();
data12 %>% group_by(respon, pred) %>% summarise(jumlah_data = n()) %>% as.data.frame();
train_data = train_dataset1_norm test_data = test_dataset1_norm train_data$respon = as.factor(train_data$respon); test_data$respon = as.factor(test_data$respon); pred = predict(modelRandomForest, newdata = test_data); print(table(pred, test_data$respon)); print(confusionMatrix(pred, test_data$respon)); #85.21% Accuracy test_data$pred = as.numeric(pred); test_data$respon = as.numeric(test_data$respon); Kendall(pred, test_data$respon); data12 = subset(test_data, test_data$respon == 1 | test_data$respon == 2); data23 = subset(test_data, test_data$respon == 2 | test_data$respon == 3); data34 = subset(test_data, test_data$respon == 3 | test_data$respon == 4); data45 = subset(test_data, test_data$respon == 4 | test_data$respon == 5);
data12 %>% group_by(respon, pred) %>% summarise(jumlah_data = n()) %>% as.data.frame();
data12$pred[data12$pred != 1] = 2; data23$pred[data23$pred != 2] = 3; data34$pred[data34$pred != 3] = 4; data45$pred[data45$pred != 4] = 5; data12 %>% group_by(respon, pred) %>% summarise(jumlah_data = n()) %>% as.data.frame();
data23 %>% group_by(respon, pred) %>% summarise(jumlah_data = n()) %>% as.data.frame();
data34 %>% group_by(respon, pred) %>% summarise(jumlah_data = n()) %>% as.data.frame();
data45 %>% group_by(respon, pred) %>% summarise(jumlah_data = n()) %>% as.data.frame();
wilcox.test(data12$pred, data12$respon); wilcox.test(data23$pred, data23$respon); wilcox.test(data34$pred, data34$respon); wilcox.test(data45$pred, data45$respon);
wilcox.test(data12$pred, data12$respon,paired=TRUE); wilcox.test(data23$pred, data23$respon, paired = TRUE); wilcox.test(data34$pred, data34$respon, paired = TRUE); wilcox.test(data45$pred, data45$respon, paired = TRUE);
wilcox.test(data12$respon, data12$pred,paired=TRUE); wilcox.test(data23$respon, data23$pred, paired = TRUE); wilcox.test(data34$respon, data34$pred, paired = TRUE); wilcox.test(data45$respon, data45$pred , paired = TRUE);
wilcox.test(data12$respon, data12$pred); wilcox.test(data23$respon, data23$pred); wilcox.test(data34$respon, data34$pred); wilcox.test(data45$respon, data45$pred); wilcox.test(data12$respon, data12$pred, paired = TRUE); wilcox.test(data23$respon, data23$pred, paired = TRUE); wilcox.test(data34$respon, data34$pred, paired = TRUE); wilcox.test(data45$respon, data45$pred, paired = TRUE);
wilcox.test(data12$respon, data12$pred); wilcox.test(data23$respon, data23$pred); wilcox.test(data34$respon, data34$pred); wilcox.test(data45$respon, data45$pred);
wilcox.test(data12$respon, data12$pred, paired = TRUE); wilcox.test(data23$respon, data23$pred, paired = TRUE); wilcox.test(data34$respon, data34$pred, paired = TRUE); wilcox.test(data45$respon, data45$pred, paired = TRUE);
Kendall(test_data$respon, pred);
wilcox.test(data12$respon, data12$pred);
head(data12)
install.packages("pROC");
install.packages("pROC");
install.packages("pROC");
library(pROC)
auc(data12$respon,data12$pred)
auc(data23$respon,data23$pred)
auc(data34$respon,data23$pred)
auc(data34$respon,data34$pred)
auc(data45$respon,data45$pred)
library(imputeTS); library(dplyr); train_file_action = "Training Data 1801.csv"; test_file_action = "Test Data 1801.csv"; train_file_word = "Training Data 1801 - Aggregated.csv"; test_file_word = "Test Data 1801 - Aggregated.csv"; target_column = "manual_assessment"; train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; train_data$source.word = NULL; train_data$target.word = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; test_data$source.word = NULL; test_data$target.word = NULL;
str(train_data)
library(imputeTS); library(dplyr); train_file_action = "Training Data 1801.csv"; test_file_action = "Test Data 1801.csv"; train_file_word = "Training Data 1801 - Aggregated.csv"; test_file_word = "Test Data 1801 - Aggregated.csv"; target_column = "manual_assessment"; train_data = baca(train_file_action);
str(train_data)
library(imputeTS); library(dplyr); train_file_action = "Training Data 1801.csv"; test_file_action = "Test Data 1801.csv"; train_file_word = "Training Data 1801 - Aggregated.csv"; test_file_word = "Test Data 1801 - Aggregated.csv"; target_column = "manual_assessment"; train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; train_data$source.word = NULL; train_data$target.word = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; test_data$source.word = NULL; test_data$target.word = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
set.seed(12345);
modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini);
importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= meanMDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= meanMDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); featuresMDA %>% arrange(-MeanDecreaseAccuracy) %>% select(kolom, MeanDecreaseAccuracy) %>% as.data.frame(); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
library(imputeTS); library(dplyr); train_file_action = "Training Data 1801 - Drop Column.csv"; test_file_action = "Test Data 1801 - Drop Column.csv";
train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; train_data$source.word = NULL; train_data$target.word = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; test_data$source.word = NULL; test_data$target.word = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
set.seed(12345); modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q96MDA = quantile(importances$MeanDecreaseAccuracy, 0.96); q96MDG = quantile(importances$MeanDecreaseGini, 0.96); q97MDA = quantile(importances$MeanDecreaseAccuracy, 0.97); q97MDG = quantile(importances$MeanDecreaseGini, 0.97); q98MDA = quantile(importances$MeanDecreaseAccuracy, 0.98); q98MDG = quantile(importances$MeanDecreaseGini, 0.98); #Spearman, Kendall, Polycholic importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= meanMDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= meanMDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); featuresMDA %>% arrange(-MeanDecreaseAccuracy) %>% select(kolom, MeanDecreaseAccuracy) %>% as.data.frame(); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
response = c(1, 2, 2, 1, 1, 2) predicted = c(1, 2, 3, 2, 1, 4) wilcox.test(response, predicted, correct = FALSE, pair = TRUE)
wilcox.test(data12$respon, data12$pred, paired = TRUE, correct=FALSE); wilcox.test(data23$respon, data23$pred, paired = TRUE, correct = FALSE); wilcox.test(data34$respon, data34$pred, paired = TRUE, correct = FALSE); wilcox.test(data45$respon, data45$pred, paired = TRUE, correct = FALSE);
auc(data12$respon, data12$pred); auc(data23$respon, data23$pred); auc(data34$respon, data34$pred); auc(data45$respon, data45$pred);
head(importances)
importances
importances %>% select(kolom, MeanDecreaseAccuracy) %>% arrange(-MeanDecreaseAccuracy);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q96MDA = quantile(importances$MeanDecreaseAccuracy, 0.96); q96MDG = quantile(importances$MeanDecreaseGini, 0.96); q97MDA = quantile(importances$MeanDecreaseAccuracy, 0.97); q97MDG = quantile(importances$MeanDecreaseGini, 0.97); q98MDA = quantile(importances$MeanDecreaseAccuracy, 0.98); q98MDG = quantile(importances$MeanDecreaseGini, 0.98); #Spearman, Kendall, Polycholic importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= 1] = 1; importances$threshMDG[importances$MeanDecreaseGini >= 1] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); featuresMDA %>% arrange(-MeanDecreaseAccuracy) %>% select(kolom, MeanDecreaseAccuracy) %>% as.data.frame(); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
quantile(importances$MeanDecreaseAccuracy)
q1MDA = quantile(importances$MeanDecreaseAccuracy)[2]; q1MDG = quantile(importances$MeanDecreaseGini)[2];
q1MDA
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q1MDA = quantile(importances$MeanDecreaseAccuracy)[2]; q1MDG = quantile(importances$MeanDecreaseGini)[2]; q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q96MDA = quantile(importances$MeanDecreaseAccuracy, 0.96); q96MDG = quantile(importances$MeanDecreaseGini, 0.96); q97MDA = quantile(importances$MeanDecreaseAccuracy, 0.97); q97MDG = quantile(importances$MeanDecreaseGini, 0.97); q98MDA = quantile(importances$MeanDecreaseAccuracy, 0.98); q98MDG = quantile(importances$MeanDecreaseGini, 0.98); #Spearman, Kendall, Polycholic importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= q1MDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= q1MDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); featuresMDA %>% arrange(-MeanDecreaseAccuracy) %>% select(kolom, MeanDecreaseAccuracy) %>% as.data.frame(); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q1MDA = quantile(importances$MeanDecreaseAccuracy)[2]; q1MDG = quantile(importances$MeanDecreaseGini)[2]; q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q96MDA = quantile(importances$MeanDecreaseAccuracy, 0.96); q96MDG = quantile(importances$MeanDecreaseGini, 0.96); q97MDA = quantile(importances$MeanDecreaseAccuracy, 0.97); q97MDG = quantile(importances$MeanDecreaseGini, 0.97); q98MDA = quantile(importances$MeanDecreaseAccuracy, 0.98); q98MDG = quantile(importances$MeanDecreaseGini, 0.98); #Spearman, Kendall, Polycholic importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= meanMDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= meanMDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); featuresMDA %>% arrange(-MeanDecreaseAccuracy) %>% select(kolom, MeanDecreaseAccuracy) %>% as.data.frame(); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
hitungNaiveBayes(train_dataset1_norm, test_dataset1_norm); hitungDecisionTree(train_dataset1_norm, test_dataset1_norm);
modelRandomForest = hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA); hitungNaiveBayes(train_dataset1_normMDA, test_dataset1_normMDA); hitungDecisionTree(train_dataset1_normMDA, test_dataset1_normMDA);
hitungNaiveBayes(train_dataset1_normMDA, test_dataset1_normMDA); hitungDecisionTree(train_dataset1_normMDA, test_dataset1_normMDA);
library(e1071); train_data_back = train_data; test_data_back = test_data; train_data = train_dataset1_norm; test_data = test_dataset1_norm; train_data5 = subset(train_data, respon == 5, select = -respon); train_data54 = subset(train_data, respon >= 4, select = -respon); train_data543 = subset(train_data, respon >= 3, select = -respon); train_data5432 = subset(train_data, respon >= 2, select = -respon); #Best nu=0.001, gamma=0.01 accuracy=78.03 #model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); #model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.1,gamma=0.01); model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.1, gamma = 1); model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.1, gamma = 0.01); model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.1, gamma = 1); pred5 = predict(model5, subset(test_data,select=-respon)); pred4 = predict(model54, subset(test_data, select = -respon)); pred3 = predict(model543, subset(test_data, select = -respon)); pred2 = predict(model5432, subset(test_data, select = -respon)); head(pred5); head(pred4); head(pred3); head(pred2); head(test_data$respon); preds = data.frame(pred5, pred4, pred3, pred2); preds$pred = -1; for (i in 1:nrow(preds)) {     if (preds$pred5[i]) {         preds$pred[i] = 5;     } else {         if (preds$pred4[i]) {             preds$pred[i] = 4;         } else {             if (preds$pred3[i]) {                 preds$pred[i] = 3;             } else {                 if (preds$pred2[i]) {                     preds$pred[i] = 2;                 } else {                     preds$pred[i] = 1;                 }             }         }     } } preds$target = test_data$respon; confusionMatrix(preds$pred, test_data$respon); test_data %>% group_by(respon) %>% summarise(jumlah_data = n(), persentase = n() / 4679) %>% as.data.frame();
library(imputeTS); library(dplyr); train_file_action = "Training Data 1901 - Drop Column.csv"; test_file_action = "Test Data 1901 - Drop Column.csv"; train_file_word = "Training Data 1801 - Aggregated.csv"; test_file_word = "Test Data 1801 - Aggregated.csv"; target_column = "manual_assessment"; train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; train_data$source.word = NULL; train_data$target.word = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; test_data$source.word = NULL; test_data$target.word = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
baca = function(nama_file) {     output = read.csv(paste("Dataset/",nama_file,sep = ""), stringsAsFactors = FALSE);     return(output); } partisi = function(input_data,response_name) {     #70/30 partition     #column response as y     colnames(input_data)[colnames(input_data) == response_name] = "respon";     partition_data = createDataPartition(input_data$respon, p = 0.7, list = FALSE, times = 1);     dataTrain = input_data[partition_data,];     dataTrain$tipe = "training";     dataTest = input_data[-partition_data,];     dataTest$tipe = "testing";     output_data = rbind(dataTrain, dataTest);     return(output_data); } hitungSVM2 = function(train_data,test_data, target_respon, nu_value, gamma_value) {     library(e1071);     model = svm(subset(train_data,select = -respon), train_data$respon, type = 'one-classification', nu = nu_value, gamma=gamma_value);     pred_trains = predict(model, subset(train_data,select= -respon));     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = train_data;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM = function(input_data,target_respon,nu_value) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data, respon == target_respon);     x = subset(df, select = -respon);     y = df$respon;     model = svm(x, y, type = 'one-classification',nu=nu_value);     pred_trains = predict(model, x);     pred_test = predict(model, subset(test_data, select = -respon));     pred_data = test_data;     pred_data$pred = pred_test;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == target_respon & pred_data$pred == TRUE] = 1;     pred_data$flag[pred_data$respon != target_respon & pred_data$pred == FALSE] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_trains;     pred_train$flag = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi = function(input_data, target_respon) {     library(e1071);     train_data = subset(input_data, tipe == "training");     train_data$tipe = NULL;     test_data = subset(input_data, tipe == "testing");     test_data$tipe = NULL;     df = subset(train_data);     x = subset(df, select = -respon);     y = as.factor(df$respon);     model = svm(x, y, probability = TRUE);     pred_train = predict(model, x, decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon),decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i,1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob>max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungSVM_multi2 = function(train_data,test_data, c_value, gamma_value) {     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = svm(subset(train_data,select=-respon), train_data$respon, probability = TRUE,C=c_value,gamma=gamma_value);     pred_train = predict(model, subset(train_data, select = -respon), decision.values = TRUE, probability = TRUE);     pred_test = predict(model, subset(test_data, select = -respon), decision.values = TRUE, probability = TRUE);     #normalization and find specific prediction value      pred_train_value = as.data.frame(attr(pred_train, "probabilities"));     pred_test_value = as.data.frame(attr(pred_test, "probabilities"));     pred_train_value$pred = -1;     for (i in 1:nrow(pred_train_value)) {         max_prob = pred_train_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_train_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_train_value$pred[i] = max_pos;     }     pred_test_value$pred = -1;     for (i in 1:nrow(pred_test_value)) {         max_prob = pred_test_value[i, 1];         max_pos = 1;         for (j in 2:5) {             current_prob = pred_test_value[i, j];             current_pos = j;             if (current_prob > max_prob) {                 max_prob = current_prob;                 max_pos = current_pos;             }         }         pred_test_value$pred[i] = max_pos;     }     pred_data = test_data;     pred_data$pred = pred_test_value$pred;     pred_data$flag = 0;     pred_data$flag[pred_data$respon == pred_data$pred] = 1;     print(model);     pred_train = df;     pred_train$pred = pred_train_value$pred;     pred_train$flag = 0;     pred_train$flag[pred_train$respon == pred_train$pred] = 1;     print(paste("Training Accuracy : ", nrow(subset(pred_train, pred_train$pred == TRUE)) / nrow(pred_train)));     print(paste("Testing Accuracy : ", nrow(subset(pred_data, flag == 1)) / nrow(pred_data)));     pred_train$tipe = "TRAIN";     pred_data$tipe = "TEST";     train_test_data = rbind(pred_train, pred_data);     return(train_test_data); } hitungDecisionTree = function(train_data,test_data) {     library(C50);     library(printr);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     print("CHAID");     library(party);     model = ctree(respon ~ ., data = train_data);     pred = predict(model, test_data);     print(confusionMatrix(pred, test_data$respon));     print("CART");     library(rpart);     model = rpart(respon ~ ., data = train_data, method = "class");     pred = predict(model, test_data, type = "class");     print(confusionMatrix(pred, test_data$respon));     print("C50");     model = C5.0(respon ~ ., data = train_data);     results = predict(object = model, newdata = test_data, type = "class");     pred = predict(model, test_data);     print(confusionMatrix(pred, test_data$respon)); } hitungRandomForest = function(train_data, test_data) {     library(caret);     library(randomForest);     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = randomForest(respon ~ ., data = train_data,importance=TRUE);     pred = predict(model, newdata = test_data);     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon));     return(model); } hitungNaiveBayes = function(train_data,test_data) {     library(e1071);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     model = naiveBayes(respon ~ ., data = train_data)     pred = predict(model, newdata = subset(test_data, select = -respon));     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); } hitungNaiveBayes_normalization = function(train_data, test_data) {     library(e1071)     library(forecast)     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     for (i in 1:(ncol(train_data)-1)) {             train_data[, i] = BoxCox(train_data[, i], BoxCox.lambda(train_data[, i]));     }     for (i in 1:(ncol(test_data)-1)) {             test_data[, i] = BoxCox(test_data[, i], BoxCox.lambda(test_data[, i]));     }     model = naiveBayes(respon ~ ., data = train_data)     pred = predict(model, newdata = subset(test_data, select = -respon));     print(table(pred, test_data$respon));     print(confusionMatrix(pred, test_data$respon)); } hitungFeaturesImportance = function(train_data,test_data,modelRandomForest) {     library(dplyr);     set.seed(12345);     train_data$respon = as.factor(train_data$respon);     test_data$respon = as.factor(test_data$respon);     importances = data.frame(importance(modelRandomForest));     kolom_train_data = colnames(train_data)[1:ncol(train_data) - 1];     importances$kolom = kolom_train_data;     importances = rbind(importances, importances[1,]);     importancesMDA = importances %>%     select(kolom, MeanDecreaseAccuracy) %>%     arrange(-MeanDecreaseAccuracy) %>%     as.data.frame();     importancesMDG = importances %>%     select(kolom, MeanDecreaseGini) %>%     arrange(-MeanDecreaseGini) %>%     as.data.frame();     importancesMDA$results = -1;     for (i in 1:nrow(importancesMDA)) {         kolom = importancesMDA$kolom[1:(nrow(importancesMDA) - i)];         train_dataset1_normMDA = train_data %>%         select(kolom) %>%         as.data.frame();         train_dataset1_normMDA$respon = as.factor(train_data$respon);         test_dataset1_normMDA = test_data %>%         select(kolom) %>%         as.data.frame();         test_dataset1_normMDA$respon = as.factor(test_data$respon);         model = randomForest(respon ~ ., data = train_data, importance = TRUE);         pred = predict(model, newdata = test_data);         hasil = confusionMatrix(pred, test_data$respon);         akurasi = as.numeric(hasil$overall[1]);         importancesMDA$results[i] = akurasi;     }     return(importancesMDA); } # Build your own `normalize()` function normalize <- function(x) {     num <- x - min(x)     denom <- max(x) - min(x)     return(num / denom) }; hitungSoftmax = function(train_data,test_data) {     library(keras);     train_data$respon = as.numeric(train_data$respon)-1;     test_data$respon = as.numeric(test_data$respon) - 1;     train_data_norm = as.data.frame(lapply(train_data[1:(ncol(train_data)-1)], normalize));     test_data_norm = as.data.frame(lapply(test_data[1:(ncol(test_data) - 1)], normalize));     train_data_norm$respon = train_data$respon;     test_data_norm$respon = test_data$respon;     train_data_matrix = as.matrix(train_data);     test_data_matrix = as.matrix(test_data);     dimnames(train_data_matrix) = NULL;     dimnames(test_data_matrix) = NULL;     train_data_matrix_wTarget = train_data_matrix[, 1:(ncol(train_data_matrix) - 1)];     train_data_matrix_target = train_data_matrix[, ncol(train_data_matrix)];     test_data_matrix_wTarget = test_data_matrix[, 1:(ncol(test_data_matrix) - 1)];     test_data_matrix_target = test_data_matrix[, ncol(test_data_matrix)];     train_data_matrix_labels = to_categorical(train_data_matrix_target);     test_data_matrix_labels = to_categorical(test_data_matrix_target);     # Initialize a sequential model     model = keras_model_sequential()     # Add layers to the model     # BEST RESULTS 1 hidden 180 units : 77.80%     # 2 hidden: 180 relu units + 90 relu units : 78.49968%     model %>%     layer_dense(units = 180, activation = 'relu', input_shape = c(90)) %>%     layer_dense(units = 5, activation = 'softmax');     # Compile the model     model %>% compile(      loss = 'categorical_crossentropy',      optimizer = 'adam',      metrics = 'accuracy'      )     # Store the fitting history in `history`      history <- model %>% fit(      train_data_matrix_wTarget,      train_data_matrix_labels,      epochs = 200,      batch_size = 5,      validation_split = 0.2     )     # Predict the classes for the test data     classes = model %>% predict_classes(test_data_matrix_wTarget, batch_size = 128)     # Evaluate on test data and labels     score = model %>% evaluate(test_data_matrix_wTarget, test_data_matrix_labels, batch_size = 128)     # Print the score     print(score)     return(output); }
library(imputeTS); library(dplyr); train_file_action = "Training Data 1901 - Drop Column.csv"; test_file_action = "Test Data 1901 - Drop Column.csv"; train_file_word = "Training Data 1801 - Aggregated.csv"; test_file_word = "Test Data 1801 - Aggregated.csv"; target_column = "manual_assessment"; train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; train_data$source.word = NULL; train_data$target.word = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; test_data$source.word = NULL; test_data$target.word = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
library(imputeTS); library(dplyr); train_file_action = "Training Data 1901 - Drop Column.csv"; test_file_action = "Test Data 1901 - Drop Column.csv"; train_file_word = "Training Data 1801 - Aggregated.csv"; test_file_word = "Test Data 1801 - Aggregated.csv"; target_column = "manual_assessment"; train_data = baca(train_file_action);
str(train_data)
library(imputeTS); library(dplyr); train_file_action = "Training Data 1901 - Drop Column.csv"; test_file_action = "Test Data 1901 - Drop Column.csv"; train_file_word = "Training Data 1801 - Aggregated.csv"; test_file_word = "Test Data 1801 - Aggregated.csv"; target_column = "manual_assessment_avg"; train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$manual_origin_source = NULL; train_data$origin_mean_vote_up = NULL; train_data$source.word = NULL; train_data$target.word = NULL; train_data$X = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$manual_origin_source = NULL; test_data$origin_mean_vote_up = NULL; test_data$source.word = NULL; test_data$target.word = NULL; test_data$X = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
str(train_dataset1_norm)
set.seed(12345); modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm); hitungNaiveBayes(train_dataset1_norm, test_dataset1_norm); hitungDecisionTree(train_dataset1_norm, test_dataset1_norm);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q1MDA = quantile(importances$MeanDecreaseAccuracy)[2]; q1MDG = quantile(importances$MeanDecreaseGini)[2]; q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q96MDA = quantile(importances$MeanDecreaseAccuracy, 0.96); q96MDG = quantile(importances$MeanDecreaseGini, 0.96); q97MDA = quantile(importances$MeanDecreaseAccuracy, 0.97); q97MDG = quantile(importances$MeanDecreaseGini, 0.97); q98MDA = quantile(importances$MeanDecreaseAccuracy, 0.98); q98MDG = quantile(importances$MeanDecreaseGini, 0.98); #Spearman, Kendall, Polycholic importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= meanMDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= meanMDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); featuresMDA %>% arrange(-MeanDecreaseAccuracy) %>% select(kolom, MeanDecreaseAccuracy) %>% as.data.frame(); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
hitungNaiveBayes(train_dataset1_normMDA, test_dataset1_normMDA); hitungDecisionTree(train_dataset1_normMDA, test_dataset1_normMDA);
library(imputeTS); library(dplyr); train_file_action = "Training Data 1901 - Drop Column.csv"; test_file_action = "Test Data 1901 - Drop Column.csv"; train_file_word = "Training Data 1801 - Aggregated.csv"; test_file_word = "Test Data 1801 - Aggregated.csv"; target_column = "manual_assessment_avg"; train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$source.word = NULL; train_data$target.word = NULL; train_data$X = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$source.word = NULL; test_data$target.word = NULL; test_data$X = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]
set.seed(12345); modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm); hitungNaiveBayes(train_dataset1_norm, test_dataset1_norm); hitungDecisionTree(train_dataset1_norm, test_dataset1_norm);
importances = data.frame(importance(modelRandomForest)); kolom_train_data = colnames(train_dataset1_norm)[1:ncol(train_dataset1_norm) - 1]; importances$kolom = kolom_train_data; importances = rbind(importances, importances[1,]); meanMDA = mean(importances$MeanDecreaseAccuracy); meanMDG = mean(importances$MeanDecreaseGini); q1MDA = quantile(importances$MeanDecreaseAccuracy)[2]; q1MDG = quantile(importances$MeanDecreaseGini)[2]; q3MDA = quantile(importances$MeanDecreaseAccuracy)[4]; q3MDG = quantile(importances$MeanDecreaseGini)[4]; q80MDA = quantile(importances$MeanDecreaseAccuracy,0.8); q80MDG = quantile(importances$MeanDecreaseGini,0.8); q85MDA = quantile(importances$MeanDecreaseAccuracy, 0.85); q85MDG = quantile(importances$MeanDecreaseGini, 0.85); q90MDA = quantile(importances$MeanDecreaseAccuracy, 0.9); q90MDG = quantile(importances$MeanDecreaseGini, 0.9); q95MDA = quantile(importances$MeanDecreaseAccuracy, 0.95); q95MDG = quantile(importances$MeanDecreaseGini, 0.95); q96MDA = quantile(importances$MeanDecreaseAccuracy, 0.96); q96MDG = quantile(importances$MeanDecreaseGini, 0.96); q97MDA = quantile(importances$MeanDecreaseAccuracy, 0.97); q97MDG = quantile(importances$MeanDecreaseGini, 0.97); q98MDA = quantile(importances$MeanDecreaseAccuracy, 0.98); q98MDG = quantile(importances$MeanDecreaseGini, 0.98); #Spearman, Kendall, Polycholic importances$threshMDA = 0; importances$threshMDG = 0; importances$threshMDA[importances$MeanDecreaseAccuracy >= meanMDA] = 1; importances$threshMDG[importances$MeanDecreaseGini >= meanMDA] = 1; featuresMDA = subset(importances, threshMDA == 1); featuresMDG = subset(importances, threshMDG == 1); featuresMDA %>% arrange(-MeanDecreaseAccuracy) %>% select(kolom, MeanDecreaseAccuracy) %>% as.data.frame(); namaMDA = featuresMDA$kolom; namaMDG = featuresMDG$kolom; train_dataset1_normMDA = train_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); train_dataset1_normMDA$respon = train_dataset1_norm$respon; train_dataset1_normMDG = train_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); train_dataset1_normMDG$respon = train_dataset1_norm$respon; test_dataset1_normMDA = test_dataset1_norm %>% select(namaMDA) %>% as.data.frame(); test_dataset1_normMDA$respon = test_dataset1_norm$respon; test_dataset1_normMDG = test_dataset1_norm %>% select(namaMDG) %>% as.data.frame(); test_dataset1_normMDG$respon = test_dataset1_norm$respon; hitungRandomForest(train_dataset1_normMDA, test_dataset1_normMDA);
hitungNaiveBayes(train_dataset1_normMDA, test_dataset1_normMDA); hitungDecisionTree(train_dataset1_normMDA, test_dataset1_normMDA);
library(e1071); train_data_back = train_data; test_data_back = test_data; train_data = train_dataset1_norm; test_data = test_dataset1_norm; train_data5 = subset(train_data, respon == 5, select = -respon); train_data54 = subset(train_data, respon >= 4, select = -respon); train_data543 = subset(train_data, respon >= 3, select = -respon); train_data5432 = subset(train_data, respon >= 2, select = -respon); #Best nu=0.001, gamma=0.01 accuracy=78.03 #model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); #model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.1,gamma=0.01); model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.1, gamma = 1); model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.1, gamma = 0.01); model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.1, gamma = 1); pred5 = predict(model5, subset(test_data,select=-respon)); pred4 = predict(model54, subset(test_data, select = -respon)); pred3 = predict(model543, subset(test_data, select = -respon)); pred2 = predict(model5432, subset(test_data, select = -respon)); head(pred5); head(pred4); head(pred3); head(pred2); head(test_data$respon); preds = data.frame(pred5, pred4, pred3, pred2); preds$pred = -1; for (i in 1:nrow(preds)) {     if (preds$pred5[i]) {         preds$pred[i] = 5;     } else {         if (preds$pred4[i]) {             preds$pred[i] = 4;         } else {             if (preds$pred3[i]) {                 preds$pred[i] = 3;             } else {                 if (preds$pred2[i]) {                     preds$pred[i] = 2;                 } else {                     preds$pred[i] = 1;                 }             }         }     } } preds$target = test_data$respon; confusionMatrix(preds$pred, test_data$respon); test_data %>% group_by(respon) %>% summarise(jumlah_data = n(), persentase = n() / 4679) %>% as.data.frame();
str(train_dataset1_normMDA)
library(e1071); train_data_back = train_data; test_data_back = test_data; train_data = train_dataset1_normMDA; test_data = test_dataset1_normMDA;
train_data5 = subset(train_data, respon == 5, select = -respon); train_data54 = subset(train_data, respon >= 4, select = -respon); train_data543 = subset(train_data, respon >= 3, select = -respon); train_data5432 = subset(train_data, respon >= 2, select = -respon); #Best nu=0.001, gamma=0.01 accuracy=78.03 #model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); #model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.001, gamma = 0.01); #model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.001, gamma = 0.1); model5 = svm(train_data5, train_data5$respon, type = 'one-classification', nu = 0.1,gamma=0.01); model54 = svm(train_data54, train_data54$respon, type = 'one-classification', nu = 0.1, gamma = 1); model543 = svm(train_data543, train_data543$respon, type = 'one-classification', nu = 0.1, gamma = 0.01); model5432 = svm(train_data5432, train_data5432$respon, type = 'one-classification', nu = 0.1, gamma = 1); pred5 = predict(model5, subset(test_data,select=-respon)); pred4 = predict(model54, subset(test_data, select = -respon)); pred3 = predict(model543, subset(test_data, select = -respon)); pred2 = predict(model5432, subset(test_data, select = -respon)); head(pred5); head(pred4); head(pred3); head(pred2); head(test_data$respon); preds = data.frame(pred5, pred4, pred3, pred2); preds$pred = -1; for (i in 1:nrow(preds)) {     if (preds$pred5[i]) {         preds$pred[i] = 5;     } else {         if (preds$pred4[i]) {             preds$pred[i] = 4;         } else {             if (preds$pred3[i]) {                 preds$pred[i] = 3;             } else {                 if (preds$pred2[i]) {                     preds$pred[i] = 2;                 } else {                     preds$pred[i] = 1;                 }             }         }     } } preds$target = test_data$respon; confusionMatrix(preds$pred, test_data$respon); test_data %>% group_by(respon) %>% summarise(jumlah_data = n(), persentase = n() / 4679) %>% as.data.frame();
importances
importances %>% select(kolom, MeanDecreaseAccuracy) %>% arrange(-MeanDecreaseAccuracy);
getFI_RandomForest = function(train_data) {     print("Train Random Forest");     set.seed(12345);     library(caret);     library(randomForest);     library(e1071);     train_data$respon = as.factor(train_data$respon);     model = randomForest(respon ~ ., data = train_data, importance = TRUE);     importances = data.frame(importance(model));     kolom_train_data = colnames(train_data)[1:ncol(train_data) - 1];     importances$kolom = kolom_train_data;     importances = rbind(importances, importances[1,]);     importancesMDA = importances %>%     select(kolom, MeanDecreaseAccuracy) %>%     arrange(-MeanDecreaseAccuracy) %>%     as.data.frame();     importancesMDG = importances %>%     select(kolom, MeanDecreaseGini) %>%     arrange(-MeanDecreaseGini) %>%     as.data.frame();     output = list("MDA" = importancesMDA, "MDG" = importancesMDG);     return(output); } ;
getFI_RandomForest = function(train_data) {     print("Train Random Forest");     set.seed(12345);     library(caret);     library(randomForest);     library(e1071);     train_data$respon = as.factor(train_data$respon);     model = randomForest(respon ~ ., data = train_data, importance = TRUE);     importances = data.frame(importance(model));     kolom_train_data = colnames(train_data)[1:ncol(train_data) - 1];     importances$kolom = kolom_train_data;     importances = rbind(importances, importances[1,]);     importancesMDA = importances %>%     select(kolom, MeanDecreaseAccuracy) %>%     arrange(-MeanDecreaseAccuracy) %>%     as.data.frame();     importancesMDG = importances %>%     select(kolom, MeanDecreaseGini) %>%     arrange(-MeanDecreaseGini) %>%     as.data.frame();     output = list("MDA" = importancesMDA, "MDG" = importancesMDG);     return(output); }
library(imputeTS); library(dplyr); source("automation.R"); train_file_action = "Training Data 1901 - Drop Column.csv"; test_file_action = "Test Data 1901 - Drop Column.csv"; train_file_word = "Training Data 1801 - Aggregated.csv"; test_file_word = "Test Data 1801 - Aggregated.csv"; target_column = "manual_assessment_avg"; train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon";
hasil = getFI_RandomForest(train_data)
library(imputeTS); library(dplyr); source("automation.R"); train_file_action = "Training Data 1901 - Drop Column.csv"; test_file_action = "Test Data 1901 - Drop Column.csv"; train_file_word = "Training Data 1801 - Aggregated.csv"; test_file_word = "Test Data 1801 - Aggregated.csv"; target_column = "manual_assessment_avg"; train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$source.word = NULL; train_data$target.word = NULL; train_data$X = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$source.word = NULL; test_data$target.word = NULL; test_data$X = NULL; train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0];
hasil = getFI_RandomForest(train_dataset1_norm);
str(hasil)
head(hasil)
library(imputeTS); library(dplyr); source("automation.R"); train_file_action = "Training Data 1901 - Drop Column.csv"; test_file_action = "Test Data 1901 - Drop Column.csv"; train_file_word = "Training Data 1801 - Aggregated.csv"; test_file_word = "Test Data 1801 - Aggregated.csv"; target_column = "manual_assessment_avg"; train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$source.word = NULL; train_data$target.word = NULL; train_data$X = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$source.word = NULL; test_data$target.word = NULL; test_data$X = NULL; nrow(train_data); nrow(test_data);
library(imputeTS); library(dplyr); source("automation.R"); train_file_action = "Training Data 1901 - Drop Column.csv"; test_file_action = "Test Data 1901 - Drop Column.csv"; train_file_word = "Training Data 1801 - Aggregated.csv"; test_file_word = "Test Data 1801 - Aggregated.csv"; target_column = "manual_assessment_avg"; train_data = baca(train_file_action); colnames(train_data)[colnames(train_data) == target_column] = "respon"; train_data$source.word = NULL; train_data$target.word = NULL; train_data$X = NULL; test_data = baca(test_file_action); colnames(test_data)[colnames(test_data) == target_column] = "respon"; test_data$source.word = NULL; test_data$target.word = NULL; test_data$X = NULL; nrow(train_data); nrow(test_data); train_data %>% filter(is.na(respon) | is.na(origin_word_entropy)) %>% group_by(origin_word_entropy, respon) %>% summarise(jumlah_data = n()); #| is.na(manual_origin_source) #Dataset1 = manual_assessment as target train_dataset1 = train_data; test_dataset1 = test_data; #Data Preprocessing train_dataset1$username = NULL; train_dataset1$source.word = NULL; train_dataset1$target.word = NULL; train_dataset1_assessed = train_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #check na value colnames(train_dataset1_assessed)[colSums(is.na(train_dataset1_assessed)) > 0] #normalization by replace NA with 0 train_dataset1_norm = na.replace(train_dataset1_assessed, 0); colnames(train_dataset1_norm)[colSums(is.na(train_dataset1_norm)) > 0] test_dataset1$username = NULL; test_dataset1$source.word = NULL; test_dataset1$target.word = NULL; test_dataset1_assessed = test_dataset1 %>% filter(!is.na(respon) & !is.na(origin_word_entropy)) %>% as.data.frame(); #& !is.na(manual_origin_source) #check na value colnames(test_dataset1_assessed)[colSums(is.na(test_dataset1_assessed)) > 0] #normalization by replace NA with 0 test_dataset1_norm = na.replace(test_dataset1_assessed, 0); colnames(test_dataset1_norm)[colSums(is.na(test_dataset1_norm)) > 0]; nrow(train_dataset1_norm); nrow(test_dataset1_norm);
modelRandomForest = hitungRandomForest(train_dataset1_norm, test_dataset1_norm);
